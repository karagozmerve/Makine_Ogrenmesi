{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/25\n",
      "124/124 [==============================] - 2s 12ms/step - loss: 0.9552 - accuracy: 0.5726 - val_loss: 0.7280 - val_accuracy: 0.5556\n",
      "Epoch 2/25\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.4601 - accuracy: 0.8306 - val_loss: 0.5195 - val_accuracy: 0.7222\n",
      "Epoch 3/25\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.2403 - accuracy: 0.9274 - val_loss: 0.2822 - val_accuracy: 0.8889\n",
      "Epoch 4/25\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.1134 - accuracy: 0.9758 - val_loss: 0.3160 - val_accuracy: 0.8704\n",
      "Epoch 5/25\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0660 - accuracy: 0.9839 - val_loss: 0.2792 - val_accuracy: 0.8889\n",
      "Epoch 6/25\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.8889\n",
      "Epoch 7/25\n",
      "124/124 [==============================] - 0s 492us/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.2667 - val_accuracy: 0.8889\n",
      "Epoch 8/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.2388 - val_accuracy: 0.8889\n",
      "Epoch 9/25\n",
      "124/124 [==============================] - 0s 524us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.2609 - val_accuracy: 0.8889\n",
      "Epoch 10/25\n",
      "124/124 [==============================] - 0s 822us/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.2439 - val_accuracy: 0.8889\n",
      "Epoch 11/25\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 0.8889\n",
      "Epoch 12/25\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2574 - val_accuracy: 0.8889\n",
      "Epoch 13/25\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.8889\n",
      "Epoch 14/25\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.8889\n",
      "Epoch 15/25\n",
      "124/124 [==============================] - 0s 621us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2740 - val_accuracy: 0.8889\n",
      "Epoch 16/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.8889\n",
      "Epoch 17/25\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.8889\n",
      "Epoch 18/25\n",
      "124/124 [==============================] - 0s 814us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.8889\n",
      "Epoch 19/25\n",
      "124/124 [==============================] - 0s 935us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.8889\n",
      "Epoch 20/25\n",
      "124/124 [==============================] - 0s 669us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.2884 - val_accuracy: 0.8889\n",
      "Epoch 21/25\n",
      "124/124 [==============================] - 0s 572us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 0.8889\n",
      "Epoch 22/25\n",
      "124/124 [==============================] - 0s 556us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2907 - val_accuracy: 0.8889\n",
      "Epoch 23/25\n",
      "124/124 [==============================] - 0s 621us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2933 - val_accuracy: 0.8889\n",
      "Epoch 24/25\n",
      "124/124 [==============================] - 0s 572us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.8889\n",
      "Epoch 25/25\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.8889\n",
      "Test loss: 0.29575098029993196\n",
      "Test accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['accuracy'])\n",
    "plt.plot(training_model.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['loss'])\n",
    "plt.plot(training_model.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 1s 6ms/step - loss: 0.9112 - accuracy: 0.5726 - val_loss: 0.6383 - val_accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.3729 - accuracy: 0.8548 - val_loss: 0.2855 - val_accuracy: 0.8889\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 420us/step - loss: 0.1951 - accuracy: 0.9355 - val_loss: 0.3253 - val_accuracy: 0.8889\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 402us/step - loss: 0.1015 - accuracy: 0.9677 - val_loss: 0.3084 - val_accuracy: 0.9074\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0696 - accuracy: 0.9758 - val_loss: 0.2211 - val_accuracy: 0.8889\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 426us/step - loss: 0.0501 - accuracy: 0.9839 - val_loss: 0.2511 - val_accuracy: 0.8889\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 430us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.8889\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 312us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.2229 - val_accuracy: 0.9074\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 409us/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.2622 - val_accuracy: 0.8889\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 516us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.2587 - val_accuracy: 0.8889\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.8889\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.2755 - val_accuracy: 0.8889\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.8889\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 368us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.2967 - val_accuracy: 0.8889\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.8704\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 290us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9074\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 384us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3187 - val_accuracy: 0.8889\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 285us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3158 - val_accuracy: 0.8889\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8889\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3220 - val_accuracy: 0.8889\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.8889\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 481us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.8889\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 384us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3306 - val_accuracy: 0.8889\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 501us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.8889\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 417us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.8889\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.8889\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 505us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.8889\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 307us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.8889\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.8889\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.8889\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.8889\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.8889\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 517us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.8889\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 349us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.8889\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.8889\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.8889\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.8889\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 537us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.8704\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.8704\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.8889\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.8889\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.8889\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.8889\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.8704\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.8704\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.8889\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.8889\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.8704\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 9.9241e-04 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.8704\n",
      "Test loss: 0.3822536275342659\n",
      "Test accuracy: 0.8703703880310059\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/150\n",
      "124/124 [==============================] - 0s 4ms/step - loss: 0.8612 - accuracy: 0.5806 - val_loss: 0.4165 - val_accuracy: 0.9259\n",
      "Epoch 2/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.3077 - accuracy: 0.8871 - val_loss: 0.2093 - val_accuracy: 0.9444\n",
      "Epoch 3/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.1259 - accuracy: 0.9758 - val_loss: 0.1630 - val_accuracy: 0.9444\n",
      "Epoch 4/150\n",
      "124/124 [==============================] - 0s 478us/step - loss: 0.0823 - accuracy: 0.9758 - val_loss: 0.6742 - val_accuracy: 0.7407\n",
      "Epoch 5/150\n",
      "124/124 [==============================] - 0s 430us/step - loss: 0.0983 - accuracy: 0.9839 - val_loss: 0.1428 - val_accuracy: 0.9815\n",
      "Epoch 6/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.0426 - accuracy: 0.9919 - val_loss: 0.5198 - val_accuracy: 0.8148\n",
      "Epoch 7/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 0.1905 - val_accuracy: 0.9259\n",
      "Epoch 8/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9444\n",
      "Epoch 9/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.1568 - val_accuracy: 0.9444\n",
      "Epoch 10/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.1646 - val_accuracy: 0.9444\n",
      "Epoch 11/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1628 - val_accuracy: 0.9444\n",
      "Epoch 12/150\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1746 - val_accuracy: 0.9444\n",
      "Epoch 13/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.1892 - val_accuracy: 0.9444\n",
      "Epoch 14/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.1805 - val_accuracy: 0.9444\n",
      "Epoch 15/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.1767 - val_accuracy: 0.9444\n",
      "Epoch 16/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9444\n",
      "Epoch 17/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1827 - val_accuracy: 0.9444\n",
      "Epoch 18/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1835 - val_accuracy: 0.9444\n",
      "Epoch 19/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9444\n",
      "Epoch 20/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9444\n",
      "Epoch 21/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.9444\n",
      "Epoch 22/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1991 - val_accuracy: 0.9444\n",
      "Epoch 23/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1998 - val_accuracy: 0.9444\n",
      "Epoch 24/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9630\n",
      "Epoch 25/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 0.9444\n",
      "Epoch 26/150\n",
      "124/124 [==============================] - 0s 348us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2021 - val_accuracy: 0.9444\n",
      "Epoch 27/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1972 - val_accuracy: 0.9630\n",
      "Epoch 28/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.9444\n",
      "Epoch 29/150\n",
      "124/124 [==============================] - 0s 324us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2047 - val_accuracy: 0.9444\n",
      "Epoch 30/150\n",
      "124/124 [==============================] - 0s 251us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9444\n",
      "Epoch 31/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9630\n",
      "Epoch 32/150\n",
      "124/124 [==============================] - 0s 428us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2012 - val_accuracy: 0.9630\n",
      "Epoch 33/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2054 - val_accuracy: 0.9630\n",
      "Epoch 34/150\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2091 - val_accuracy: 0.9444\n",
      "Epoch 35/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2110 - val_accuracy: 0.9444\n",
      "Epoch 36/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2111 - val_accuracy: 0.9630\n",
      "Epoch 37/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9444\n",
      "Epoch 38/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9630\n",
      "Epoch 39/150\n",
      "124/124 [==============================] - 0s 344us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2135 - val_accuracy: 0.9630\n",
      "Epoch 40/150\n",
      "124/124 [==============================] - 0s 465us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9630\n",
      "Epoch 41/150\n",
      "124/124 [==============================] - 0s 685us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9630\n",
      "Epoch 42/150\n",
      "124/124 [==============================] - 0s 621us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2123 - val_accuracy: 0.9630\n",
      "Epoch 43/150\n",
      "124/124 [==============================] - 0s 717us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9630\n",
      "Epoch 44/150\n",
      "124/124 [==============================] - 0s 548us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2157 - val_accuracy: 0.9630\n",
      "Epoch 45/150\n",
      "124/124 [==============================] - 0s 556us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9630\n",
      "Epoch 46/150\n",
      "124/124 [==============================] - 0s 653us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9630\n",
      "Epoch 47/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9630\n",
      "Epoch 48/150\n",
      "124/124 [==============================] - 0s 328us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9630\n",
      "Epoch 49/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9630\n",
      "Epoch 50/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9630\n",
      "Epoch 51/150\n",
      "124/124 [==============================] - 0s 383us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2247 - val_accuracy: 0.9630\n",
      "Epoch 52/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9630\n",
      "Epoch 53/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2252 - val_accuracy: 0.9630\n",
      "Epoch 54/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9630\n",
      "Epoch 55/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2293 - val_accuracy: 0.9630\n",
      "Epoch 56/150\n",
      "124/124 [==============================] - 0s 460us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "124/124 [==============================] - 0s 437us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9630\n",
      "Epoch 58/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9630\n",
      "Epoch 59/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 0.9630\n",
      "Epoch 60/150\n",
      "124/124 [==============================] - 0s 280us/step - loss: 9.8728e-04 - accuracy: 1.0000 - val_loss: 0.2332 - val_accuracy: 0.9630\n",
      "Epoch 61/150\n",
      "124/124 [==============================] - 0s 433us/step - loss: 9.6279e-04 - accuracy: 1.0000 - val_loss: 0.2307 - val_accuracy: 0.9630\n",
      "Epoch 62/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 9.4284e-04 - accuracy: 1.0000 - val_loss: 0.2325 - val_accuracy: 0.9630\n",
      "Epoch 63/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.1985e-04 - accuracy: 1.0000 - val_loss: 0.2331 - val_accuracy: 0.9630\n",
      "Epoch 64/150\n",
      "124/124 [==============================] - 0s 740us/step - loss: 9.0220e-04 - accuracy: 1.0000 - val_loss: 0.2339 - val_accuracy: 0.9630\n",
      "Epoch 65/150\n",
      "124/124 [==============================] - 0s 782us/step - loss: 8.8505e-04 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9630\n",
      "Epoch 66/150\n",
      "124/124 [==============================] - 0s 935us/step - loss: 8.6580e-04 - accuracy: 1.0000 - val_loss: 0.2354 - val_accuracy: 0.9630\n",
      "Epoch 67/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 8.4662e-04 - accuracy: 1.0000 - val_loss: 0.2355 - val_accuracy: 0.9630\n",
      "Epoch 68/150\n",
      "124/124 [==============================] - 0s 742us/step - loss: 8.2483e-04 - accuracy: 1.0000 - val_loss: 0.2359 - val_accuracy: 0.9630\n",
      "Epoch 69/150\n",
      "124/124 [==============================] - 0s 564us/step - loss: 8.0865e-04 - accuracy: 1.0000 - val_loss: 0.2370 - val_accuracy: 0.9630\n",
      "Epoch 70/150\n",
      "124/124 [==============================] - 0s 532us/step - loss: 7.9888e-04 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9630\n",
      "Epoch 71/150\n",
      "124/124 [==============================] - 0s 375us/step - loss: 7.8089e-04 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9630\n",
      "Epoch 72/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.6839e-04 - accuracy: 1.0000 - val_loss: 0.2393 - val_accuracy: 0.9630\n",
      "Epoch 73/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.5095e-04 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9630\n",
      "Epoch 74/150\n",
      "124/124 [==============================] - 0s 502us/step - loss: 7.3994e-04 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9630\n",
      "Epoch 75/150\n",
      "124/124 [==============================] - 0s 442us/step - loss: 7.2994e-04 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9630\n",
      "Epoch 76/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 7.1352e-04 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9630\n",
      "Epoch 77/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 7.0230e-04 - accuracy: 1.0000 - val_loss: 0.2430 - val_accuracy: 0.9630\n",
      "Epoch 78/150\n",
      "124/124 [==============================] - 0s 677us/step - loss: 6.8640e-04 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9630\n",
      "Epoch 79/150\n",
      "124/124 [==============================] - 0s 548us/step - loss: 6.7616e-04 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9630\n",
      "Epoch 80/150\n",
      "124/124 [==============================] - 0s 532us/step - loss: 6.6265e-04 - accuracy: 1.0000 - val_loss: 0.2442 - val_accuracy: 0.9630\n",
      "Epoch 81/150\n",
      "124/124 [==============================] - 0s 685us/step - loss: 6.5388e-04 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9630\n",
      "Epoch 82/150\n",
      "124/124 [==============================] - 0s 930us/step - loss: 6.4184e-04 - accuracy: 1.0000 - val_loss: 0.2447 - val_accuracy: 0.9630\n",
      "Epoch 83/150\n",
      "124/124 [==============================] - 0s 528us/step - loss: 6.2936e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9630\n",
      "Epoch 84/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.2437e-04 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9630\n",
      "Epoch 85/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.1209e-04 - accuracy: 1.0000 - val_loss: 0.2480 - val_accuracy: 0.9630\n",
      "Epoch 86/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.0159e-04 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9630\n",
      "Epoch 87/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.9226e-04 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9630\n",
      "Epoch 88/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.8404e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9630\n",
      "Epoch 89/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.7294e-04 - accuracy: 1.0000 - val_loss: 0.2497 - val_accuracy: 0.9630\n",
      "Epoch 90/150\n",
      "124/124 [==============================] - 0s 432us/step - loss: 5.6473e-04 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9630\n",
      "Epoch 91/150\n",
      "124/124 [==============================] - 0s 575us/step - loss: 5.5836e-04 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9630\n",
      "Epoch 92/150\n",
      "124/124 [==============================] - 0s 838us/step - loss: 5.4883e-04 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9630\n",
      "Epoch 93/150\n",
      "124/124 [==============================] - 0s 621us/step - loss: 5.4127e-04 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9630\n",
      "Epoch 94/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 5.3163e-04 - accuracy: 1.0000 - val_loss: 0.2510 - val_accuracy: 0.9630\n",
      "Epoch 95/150\n",
      "124/124 [==============================] - 0s 522us/step - loss: 5.2343e-04 - accuracy: 1.0000 - val_loss: 0.2515 - val_accuracy: 0.9630\n",
      "Epoch 96/150\n",
      "124/124 [==============================] - 0s 709us/step - loss: 5.1678e-04 - accuracy: 1.0000 - val_loss: 0.2532 - val_accuracy: 0.9630\n",
      "Epoch 97/150\n",
      "124/124 [==============================] - 0s 742us/step - loss: 5.0992e-04 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9630\n",
      "Epoch 98/150\n",
      "124/124 [==============================] - 0s 580us/step - loss: 5.0123e-04 - accuracy: 1.0000 - val_loss: 0.2526 - val_accuracy: 0.9630\n",
      "Epoch 99/150\n",
      "124/124 [==============================] - 0s 548us/step - loss: 4.9310e-04 - accuracy: 1.0000 - val_loss: 0.2521 - val_accuracy: 0.9630\n",
      "Epoch 100/150\n",
      "124/124 [==============================] - 0s 492us/step - loss: 4.8753e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9630\n",
      "Epoch 101/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.8018e-04 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9630\n",
      "Epoch 102/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.7507e-04 - accuracy: 1.0000 - val_loss: 0.2527 - val_accuracy: 0.9630\n",
      "Epoch 103/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.6848e-04 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9630\n",
      "Epoch 104/150\n",
      "124/124 [==============================] - 0s 485us/step - loss: 4.6334e-04 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 0.9630\n",
      "Epoch 105/150\n",
      "124/124 [==============================] - 0s 516us/step - loss: 4.5586e-04 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9630\n",
      "Epoch 106/150\n",
      "124/124 [==============================] - 0s 645us/step - loss: 4.4957e-04 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9630\n",
      "Epoch 107/150\n",
      "124/124 [==============================] - 0s 645us/step - loss: 4.4420e-04 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9630\n",
      "Epoch 108/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.3761e-04 - accuracy: 1.0000 - val_loss: 0.2537 - val_accuracy: 0.9630\n",
      "Epoch 109/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.3235e-04 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9630\n",
      "Epoch 110/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 4.2546e-04 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9630\n",
      "Epoch 111/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.1961e-04 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9630\n",
      "Epoch 112/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.1567e-04 - accuracy: 1.0000 - val_loss: 0.2570 - val_accuracy: 0.9630\n",
      "Epoch 113/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.1182e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9630\n",
      "Epoch 114/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.0639e-04 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9630\n",
      "Epoch 115/150\n",
      "124/124 [==============================] - 0s 472us/step - loss: 4.0187e-04 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9630\n",
      "Epoch 116/150\n",
      "124/124 [==============================] - ETA: 0s - loss: 5.1790e-04 - accuracy: 1.00 - 0s 500us/step - loss: 3.9666e-04 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9630\n",
      "Epoch 117/150\n",
      "124/124 [==============================] - 0s 580us/step - loss: 3.9196e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9630\n",
      "Epoch 118/150\n",
      "124/124 [==============================] - 0s 556us/step - loss: 3.8608e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9630\n",
      "Epoch 119/150\n",
      "124/124 [==============================] - 0s 540us/step - loss: 3.8194e-04 - accuracy: 1.0000 - val_loss: 0.2595 - val_accuracy: 0.9630\n",
      "Epoch 120/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 3.7713e-04 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9630\n",
      "Epoch 121/150\n",
      "124/124 [==============================] - 0s 292us/step - loss: 3.7360e-04 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9630\n",
      "Epoch 122/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.7066e-04 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9630\n",
      "Epoch 123/150\n",
      "124/124 [==============================] - 0s 356us/step - loss: 3.6603e-04 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 0.9630\n",
      "Epoch 124/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.6276e-04 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9630\n",
      "Epoch 125/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.5837e-04 - accuracy: 1.0000 - val_loss: 0.2586 - val_accuracy: 0.9630\n",
      "Epoch 126/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.5346e-04 - accuracy: 1.0000 - val_loss: 0.2583 - val_accuracy: 0.9630\n",
      "Epoch 127/150\n",
      "124/124 [==============================] - 0s 480us/step - loss: 3.4990e-04 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9630\n",
      "Epoch 128/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 3.4451e-04 - accuracy: 1.0000 - val_loss: 0.2601 - val_accuracy: 0.9630\n",
      "Epoch 129/150\n",
      "124/124 [==============================] - 0s 604us/step - loss: 3.4191e-04 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9630\n",
      "Epoch 130/150\n",
      "124/124 [==============================] - 0s 532us/step - loss: 3.3711e-04 - accuracy: 1.0000 - val_loss: 0.2619 - val_accuracy: 0.9630\n",
      "Epoch 131/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 3.3263e-04 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9630\n",
      "Epoch 132/150\n",
      "124/124 [==============================] - 0s 278us/step - loss: 3.2934e-04 - accuracy: 1.0000 - val_loss: 0.2626 - val_accuracy: 0.9630\n",
      "Epoch 133/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 3.2656e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9630\n",
      "Epoch 134/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 3.2343e-04 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9630\n",
      "Epoch 135/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 3.1978e-04 - accuracy: 1.0000 - val_loss: 0.2648 - val_accuracy: 0.9630\n",
      "Epoch 136/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.1801e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9630\n",
      "Epoch 137/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 3.1395e-04 - accuracy: 1.0000 - val_loss: 0.2646 - val_accuracy: 0.9630\n",
      "Epoch 138/150\n",
      "124/124 [==============================] - 0s 407us/step - loss: 3.1082e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9630\n",
      "Epoch 139/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 3.0797e-04 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9630\n",
      "Epoch 140/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 3.0372e-04 - accuracy: 1.0000 - val_loss: 0.2647 - val_accuracy: 0.9630\n",
      "Epoch 141/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 3.0108e-04 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9630\n",
      "Epoch 142/150\n",
      "124/124 [==============================] - 0s 318us/step - loss: 2.9797e-04 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9630\n",
      "Epoch 143/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.9629e-04 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9630\n",
      "Epoch 144/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.9209e-04 - accuracy: 1.0000 - val_loss: 0.2673 - val_accuracy: 0.9630\n",
      "Epoch 145/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.8924e-04 - accuracy: 1.0000 - val_loss: 0.2676 - val_accuracy: 0.9630\n",
      "Epoch 146/150\n",
      "124/124 [==============================] - 0s 446us/step - loss: 2.8664e-04 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9630\n",
      "Epoch 147/150\n",
      "124/124 [==============================] - 0s 516us/step - loss: 2.8401e-04 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9630\n",
      "Epoch 148/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 2.8062e-04 - accuracy: 1.0000 - val_loss: 0.2687 - val_accuracy: 0.9630\n",
      "Epoch 149/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 2.7874e-04 - accuracy: 1.0000 - val_loss: 0.2708 - val_accuracy: 0.9630\n",
      "Epoch 150/150\n",
      "124/124 [==============================] - 0s 364us/step - loss: 2.7608e-04 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9630\n",
      "Test loss: 0.27085594301698385\n",
      "Test accuracy: 0.9629629850387573\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=150,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/250\n",
      "124/124 [==============================] - 1s 9ms/step - loss: 1.0275 - accuracy: 0.4435 - val_loss: 0.6734 - val_accuracy: 0.8889\n",
      "Epoch 2/250\n",
      "124/124 [==============================] - 0s 601us/step - loss: 0.4420 - accuracy: 0.8790 - val_loss: 0.2609 - val_accuracy: 0.9444\n",
      "Epoch 3/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 0.1766 - accuracy: 0.9597 - val_loss: 0.1925 - val_accuracy: 0.8889\n",
      "Epoch 4/250\n",
      "124/124 [==============================] - 0s 334us/step - loss: 0.0893 - accuracy: 0.9839 - val_loss: 0.2240 - val_accuracy: 0.9074\n",
      "Epoch 5/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0574 - accuracy: 0.9919 - val_loss: 0.2394 - val_accuracy: 0.8889\n",
      "Epoch 6/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 0.0421 - accuracy: 0.9919 - val_loss: 0.1772 - val_accuracy: 0.9259\n",
      "Epoch 7/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9074\n",
      "Epoch 8/250\n",
      "124/124 [==============================] - 0s 601us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.1760 - val_accuracy: 0.9074\n",
      "Epoch 9/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.8889\n",
      "Epoch 10/250\n",
      "124/124 [==============================] - 0s 549us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.2319 - val_accuracy: 0.8889\n",
      "Epoch 11/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9074\n",
      "Epoch 12/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2220 - val_accuracy: 0.9074\n",
      "Epoch 13/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9074\n",
      "Epoch 14/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2055 - val_accuracy: 0.9074\n",
      "Epoch 15/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9074\n",
      "Epoch 16/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9074\n",
      "Epoch 17/250\n",
      "124/124 [==============================] - 0s 405us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.2397 - val_accuracy: 0.9074\n",
      "Epoch 18/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2317 - val_accuracy: 0.9074\n",
      "Epoch 19/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2294 - val_accuracy: 0.9074\n",
      "Epoch 20/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2353 - val_accuracy: 0.9074\n",
      "Epoch 21/250\n",
      "124/124 [==============================] - 0s 376us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2367 - val_accuracy: 0.9074\n",
      "Epoch 22/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9074\n",
      "Epoch 23/250\n",
      "124/124 [==============================] - 0s 418us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9074\n",
      "Epoch 24/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9074\n",
      "Epoch 25/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9074\n",
      "Epoch 26/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9074\n",
      "Epoch 27/250\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2523 - val_accuracy: 0.9074\n",
      "Epoch 28/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9074\n",
      "Epoch 29/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2575 - val_accuracy: 0.9074\n",
      "Epoch 30/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2592 - val_accuracy: 0.9074\n",
      "Epoch 31/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2508 - val_accuracy: 0.9074\n",
      "Epoch 32/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9074\n",
      "Epoch 33/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9074\n",
      "Epoch 34/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2681 - val_accuracy: 0.9074\n",
      "Epoch 35/250\n",
      "124/124 [==============================] - 0s 493us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.9074\n",
      "Epoch 36/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2694 - val_accuracy: 0.9074\n",
      "Epoch 37/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2709 - val_accuracy: 0.9074\n",
      "Epoch 38/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2712 - val_accuracy: 0.9074\n",
      "Epoch 39/250\n",
      "124/124 [==============================] - 0s 250us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2726 - val_accuracy: 0.9074\n",
      "Epoch 40/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2750 - val_accuracy: 0.9074\n",
      "Epoch 41/250\n",
      "124/124 [==============================] - 0s 483us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2762 - val_accuracy: 0.9074\n",
      "Epoch 42/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 9.8612e-04 - accuracy: 1.0000 - val_loss: 0.2765 - val_accuracy: 0.9074\n",
      "Epoch 43/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 9.5693e-04 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9074\n",
      "Epoch 44/250\n",
      "124/124 [==============================] - 0s 459us/step - loss: 9.3473e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9074\n",
      "Epoch 45/250\n",
      "124/124 [==============================] - 0s 417us/step - loss: 9.0162e-04 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9074\n",
      "Epoch 46/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 8.7280e-04 - accuracy: 1.0000 - val_loss: 0.2837 - val_accuracy: 0.9074\n",
      "Epoch 47/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 8.4561e-04 - accuracy: 1.0000 - val_loss: 0.2886 - val_accuracy: 0.9074\n",
      "Epoch 48/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 8.2460e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9074\n",
      "Epoch 49/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 8.0056e-04 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9074\n",
      "Epoch 50/250\n",
      "124/124 [==============================] - 0s 259us/step - loss: 7.7762e-04 - accuracy: 1.0000 - val_loss: 0.2895 - val_accuracy: 0.9074\n",
      "Epoch 51/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 7.5424e-04 - accuracy: 1.0000 - val_loss: 0.2902 - val_accuracy: 0.9074\n",
      "Epoch 52/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.3629e-04 - accuracy: 1.0000 - val_loss: 0.2911 - val_accuracy: 0.9074\n",
      "Epoch 53/250\n",
      "124/124 [==============================] - 0s 457us/step - loss: 7.1457e-04 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9074\n",
      "Epoch 54/250\n",
      "124/124 [==============================] - 0s 257us/step - loss: 6.9587e-04 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9074\n",
      "Epoch 55/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.8254e-04 - accuracy: 1.0000 - val_loss: 0.2936 - val_accuracy: 0.9074\n",
      "Epoch 56/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.5880e-04 - accuracy: 1.0000 - val_loss: 0.2960 - val_accuracy: 0.9074\n",
      "Epoch 57/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.4974e-04 - accuracy: 1.0000 - val_loss: 0.2969 - val_accuracy: 0.9074\n",
      "Epoch 58/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.3190e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9074\n",
      "Epoch 59/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.1570e-04 - accuracy: 1.0000 - val_loss: 0.2956 - val_accuracy: 0.9074\n",
      "Epoch 60/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.9748e-04 - accuracy: 1.0000 - val_loss: 0.2943 - val_accuracy: 0.9074\n",
      "Epoch 61/250\n",
      "124/124 [==============================] - 0s 528us/step - loss: 5.8385e-04 - accuracy: 1.0000 - val_loss: 0.2958 - val_accuracy: 0.9074\n",
      "Epoch 62/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 5.7200e-04 - accuracy: 1.0000 - val_loss: 0.2981 - val_accuracy: 0.9074\n",
      "Epoch 63/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 5.5878e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9074\n",
      "Epoch 64/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 5.4951e-04 - accuracy: 1.0000 - val_loss: 0.3008 - val_accuracy: 0.9074\n",
      "Epoch 65/250\n",
      "124/124 [==============================] - 0s 496us/step - loss: 5.3403e-04 - accuracy: 1.0000 - val_loss: 0.3021 - val_accuracy: 0.9074\n",
      "Epoch 66/250\n",
      "124/124 [==============================] - ETA: 0s - loss: 5.6565e-04 - accuracy: 1.00 - 0s 492us/step - loss: 5.2574e-04 - accuracy: 1.0000 - val_loss: 0.3033 - val_accuracy: 0.9074\n",
      "Epoch 67/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 5.1356e-04 - accuracy: 1.0000 - val_loss: 0.3044 - val_accuracy: 0.9074\n",
      "Epoch 68/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 5.0365e-04 - accuracy: 1.0000 - val_loss: 0.3057 - val_accuracy: 0.9074\n",
      "Epoch 69/250\n",
      "124/124 [==============================] - 0s 266us/step - loss: 4.9444e-04 - accuracy: 1.0000 - val_loss: 0.3023 - val_accuracy: 0.9074\n",
      "Epoch 70/250\n",
      "124/124 [==============================] - 0s 591us/step - loss: 4.8449e-04 - accuracy: 1.0000 - val_loss: 0.3054 - val_accuracy: 0.9074\n",
      "Epoch 71/250\n",
      "124/124 [==============================] - 0s 860us/step - loss: 4.7431e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9074\n",
      "Epoch 72/250\n",
      "124/124 [==============================] - 0s 507us/step - loss: 4.6405e-04 - accuracy: 1.0000 - val_loss: 0.3083 - val_accuracy: 0.9074\n",
      "Epoch 73/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 4.5622e-04 - accuracy: 1.0000 - val_loss: 0.3090 - val_accuracy: 0.9074\n",
      "Epoch 74/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 4.4841e-04 - accuracy: 1.0000 - val_loss: 0.3068 - val_accuracy: 0.9074\n",
      "Epoch 75/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 4.4096e-04 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9074\n",
      "Epoch 76/250\n",
      "124/124 [==============================] - 0s 728us/step - loss: 4.3025e-04 - accuracy: 1.0000 - val_loss: 0.3077 - val_accuracy: 0.9074\n",
      "Epoch 77/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 4.2477e-04 - accuracy: 1.0000 - val_loss: 0.3098 - val_accuracy: 0.9074\n",
      "Epoch 78/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 4.1759e-04 - accuracy: 1.0000 - val_loss: 0.3112 - val_accuracy: 0.9074\n",
      "Epoch 79/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 4.0967e-04 - accuracy: 1.0000 - val_loss: 0.3119 - val_accuracy: 0.9074\n",
      "Epoch 80/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 4.0315e-04 - accuracy: 1.0000 - val_loss: 0.3136 - val_accuracy: 0.9074\n",
      "Epoch 81/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 3.9649e-04 - accuracy: 1.0000 - val_loss: 0.3147 - val_accuracy: 0.9074\n",
      "Epoch 82/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 3.9131e-04 - accuracy: 1.0000 - val_loss: 0.3175 - val_accuracy: 0.9074\n",
      "Epoch 83/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 3.8293e-04 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9074\n",
      "Epoch 84/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 3.7719e-04 - accuracy: 1.0000 - val_loss: 0.3202 - val_accuracy: 0.9074\n",
      "Epoch 85/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 3.7048e-04 - accuracy: 1.0000 - val_loss: 0.3201 - val_accuracy: 0.9074\n",
      "Epoch 86/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 3.6471e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9074\n",
      "Epoch 87/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 3.5771e-04 - accuracy: 1.0000 - val_loss: 0.3212 - val_accuracy: 0.9074\n",
      "Epoch 88/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 3.5339e-04 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 0.9074\n",
      "Epoch 89/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 3.4880e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9074\n",
      "Epoch 90/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 3.4339e-04 - accuracy: 1.0000 - val_loss: 0.3225 - val_accuracy: 0.9074\n",
      "Epoch 91/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 3.3907e-04 - accuracy: 1.0000 - val_loss: 0.3229 - val_accuracy: 0.9074\n",
      "Epoch 92/250\n",
      "124/124 [==============================] - 0s 529us/step - loss: 3.3471e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.9074\n",
      "Epoch 93/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 3.2867e-04 - accuracy: 1.0000 - val_loss: 0.3238 - val_accuracy: 0.9074\n",
      "Epoch 94/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 3.2347e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9074\n",
      "Epoch 95/250\n",
      "124/124 [==============================] - 0s 838us/step - loss: 3.1954e-04 - accuracy: 1.0000 - val_loss: 0.3269 - val_accuracy: 0.9074\n",
      "Epoch 96/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 3.1463e-04 - accuracy: 1.0000 - val_loss: 0.3263 - val_accuracy: 0.9074\n",
      "Epoch 97/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 3.1017e-04 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9074\n",
      "Epoch 98/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 3.0635e-04 - accuracy: 1.0000 - val_loss: 0.3272 - val_accuracy: 0.9074\n",
      "Epoch 99/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 3.0119e-04 - accuracy: 1.0000 - val_loss: 0.3280 - val_accuracy: 0.9074\n",
      "Epoch 100/250\n",
      "124/124 [==============================] - 0s 798us/step - loss: 2.9786e-04 - accuracy: 1.0000 - val_loss: 0.3289 - val_accuracy: 0.9074\n",
      "Epoch 101/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.9355e-04 - accuracy: 1.0000 - val_loss: 0.3293 - val_accuracy: 0.9074\n",
      "Epoch 102/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 2.9034e-04 - accuracy: 1.0000 - val_loss: 0.3298 - val_accuracy: 0.9074\n",
      "Epoch 103/250\n",
      "124/124 [==============================] - 0s 705us/step - loss: 2.8691e-04 - accuracy: 1.0000 - val_loss: 0.3301 - val_accuracy: 0.9074\n",
      "Epoch 104/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 2.8293e-04 - accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9074\n",
      "Epoch 105/250\n",
      "124/124 [==============================] - 0s 778us/step - loss: 2.7948e-04 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9074\n",
      "Epoch 106/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 2.7680e-04 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9074\n",
      "Epoch 107/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 2.7245e-04 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9074\n",
      "Epoch 108/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 2.6919e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.8889\n",
      "Epoch 109/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 2.6605e-04 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.8889\n",
      "Epoch 110/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 532us/step - loss: 2.6328e-04 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.8889\n",
      "Epoch 111/250\n",
      "124/124 [==============================] - 0s 927us/step - loss: 2.5999e-04 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.8889\n",
      "Epoch 112/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 2.5634e-04 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.8889\n",
      "Epoch 113/250\n",
      "124/124 [==============================] - 0s 798us/step - loss: 2.5336e-04 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.8889\n",
      "Epoch 114/250\n",
      "124/124 [==============================] - 0s 870us/step - loss: 2.5005e-04 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.8889\n",
      "Epoch 115/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 2.4768e-04 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.8889\n",
      "Epoch 116/250\n",
      "124/124 [==============================] - 0s 559us/step - loss: 2.4475e-04 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.8889\n",
      "Epoch 117/250\n",
      "124/124 [==============================] - 0s 661us/step - loss: 2.4234e-04 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.8889\n",
      "Epoch 118/250\n",
      "124/124 [==============================] - 0s 911us/step - loss: 2.3895e-04 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.8889\n",
      "Epoch 119/250\n",
      "124/124 [==============================] - 0s 919us/step - loss: 2.3640e-04 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9074\n",
      "Epoch 120/250\n",
      "124/124 [==============================] - 0s 814us/step - loss: 2.3392e-04 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9074\n",
      "Epoch 121/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 2.3128e-04 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.8889\n",
      "Epoch 122/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 2.2829e-04 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.8889\n",
      "Epoch 123/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 2.2667e-04 - accuracy: 1.0000 - val_loss: 0.3420 - val_accuracy: 0.8889\n",
      "Epoch 124/250\n",
      "124/124 [==============================] - 0s 854us/step - loss: 2.2434e-04 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.8889\n",
      "Epoch 125/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 2.2131e-04 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.8889\n",
      "Epoch 126/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 2.1923e-04 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.8889\n",
      "Epoch 127/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 2.1689e-04 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.8889\n",
      "Epoch 128/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 2.1514e-04 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.8889\n",
      "Epoch 129/250\n",
      "124/124 [==============================] - 0s 661us/step - loss: 2.1255e-04 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.8889\n",
      "Epoch 130/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 2.1075e-04 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.8889\n",
      "Epoch 131/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 2.0837e-04 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.8889\n",
      "Epoch 132/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 2.0666e-04 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.8889\n",
      "Epoch 133/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 2.0438e-04 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.8889\n",
      "Epoch 134/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 2.0256e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.8889\n",
      "Epoch 135/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 2.0040e-04 - accuracy: 1.0000 - val_loss: 0.3481 - val_accuracy: 0.8889\n",
      "Epoch 136/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 1.9841e-04 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.8889\n",
      "Epoch 137/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 1.9646e-04 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.8889\n",
      "Epoch 138/250\n",
      "124/124 [==============================] - 0s 822us/step - loss: 1.9459e-04 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.8889\n",
      "Epoch 139/250\n",
      "124/124 [==============================] - ETA: 0s - loss: 8.4035e-05 - accuracy: 1.00 - 0s 580us/step - loss: 1.9286e-04 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.8889\n",
      "Epoch 140/250\n",
      "124/124 [==============================] - 0s 806us/step - loss: 1.9082e-04 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.8889\n",
      "Epoch 141/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 1.8938e-04 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.8889\n",
      "Epoch 142/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 1.8728e-04 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.8889\n",
      "Epoch 143/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.8562e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.8889\n",
      "Epoch 144/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.8417e-04 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.8889\n",
      "Epoch 145/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 1.8208e-04 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.8889\n",
      "Epoch 146/250\n",
      "124/124 [==============================] - 0s 701us/step - loss: 1.8079e-04 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.8889\n",
      "Epoch 147/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 1.7909e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.8889\n",
      "Epoch 148/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.7774e-04 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.8889\n",
      "Epoch 149/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.7590e-04 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.8889\n",
      "Epoch 150/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.7480e-04 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.8889\n",
      "Epoch 151/250\n",
      "124/124 [==============================] - 0s 911us/step - loss: 1.7342e-04 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.8889\n",
      "Epoch 152/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 1.7164e-04 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.8889\n",
      "Epoch 153/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.7048e-04 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.8889\n",
      "Epoch 154/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 1.6931e-04 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.8889\n",
      "Epoch 155/250\n",
      "124/124 [==============================] - 0s 822us/step - loss: 1.6790e-04 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.8889\n",
      "Epoch 156/250\n",
      "124/124 [==============================] - 0s 814us/step - loss: 1.6616e-04 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.8889\n",
      "Epoch 157/250\n",
      "124/124 [==============================] - 0s 927us/step - loss: 1.6477e-04 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.8889\n",
      "Epoch 158/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 1.6386e-04 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.8889\n",
      "Epoch 159/250\n",
      "124/124 [==============================] - 0s 822us/step - loss: 1.6223e-04 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.8889\n",
      "Epoch 160/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 1.6088e-04 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.8889\n",
      "Epoch 161/250\n",
      "124/124 [==============================] - 0s 838us/step - loss: 1.5985e-04 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.8889\n",
      "Epoch 162/250\n",
      "124/124 [==============================] - 0s 596us/step - loss: 1.5846e-04 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.8889\n",
      "Epoch 163/250\n",
      "124/124 [==============================] - 0s 967us/step - loss: 1.5705e-04 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.8889\n",
      "Epoch 164/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 879us/step - loss: 1.5591e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.8889\n",
      "Epoch 165/250\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.8411e-04 - accuracy: 1.00 - 0s 516us/step - loss: 1.5465e-04 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.8889\n",
      "Epoch 166/250\n",
      "124/124 [==============================] - 0s 919us/step - loss: 1.5374e-04 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.8889\n",
      "Epoch 167/250\n",
      "124/124 [==============================] - 0s 541us/step - loss: 1.5211e-04 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.8889\n",
      "Epoch 168/250\n",
      "124/124 [==============================] - 0s 712us/step - loss: 1.5107e-04 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.8889\n",
      "Epoch 169/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 1.4986e-04 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.8889\n",
      "Epoch 170/250\n",
      "124/124 [==============================] - 0s 786us/step - loss: 1.4859e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.8889\n",
      "Epoch 171/250\n",
      "124/124 [==============================] - 0s 611us/step - loss: 1.4720e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.8889\n",
      "Epoch 172/250\n",
      "124/124 [==============================] - 0s 887us/step - loss: 1.4614e-04 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.8889\n",
      "Epoch 173/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 1.4516e-04 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.8889\n",
      "Epoch 174/250\n",
      "124/124 [==============================] - 0s 751us/step - loss: 1.4384e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.8889\n",
      "Epoch 175/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 1.4283e-04 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.8889\n",
      "Epoch 176/250\n",
      "124/124 [==============================] - 0s 652us/step - loss: 1.4178e-04 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.8889\n",
      "Epoch 177/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.4049e-04 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.8889\n",
      "Epoch 178/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 1.3958e-04 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.8889\n",
      "Epoch 179/250\n",
      "124/124 [==============================] - 0s 677us/step - loss: 1.3907e-04 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.8889\n",
      "Epoch 180/250\n",
      "124/124 [==============================] - 0s 846us/step - loss: 1.3766e-04 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.8889\n",
      "Epoch 181/250\n",
      "124/124 [==============================] - 0s 903us/step - loss: 1.3695e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.8889\n",
      "Epoch 182/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 1.3557e-04 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.8889\n",
      "Epoch 183/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 1.3511e-04 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.8889\n",
      "Epoch 184/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 1.3391e-04 - accuracy: 1.0000 - val_loss: 0.3660 - val_accuracy: 0.8889\n",
      "Epoch 185/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 1.3296e-04 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.8889\n",
      "Epoch 186/250\n",
      "124/124 [==============================] - 0s 838us/step - loss: 1.3186e-04 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.8889\n",
      "Epoch 187/250\n",
      "124/124 [==============================] - 0s 862us/step - loss: 1.3088e-04 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.8889\n",
      "Epoch 188/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 1.3019e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.8889\n",
      "Epoch 189/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.2939e-04 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.8889\n",
      "Epoch 190/250\n",
      "124/124 [==============================] - 0s 717us/step - loss: 1.2824e-04 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.8889\n",
      "Epoch 191/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 1.2765e-04 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.8889\n",
      "Epoch 192/250\n",
      "124/124 [==============================] - 0s 814us/step - loss: 1.2684e-04 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.8889\n",
      "Epoch 193/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 1.2610e-04 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.8889\n",
      "Epoch 194/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 1.2514e-04 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.8889\n",
      "Epoch 195/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.2419e-04 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8889\n",
      "Epoch 196/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.2329e-04 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.8889\n",
      "Epoch 197/250\n",
      "124/124 [==============================] - 0s 677us/step - loss: 1.2249e-04 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.8889\n",
      "Epoch 198/250\n",
      "124/124 [==============================] - 0s 721us/step - loss: 1.2174e-04 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.8889\n",
      "Epoch 199/250\n",
      "124/124 [==============================] - 0s 830us/step - loss: 1.2101e-04 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.8889\n",
      "Epoch 200/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 1.2028e-04 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.8889\n",
      "Epoch 201/250\n",
      "124/124 [==============================] - 0s 919us/step - loss: 1.1929e-04 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.8889\n",
      "Epoch 202/250\n",
      "124/124 [==============================] - 0s 605us/step - loss: 1.1899e-04 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.8889\n",
      "Epoch 203/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 1.1792e-04 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.8889\n",
      "Epoch 204/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 1.1721e-04 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.8889\n",
      "Epoch 205/250\n",
      "124/124 [==============================] - 0s 735us/step - loss: 1.1670e-04 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.8889\n",
      "Epoch 206/250\n",
      "124/124 [==============================] - 0s 799us/step - loss: 1.1591e-04 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.8889\n",
      "Epoch 207/250\n",
      "124/124 [==============================] - 0s 870us/step - loss: 1.1529e-04 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.8889\n",
      "Epoch 208/250\n",
      "124/124 [==============================] - 0s 766us/step - loss: 1.1440e-04 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.8889\n",
      "Epoch 209/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 1.1370e-04 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.8889\n",
      "Epoch 210/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.1324e-04 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.8889\n",
      "Epoch 211/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 1.1246e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.8889\n",
      "Epoch 212/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.1174e-04 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.8889\n",
      "Epoch 213/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 1.1109e-04 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.8889\n",
      "Epoch 214/250\n",
      "124/124 [==============================] - 0s 661us/step - loss: 1.1048e-04 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.8889\n",
      "Epoch 215/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 1.1007e-04 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.8889\n",
      "Epoch 216/250\n",
      "124/124 [==============================] - 0s 862us/step - loss: 1.0925e-04 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.8889\n",
      "Epoch 217/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 1.0848e-04 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.8889\n",
      "Epoch 218/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 822us/step - loss: 1.0796e-04 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.8889\n",
      "Epoch 219/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 1.0725e-04 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.8889\n",
      "Epoch 220/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 1.0681e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8889\n",
      "Epoch 221/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 1.0620e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8889\n",
      "Epoch 222/250\n",
      "124/124 [==============================] - 0s 862us/step - loss: 1.0572e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.8889\n",
      "Epoch 223/250\n",
      "124/124 [==============================] - 0s 812us/step - loss: 1.0504e-04 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.8889\n",
      "Epoch 224/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 1.0459e-04 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.8889\n",
      "Epoch 225/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 1.0401e-04 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.8889\n",
      "Epoch 226/250\n",
      "124/124 [==============================] - 0s 790us/step - loss: 1.0336e-04 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.8889\n",
      "Epoch 227/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.0266e-04 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.8889\n",
      "Epoch 228/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 1.0218e-04 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.8889\n",
      "Epoch 229/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.0160e-04 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.8889\n",
      "Epoch 230/250\n",
      "124/124 [==============================] - 0s 733us/step - loss: 1.0117e-04 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.8889\n",
      "Epoch 231/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.8889\n",
      "Epoch 232/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 9.9847e-05 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.8889\n",
      "Epoch 233/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 9.9325e-05 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.8889\n",
      "Epoch 234/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 9.8854e-05 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.8889\n",
      "Epoch 235/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 9.8366e-05 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.8889\n",
      "Epoch 236/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 9.7623e-05 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.8889\n",
      "Epoch 237/250\n",
      "124/124 [==============================] - 0s 690us/step - loss: 9.7400e-05 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.8889\n",
      "Epoch 238/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 9.6700e-05 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.8889\n",
      "Epoch 239/250\n",
      "124/124 [==============================] - 0s 895us/step - loss: 9.6221e-05 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.8889\n",
      "Epoch 240/250\n",
      "124/124 [==============================] - 0s 967us/step - loss: 9.5701e-05 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.8889\n",
      "Epoch 241/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 9.5154e-05 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.8889\n",
      "Epoch 242/250\n",
      "124/124 [==============================] - 0s 494us/step - loss: 9.4765e-05 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.8889\n",
      "Epoch 243/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 9.4270e-05 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.8889\n",
      "Epoch 244/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 9.3662e-05 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.8889\n",
      "Epoch 245/250\n",
      "124/124 [==============================] - 0s 717us/step - loss: 9.3214e-05 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.8889\n",
      "Epoch 246/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 9.2668e-05 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.8889\n",
      "Epoch 247/250\n",
      "124/124 [==============================] - 0s 806us/step - loss: 9.2273e-05 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.8889\n",
      "Epoch 248/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 9.1713e-05 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.8889\n",
      "Epoch 249/250\n",
      "124/124 [==============================] - 0s 692us/step - loss: 9.1452e-05 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.8889\n",
      "Epoch 250/250\n",
      "124/124 [==============================] - 0s 782us/step - loss: 9.0871e-05 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.8889\n",
      "Test loss: 0.38395650684833527\n",
      "Test accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adagrad',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=250,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
