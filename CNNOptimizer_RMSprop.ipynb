{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/25\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 1.0758 - accuracy: 0.4919 - val_loss: 1.0206 - val_accuracy: 0.8704\n",
      "Epoch 2/25\n",
      "124/124 [==============================] - 0s 495us/step - loss: 0.9645 - accuracy: 0.7823 - val_loss: 0.8721 - val_accuracy: 0.8889\n",
      "Epoch 3/25\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.7730 - accuracy: 0.8871 - val_loss: 0.6546 - val_accuracy: 0.9074\n",
      "Epoch 4/25\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.5315 - accuracy: 0.9274 - val_loss: 0.4971 - val_accuracy: 0.8333\n",
      "Epoch 5/25\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.3532 - accuracy: 0.9194 - val_loss: 0.3202 - val_accuracy: 0.8704\n",
      "Epoch 6/25\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.2119 - accuracy: 0.9677 - val_loss: 0.3493 - val_accuracy: 0.8704\n",
      "Epoch 7/25\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.1806 - accuracy: 0.9516 - val_loss: 0.2071 - val_accuracy: 0.9444\n",
      "Epoch 8/25\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.86 - 0s 427us/step - loss: 0.1198 - accuracy: 0.9677 - val_loss: 0.2413 - val_accuracy: 0.8889\n",
      "Epoch 9/25\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0989 - accuracy: 0.9758 - val_loss: 0.2296 - val_accuracy: 0.8889\n",
      "Epoch 10/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0863 - accuracy: 0.9839 - val_loss: 0.1810 - val_accuracy: 0.9074\n",
      "Epoch 11/25\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0645 - accuracy: 0.9839 - val_loss: 0.1654 - val_accuracy: 0.9444\n",
      "Epoch 12/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0464 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9074\n",
      "Epoch 13/25\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0599 - accuracy: 0.9758 - val_loss: 0.1693 - val_accuracy: 0.9444\n",
      "Epoch 14/25\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0398 - accuracy: 0.9839 - val_loss: 0.2303 - val_accuracy: 0.8889\n",
      "Epoch 15/25\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.1757 - val_accuracy: 0.9630\n",
      "Epoch 16/25\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.0267 - accuracy: 0.9919 - val_loss: 0.1947 - val_accuracy: 0.9259\n",
      "Epoch 17/25\n",
      "124/124 [==============================] - 0s 475us/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 0.2076 - val_accuracy: 0.9074\n",
      "Epoch 18/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.2925 - val_accuracy: 0.8889\n",
      "Epoch 19/25\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9259\n",
      "Epoch 20/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9444\n",
      "Epoch 21/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2337 - val_accuracy: 0.9259\n",
      "Epoch 22/25\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9074\n",
      "Epoch 23/25\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2677 - val_accuracy: 0.9259\n",
      "Epoch 24/25\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2938 - val_accuracy: 0.9259\n",
      "Epoch 25/25\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9259\n",
      "Test loss: 0.2833907642850169\n",
      "Test accuracy: 0.9259259104728699\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='RMSprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['loss'])\n",
    "plt.plot(training_model.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['accuracy'])\n",
    "plt.plot(training_model.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 1.0638 - accuracy: 0.4758 - val_loss: 0.9803 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 565us/step - loss: 0.8995 - accuracy: 0.6129 - val_loss: 0.7676 - val_accuracy: 0.7593\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.6585 - accuracy: 0.8871 - val_loss: 0.5364 - val_accuracy: 0.9444\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.4469 - accuracy: 0.9113 - val_loss: 0.3768 - val_accuracy: 0.8704\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 406us/step - loss: 0.2849 - accuracy: 0.9597 - val_loss: 0.2725 - val_accuracy: 0.9444\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2030 - accuracy: 0.9516 - val_loss: 0.2428 - val_accuracy: 0.9074\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 366us/step - loss: 0.1433 - accuracy: 0.9597 - val_loss: 0.2026 - val_accuracy: 0.9444\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.1357 - accuracy: 0.9597 - val_loss: 0.1988 - val_accuracy: 0.9074\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0899 - accuracy: 0.9758 - val_loss: 0.1716 - val_accuracy: 0.9259\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.0928 - accuracy: 0.9677 - val_loss: 0.2582 - val_accuracy: 0.9074\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 391us/step - loss: 0.0632 - accuracy: 0.9919 - val_loss: 0.1718 - val_accuracy: 0.9444\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0714 - accuracy: 0.9839 - val_loss: 0.1937 - val_accuracy: 0.9074\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 365us/step - loss: 0.0402 - accuracy: 0.9919 - val_loss: 0.1864 - val_accuracy: 0.9444\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.3186 - val_accuracy: 0.9074\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.0346 - accuracy: 0.9839 - val_loss: 0.2803 - val_accuracy: 0.9074\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 370us/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9074\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.8704\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2256 - val_accuracy: 0.9259\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8889\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 349us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9259\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9074\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2542 - val_accuracy: 0.9074\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9074\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3002 - val_accuracy: 0.9074\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3092 - val_accuracy: 0.9259\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3067 - val_accuracy: 0.9074\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 9.6738e-04 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9074\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 427us/step - loss: 8.2763e-04 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.8889\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 390us/step - loss: 5.1878e-04 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9074\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 269us/step - loss: 4.1084e-04 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9074\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 527us/step - loss: 1.8258e-04 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9259\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 7.0111e-04 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.9074\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0562e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9074\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 6.6916e-05 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8889\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 6.6578e-05 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8889\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 4.0380e-05 - accuracy: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.9074\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 2.9440e-05 - accuracy: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.9074\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 3.0648e-05 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9074\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.4163e-05 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.9259\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.4436e-05 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9074\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 350us/step - loss: 7.6229e-06 - accuracy: 1.0000 - val_loss: 0.5380 - val_accuracy: 0.8889\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 371us/step - loss: 4.8218e-06 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.8889\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 3.4961e-06 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.9074\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 3.2062e-06 - accuracy: 1.0000 - val_loss: 0.6442 - val_accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1513e-05 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.8889\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 8.4889e-07 - accuracy: 1.0000 - val_loss: 0.6279 - val_accuracy: 0.8889\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 8.4841e-07 - accuracy: 1.0000 - val_loss: 0.6155 - val_accuracy: 0.8889\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 419us/step - loss: 5.7249e-07 - accuracy: 1.0000 - val_loss: 0.6336 - val_accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 5.2971e-07 - accuracy: 1.0000 - val_loss: 0.6075 - val_accuracy: 0.8889\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 3.9945e-07 - accuracy: 1.0000 - val_loss: 0.6363 - val_accuracy: 0.8889\n",
      "Test loss: 0.6362886917259958\n",
      "Test accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='RMSprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/150\n",
      "124/124 [==============================] - 4s 32ms/step - loss: 1.0727 - accuracy: 0.3790 - val_loss: 1.0201 - val_accuracy: 0.8704\n",
      "Epoch 2/150\n",
      "124/124 [==============================] - 0s 830us/step - loss: 0.9510 - accuracy: 0.7903 - val_loss: 0.8288 - val_accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "124/124 [==============================] - 0s 613us/step - loss: 0.7114 - accuracy: 0.7742 - val_loss: 0.6315 - val_accuracy: 0.7778\n",
      "Epoch 4/150\n",
      "124/124 [==============================] - 0s 924us/step - loss: 0.4659 - accuracy: 0.8710 - val_loss: 0.4926 - val_accuracy: 0.8704\n",
      "Epoch 5/150\n",
      "124/124 [==============================] - 0s 613us/step - loss: 0.3324 - accuracy: 0.9274 - val_loss: 0.3459 - val_accuracy: 0.8889\n",
      "Epoch 6/150\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.95 - 0s 782us/step - loss: 0.2130 - accuracy: 0.9516 - val_loss: 0.3144 - val_accuracy: 0.9074\n",
      "Epoch 7/150\n",
      "124/124 [==============================] - 0s 645us/step - loss: 0.1499 - accuracy: 0.9839 - val_loss: 0.2477 - val_accuracy: 0.8704\n",
      "Epoch 8/150\n",
      "124/124 [==============================] - 0s 587us/step - loss: 0.1044 - accuracy: 0.9919 - val_loss: 0.2383 - val_accuracy: 0.9074\n",
      "Epoch 9/150\n",
      "124/124 [==============================] - 0s 540us/step - loss: 0.0771 - accuracy: 0.9758 - val_loss: 0.3754 - val_accuracy: 0.8889\n",
      "Epoch 10/150\n",
      "124/124 [==============================] - 0s 703us/step - loss: 0.0797 - accuracy: 0.9758 - val_loss: 0.2934 - val_accuracy: 0.9074\n",
      "Epoch 11/150\n",
      "124/124 [==============================] - 0s 596us/step - loss: 0.0515 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.8889\n",
      "Epoch 12/150\n",
      "124/124 [==============================] - 0s 766us/step - loss: 0.0404 - accuracy: 0.9919 - val_loss: 0.2633 - val_accuracy: 0.8889\n",
      "Epoch 13/150\n",
      "124/124 [==============================] - 0s 827us/step - loss: 0.0337 - accuracy: 0.9919 - val_loss: 0.2863 - val_accuracy: 0.8889\n",
      "Epoch 14/150\n",
      "124/124 [==============================] - 0s 993us/step - loss: 0.0295 - accuracy: 0.9839 - val_loss: 0.2590 - val_accuracy: 0.8889\n",
      "Epoch 15/150\n",
      "124/124 [==============================] - 0s 838us/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.2754 - val_accuracy: 0.9074\n",
      "Epoch 16/150\n",
      "124/124 [==============================] - 0s 822us/step - loss: 0.0214 - accuracy: 0.9919 - val_loss: 0.3201 - val_accuracy: 0.8889\n",
      "Epoch 17/150\n",
      "124/124 [==============================] - 0s 782us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9074\n",
      "Epoch 18/150\n",
      "124/124 [==============================] - 0s 572us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.8889\n",
      "Epoch 19/150\n",
      "124/124 [==============================] - 0s 661us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.8704\n",
      "Epoch 20/150\n",
      "124/124 [==============================] - 0s 677us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.8704\n",
      "Epoch 21/150\n",
      "124/124 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.8519\n",
      "Epoch 22/150\n",
      "124/124 [==============================] - 0s 439us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.8519\n",
      "Epoch 23/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5614 - val_accuracy: 0.8889\n",
      "Epoch 24/150\n",
      "124/124 [==============================] - 0s 587us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.8704\n",
      "Epoch 25/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 8.6494e-04 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.8889\n",
      "Epoch 26/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.1268e-04 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.8889\n",
      "Epoch 27/150\n",
      "124/124 [==============================] - 0s 630us/step - loss: 7.3248e-04 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9074\n",
      "Epoch 28/150\n",
      "124/124 [==============================] - 0s 679us/step - loss: 4.0333e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.8889\n",
      "Epoch 29/150\n",
      "124/124 [==============================] - 0s 714us/step - loss: 2.7148e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.8519\n",
      "Epoch 30/150\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.5567e-04 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.8889\n",
      "Epoch 31/150\n",
      "124/124 [==============================] - 0s 637us/step - loss: 1.3695e-04 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.8889\n",
      "Epoch 32/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 9.4804e-05 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.8889\n",
      "Epoch 33/150\n",
      "124/124 [==============================] - 0s 714us/step - loss: 4.9804e-05 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.8519\n",
      "Epoch 34/150\n",
      "124/124 [==============================] - 0s 558us/step - loss: 3.6012e-05 - accuracy: 1.0000 - val_loss: 0.6520 - val_accuracy: 0.8704\n",
      "Epoch 35/150\n",
      "124/124 [==============================] - 0s 779us/step - loss: 1.0891e-04 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.8704\n",
      "Epoch 36/150\n",
      "124/124 [==============================] - 0s 684us/step - loss: 1.1343e-05 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.8704\n",
      "Epoch 37/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 8.7905e-06 - accuracy: 1.0000 - val_loss: 0.6259 - val_accuracy: 0.8704\n",
      "Epoch 38/150\n",
      "124/124 [==============================] - 0s 774us/step - loss: 7.5286e-06 - accuracy: 1.0000 - val_loss: 0.6283 - val_accuracy: 0.8704\n",
      "Epoch 39/150\n",
      "124/124 [==============================] - 0s 519us/step - loss: 5.9990e-06 - accuracy: 1.0000 - val_loss: 0.6435 - val_accuracy: 0.8704\n",
      "Epoch 40/150\n",
      "124/124 [==============================] - 0s 669us/step - loss: 5.1088e-06 - accuracy: 1.0000 - val_loss: 0.6750 - val_accuracy: 0.8704\n",
      "Epoch 41/150\n",
      "124/124 [==============================] - 0s 613us/step - loss: 3.1687e-06 - accuracy: 1.0000 - val_loss: 0.6740 - val_accuracy: 0.8704\n",
      "Epoch 42/150\n",
      "124/124 [==============================] - 0s 822us/step - loss: 2.1597e-06 - accuracy: 1.0000 - val_loss: 0.6670 - val_accuracy: 0.8519\n",
      "Epoch 43/150\n",
      "124/124 [==============================] - 0s 621us/step - loss: 1.8843e-06 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.8704\n",
      "Epoch 44/150\n",
      "124/124 [==============================] - 0s 588us/step - loss: 1.0854e-06 - accuracy: 1.0000 - val_loss: 0.7210 - val_accuracy: 0.8704\n",
      "Epoch 45/150\n",
      "124/124 [==============================] - 0s 620us/step - loss: 6.6767e-07 - accuracy: 1.0000 - val_loss: 0.7431 - val_accuracy: 0.8704\n",
      "Epoch 46/150\n",
      "124/124 [==============================] - 0s 442us/step - loss: 1.0171e-06 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.8519\n",
      "Epoch 47/150\n",
      "124/124 [==============================] - 0s 860us/step - loss: 7.2968e-07 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.8519\n",
      "Epoch 48/150\n",
      "124/124 [==============================] - 0s 762us/step - loss: 3.3359e-07 - accuracy: 1.0000 - val_loss: 0.8225 - val_accuracy: 0.8519\n",
      "Epoch 49/150\n",
      "124/124 [==============================] - 0s 790us/step - loss: 2.1631e-07 - accuracy: 1.0000 - val_loss: 0.8489 - val_accuracy: 0.8519\n",
      "Epoch 50/150\n",
      "124/124 [==============================] - 0s 725us/step - loss: 2.3073e-07 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.8519\n",
      "Epoch 51/150\n",
      "124/124 [==============================] - 0s 959us/step - loss: 2.2592e-07 - accuracy: 1.0000 - val_loss: 0.8707 - val_accuracy: 0.8519\n",
      "Epoch 52/150\n",
      "124/124 [==============================] - 0s 669us/step - loss: 1.9516e-07 - accuracy: 1.0000 - val_loss: 0.8445 - val_accuracy: 0.8889\n",
      "Epoch 53/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 3.1148e-07 - accuracy: 1.0000 - val_loss: 0.8048 - val_accuracy: 0.8889\n",
      "Epoch 54/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.6343e-07 - accuracy: 1.0000 - val_loss: 0.9123 - val_accuracy: 0.8519\n",
      "Epoch 55/150\n",
      "124/124 [==============================] - 0s 698us/step - loss: 1.2738e-07 - accuracy: 1.0000 - val_loss: 0.9300 - val_accuracy: 0.8519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.2354e-07 - accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 0.8519\n",
      "Epoch 57/150\n",
      "124/124 [==============================] - 0s 604us/step - loss: 1.2209e-07 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.8519\n",
      "Epoch 58/150\n",
      "124/124 [==============================] - 0s 822us/step - loss: 1.2257e-07 - accuracy: 1.0000 - val_loss: 0.9596 - val_accuracy: 0.8519\n",
      "Epoch 59/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 0.9566 - val_accuracy: 0.8519\n",
      "Epoch 60/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.2354e-07 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.8519\n",
      "Epoch 61/150\n",
      "124/124 [==============================] - 0s 806us/step - loss: 1.2594e-07 - accuracy: 1.0000 - val_loss: 0.9455 - val_accuracy: 0.8889\n",
      "Epoch 62/150\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.8704\n",
      "Epoch 63/150\n",
      "124/124 [==============================] - 0s 613us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.8519\n",
      "Epoch 64/150\n",
      "124/124 [==============================] - 0s 588us/step - loss: 1.2161e-07 - accuracy: 1.0000 - val_loss: 0.9549 - val_accuracy: 0.8519\n",
      "Epoch 65/150\n",
      "124/124 [==============================] - 0s 500us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.9601 - val_accuracy: 0.8519\n",
      "Epoch 66/150\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.9609 - val_accuracy: 0.8519\n",
      "Epoch 67/150\n",
      "124/124 [==============================] - 0s 605us/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 1.0129 - val_accuracy: 0.8519\n",
      "Epoch 68/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.2546e-07 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.8519\n",
      "Epoch 69/150\n",
      "124/124 [==============================] - 0s 430us/step - loss: 1.2305e-07 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.8519\n",
      "Epoch 70/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.2017e-07 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.8519\n",
      "Epoch 71/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.8519\n",
      "Epoch 72/150\n",
      "124/124 [==============================] - 0s 895us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.8519\n",
      "Epoch 73/150\n",
      "124/124 [==============================] - 0s 626us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0046 - val_accuracy: 0.8519\n",
      "Epoch 74/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0032 - val_accuracy: 0.8519\n",
      "Epoch 75/150\n",
      "124/124 [==============================] - 0s 618us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0009 - val_accuracy: 0.8519\n",
      "Epoch 76/150\n",
      "124/124 [==============================] - 0s 683us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.8519\n",
      "Epoch 77/150\n",
      "124/124 [==============================] - 0s 604us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9790 - val_accuracy: 0.8519\n",
      "Epoch 78/150\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 1.00 - 0s 462us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.8519\n",
      "Epoch 79/150\n",
      "124/124 [==============================] - 0s 714us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.8519\n",
      "Epoch 80/150\n",
      "124/124 [==============================] - 0s 802us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.8519\n",
      "Epoch 81/150\n",
      "124/124 [==============================] - 0s 862us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9881 - val_accuracy: 0.8519\n",
      "Epoch 82/150\n",
      "124/124 [==============================] - 0s 991us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9966 - val_accuracy: 0.8519\n",
      "Epoch 83/150\n",
      "124/124 [==============================] - 0s 967us/step - loss: 1.2113e-07 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.8704\n",
      "Epoch 84/150\n",
      "124/124 [==============================] - 0s 871us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.8704\n",
      "Epoch 85/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.8519\n",
      "Epoch 86/150\n",
      "124/124 [==============================] - 0s 583us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9858 - val_accuracy: 0.8519\n",
      "Epoch 87/150\n",
      "124/124 [==============================] - 0s 565us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.9906 - val_accuracy: 0.8704\n",
      "Epoch 88/150\n",
      "124/124 [==============================] - 0s 783us/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 0.9810 - val_accuracy: 0.8704\n",
      "Epoch 89/150\n",
      "124/124 [==============================] - 0s 621us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.9807 - val_accuracy: 0.8704\n",
      "Epoch 90/150\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.8704\n",
      "Epoch 91/150\n",
      "124/124 [==============================] - 0s 604us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.8704\n",
      "Epoch 92/150\n",
      "124/124 [==============================] - 0s 626us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.8704\n",
      "Epoch 93/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9892 - val_accuracy: 0.8704\n",
      "Epoch 94/150\n",
      "124/124 [==============================] - 0s 609us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9936 - val_accuracy: 0.8704\n",
      "Epoch 95/150\n",
      "124/124 [==============================] - 0s 425us/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.8704\n",
      "Epoch 96/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.8704\n",
      "Epoch 97/150\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 1.00 - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.8704\n",
      "Epoch 98/150\n",
      "124/124 [==============================] - 0s 531us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.8704\n",
      "Epoch 99/150\n",
      "124/124 [==============================] - 0s 507us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.8704\n",
      "Epoch 100/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9955 - val_accuracy: 0.8704\n",
      "Epoch 101/150\n",
      "124/124 [==============================] - 0s 630us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.8704\n",
      "Epoch 102/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.8704\n",
      "Epoch 103/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9928 - val_accuracy: 0.8704\n",
      "Epoch 104/150\n",
      "124/124 [==============================] - 0s 544us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0022 - val_accuracy: 0.8704\n",
      "Epoch 105/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 0.8704\n",
      "Epoch 106/150\n",
      "124/124 [==============================] - 0s 758us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0130 - val_accuracy: 0.8704\n",
      "Epoch 107/150\n",
      "124/124 [==============================] - 0s 895us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.8704\n",
      "Epoch 108/150\n",
      "124/124 [==============================] - 0s 790us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 1.0182 - val_accuracy: 0.8704\n",
      "Epoch 109/150\n",
      "124/124 [==============================] - 0s 717us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0161 - val_accuracy: 0.8704\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 444us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.8704\n",
      "Epoch 111/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.8704\n",
      "Epoch 112/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.8704\n",
      "Epoch 113/150\n",
      "124/124 [==============================] - 0s 473us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0106 - val_accuracy: 0.8704\n",
      "Epoch 114/150\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.8704\n",
      "Epoch 115/150\n",
      "124/124 [==============================] - 0s 516us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.8704\n",
      "Epoch 116/150\n",
      "124/124 [==============================] - 0s 564us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0097 - val_accuracy: 0.8704\n",
      "Epoch 117/150\n",
      "124/124 [==============================] - 0s 538us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.8519\n",
      "Epoch 118/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.8704\n",
      "Epoch 119/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.8704\n",
      "Epoch 120/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0088 - val_accuracy: 0.8704\n",
      "Epoch 121/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 1.0172 - val_accuracy: 0.8704\n",
      "Epoch 122/150\n",
      "124/124 [==============================] - 0s 491us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0200 - val_accuracy: 0.8704\n",
      "Epoch 123/150\n",
      "124/124 [==============================] - 0s 572us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.8704\n",
      "Epoch 124/150\n",
      "124/124 [==============================] - 0s 532us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0143 - val_accuracy: 0.8519\n",
      "Epoch 125/150\n",
      "124/124 [==============================] - 0s 544us/step - loss: 1.2017e-07 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.8704\n",
      "Epoch 126/150\n",
      "124/124 [==============================] - 0s 305us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.8704\n",
      "Epoch 127/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0146 - val_accuracy: 0.8704\n",
      "Epoch 128/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.8519\n",
      "Epoch 129/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.8519\n",
      "Epoch 130/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.8519\n",
      "Epoch 131/150\n",
      "124/124 [==============================] - 0s 397us/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.8704\n",
      "Epoch 132/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.8704\n",
      "Epoch 133/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.8704\n",
      "Epoch 134/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0118 - val_accuracy: 0.8704\n",
      "Epoch 135/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.8519\n",
      "Epoch 136/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0116 - val_accuracy: 0.8704\n",
      "Epoch 137/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0141 - val_accuracy: 0.8519\n",
      "Epoch 138/150\n",
      "124/124 [==============================] - 0s 373us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0141 - val_accuracy: 0.8519\n",
      "Epoch 139/150\n",
      "124/124 [==============================] - 0s 384us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.8519\n",
      "Epoch 140/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 1.0089 - val_accuracy: 0.8519\n",
      "Epoch 141/150\n",
      "124/124 [==============================] - 0s 572us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0251 - val_accuracy: 0.8519\n",
      "Epoch 142/150\n",
      "124/124 [==============================] - 0s 564us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0251 - val_accuracy: 0.8519\n",
      "Epoch 143/150\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.8519\n",
      "Epoch 144/150\n",
      "124/124 [==============================] - 0s 500us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0167 - val_accuracy: 0.8519\n",
      "Epoch 145/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.2017e-07 - accuracy: 1.0000 - val_loss: 1.0065 - val_accuracy: 0.8704\n",
      "Epoch 146/150\n",
      "124/124 [==============================] - 0s 508us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0065 - val_accuracy: 0.8704\n",
      "Epoch 147/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0104 - val_accuracy: 0.8704\n",
      "Epoch 148/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0104 - val_accuracy: 0.8704\n",
      "Epoch 149/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.8704\n",
      "Epoch 150/150\n",
      "124/124 [==============================] - 0s 307us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.8704\n",
      "Test loss: 1.0062942692527064\n",
      "Test accuracy: 0.8703703880310059\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='RMSprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=150,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/250\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 1.0728 - accuracy: 0.4839 - val_loss: 1.0084 - val_accuracy: 0.7593\n",
      "Epoch 2/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.9465 - accuracy: 0.7823 - val_loss: 0.8400 - val_accuracy: 0.8333\n",
      "Epoch 3/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.7272 - accuracy: 0.9355 - val_loss: 0.5804 - val_accuracy: 0.8704\n",
      "Epoch 4/250\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.4783 - accuracy: 0.9194 - val_loss: 0.3930 - val_accuracy: 0.9630\n",
      "Epoch 5/250\n",
      "124/124 [==============================] - 0s 331us/step - loss: 0.2888 - accuracy: 0.9597 - val_loss: 0.2514 - val_accuracy: 0.9630\n",
      "Epoch 6/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.1985 - accuracy: 0.9516 - val_loss: 0.2488 - val_accuracy: 0.9074\n",
      "Epoch 7/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.1468 - accuracy: 0.9597 - val_loss: 0.2248 - val_accuracy: 0.9444\n",
      "Epoch 8/250\n",
      "124/124 [==============================] - 0s 227us/step - loss: 0.1103 - accuracy: 0.9677 - val_loss: 0.3506 - val_accuracy: 0.8148\n",
      "Epoch 9/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0896 - accuracy: 0.9839 - val_loss: 0.2710 - val_accuracy: 0.9074\n",
      "Epoch 10/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0790 - accuracy: 0.9839 - val_loss: 0.1621 - val_accuracy: 0.9259\n",
      "Epoch 11/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0441 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.8889\n",
      "Epoch 12/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0735 - accuracy: 0.9758 - val_loss: 0.1599 - val_accuracy: 0.9630\n",
      "Epoch 13/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1653 - val_accuracy: 0.9259\n",
      "Epoch 14/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0296 - accuracy: 0.9919 - val_loss: 0.1871 - val_accuracy: 0.9259\n",
      "Epoch 15/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 0.9444\n",
      "Epoch 16/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9074\n",
      "Epoch 17/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9630\n",
      "Epoch 18/250\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9444\n",
      "Epoch 19/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.8704\n",
      "Epoch 20/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2210 - val_accuracy: 0.9630\n",
      "Epoch 21/250\n",
      "124/124 [==============================] - 0s 447us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9444\n",
      "Epoch 22/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2318 - val_accuracy: 0.9630\n",
      "Epoch 23/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9630\n",
      "Epoch 24/250\n",
      "124/124 [==============================] - 0s 307us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9630\n",
      "Epoch 25/250\n",
      "124/124 [==============================] - 0s 465us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9259\n",
      "Epoch 26/250\n",
      "124/124 [==============================] - 0s 310us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9074\n",
      "Epoch 27/250\n",
      "124/124 [==============================] - 0s 581us/step - loss: 7.4988e-04 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9444\n",
      "Epoch 28/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 3.8964e-04 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9630\n",
      "Epoch 29/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 3.8440e-04 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.9444\n",
      "Epoch 30/250\n",
      "124/124 [==============================] - 0s 865us/step - loss: 2.6492e-04 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9444\n",
      "Epoch 31/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 2.0077e-04 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 0.9444\n",
      "Epoch 32/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 1.4416e-04 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9074\n",
      "Epoch 33/250\n",
      "124/124 [==============================] - 0s 498us/step - loss: 1.5615e-04 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9444\n",
      "Epoch 34/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 5.9942e-05 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9630\n",
      "Epoch 35/250\n",
      "124/124 [==============================] - 0s 574us/step - loss: 4.5172e-05 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9444\n",
      "Epoch 36/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 3.2251e-05 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.8704\n",
      "Epoch 37/250\n",
      "124/124 [==============================] - 0s 340us/step - loss: 2.6811e-04 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9630\n",
      "Epoch 38/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.5365e-05 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9444\n",
      "Epoch 39/250\n",
      "124/124 [==============================] - 0s 434us/step - loss: 1.2301e-05 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9444\n",
      "Epoch 40/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.0110e-05 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9444\n",
      "Epoch 41/250\n",
      "124/124 [==============================] - 0s 439us/step - loss: 8.2925e-06 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9259\n",
      "Epoch 42/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 7.2979e-06 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9444\n",
      "Epoch 43/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 4.4464e-06 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9259\n",
      "Epoch 44/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 3.5955e-06 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9074\n",
      "Epoch 45/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 3.6692e-06 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9444\n",
      "Epoch 46/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.7439e-06 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9444\n",
      "Epoch 47/250\n",
      "124/124 [==============================] - 0s 336us/step - loss: 1.3522e-06 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.9074\n",
      "Epoch 48/250\n",
      "124/124 [==============================] - 0s 506us/step - loss: 2.2424e-06 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9259\n",
      "Epoch 49/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 7.0084e-07 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9259\n",
      "Epoch 50/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 3.8214e-07 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9259\n",
      "Epoch 51/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 4.1387e-07 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9259\n",
      "Epoch 52/250\n",
      "124/124 [==============================] - 0s 412us/step - loss: 3.1100e-07 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.9259\n",
      "Epoch 53/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 4.8165e-07 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9074\n",
      "Epoch 54/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.4659e-07 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9630\n",
      "Epoch 55/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.6103e-07 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9259\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 378us/step - loss: 1.4853e-07 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9444\n",
      "Epoch 57/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.0429e-07 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9259\n",
      "Epoch 58/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.4949e-07 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9444\n",
      "Epoch 59/250\n",
      "124/124 [==============================] - 0s 372us/step - loss: 1.3171e-07 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9259\n",
      "Epoch 60/250\n",
      "124/124 [==============================] - 0s 277us/step - loss: 1.3411e-07 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9444\n",
      "Epoch 61/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2930e-07 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9444\n",
      "Epoch 62/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2305e-07 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9444\n",
      "Epoch 63/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.2448e-07 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9074\n",
      "Epoch 64/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2882e-07 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9259\n",
      "Epoch 65/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 1.2113e-07 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9444\n",
      "Epoch 66/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9444\n",
      "Epoch 67/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.2017e-07 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9259\n",
      "Epoch 68/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9259\n",
      "Epoch 69/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9259\n",
      "Epoch 70/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2402e-07 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9259\n",
      "Epoch 71/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9259\n",
      "Epoch 72/250\n",
      "124/124 [==============================] - 0s 224us/step - loss: 1.2402e-07 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.9259\n",
      "Epoch 73/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9259\n",
      "Epoch 74/250\n",
      "124/124 [==============================] - 0s 420us/step - loss: 1.3363e-07 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.9074\n",
      "Epoch 75/250\n",
      "124/124 [==============================] - 0s 290us/step - loss: 1.2402e-07 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9259\n",
      "Epoch 76/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9259\n",
      "Epoch 77/250\n",
      "124/124 [==============================] - 0s 315us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.9259\n",
      "Epoch 78/250\n",
      "124/124 [==============================] - 0s 456us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9259\n",
      "Epoch 79/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9259\n",
      "Epoch 80/250\n",
      "124/124 [==============================] - 0s 269us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9259\n",
      "Epoch 81/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9259\n",
      "Epoch 82/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9259\n",
      "Epoch 83/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.2257e-07 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9259\n",
      "Epoch 84/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9259\n",
      "Epoch 85/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9259\n",
      "Epoch 86/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9259\n",
      "Epoch 87/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9259\n",
      "Epoch 88/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2161e-07 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9259\n",
      "Epoch 89/250\n",
      "124/124 [==============================] - 0s 457us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9259\n",
      "Epoch 90/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9259\n",
      "Epoch 91/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9259\n",
      "Epoch 92/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9259\n",
      "Epoch 93/250\n",
      "124/124 [==============================] - 0s 265us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9259\n",
      "Epoch 94/250\n",
      "124/124 [==============================] - 0s 350us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9259\n",
      "Epoch 95/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9259\n",
      "Epoch 96/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9259\n",
      "Epoch 97/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9444\n",
      "Epoch 98/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9444\n",
      "Epoch 99/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9444\n",
      "Epoch 100/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9444\n",
      "Epoch 101/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.9444\n",
      "Epoch 102/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9259\n",
      "Epoch 103/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9259\n",
      "Epoch 104/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9259\n",
      "Epoch 105/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9259\n",
      "Epoch 106/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9259\n",
      "Epoch 107/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9259\n",
      "Epoch 108/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9259\n",
      "Epoch 109/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9259\n",
      "Epoch 110/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.2017e-07 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9259\n",
      "Epoch 111/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9259\n",
      "Epoch 112/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9259\n",
      "Epoch 113/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 114/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 115/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 116/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9259\n",
      "Epoch 117/250\n",
      "124/124 [==============================] - 0s 297us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9259\n",
      "Epoch 118/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9259\n",
      "Epoch 119/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9259\n",
      "Epoch 120/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9259\n",
      "Epoch 121/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9259\n",
      "Epoch 122/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9259\n",
      "Epoch 123/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9259\n",
      "Epoch 124/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9259\n",
      "Epoch 125/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9259\n",
      "Epoch 126/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2257e-07 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9259\n",
      "Epoch 127/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.2017e-07 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9259\n",
      "Epoch 128/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9259\n",
      "Epoch 129/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9259\n",
      "Epoch 130/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9259\n",
      "Epoch 131/250\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 1.00 - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9259\n",
      "Epoch 132/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9259\n",
      "Epoch 133/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9259\n",
      "Epoch 134/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9259\n",
      "Epoch 135/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9259\n",
      "Epoch 136/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9259\n",
      "Epoch 137/250\n",
      "124/124 [==============================] - 0s 598us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9259\n",
      "Epoch 138/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.2065e-07 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9259\n",
      "Epoch 139/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.2257e-07 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9259\n",
      "Epoch 140/250\n",
      "124/124 [==============================] - 0s 331us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9259\n",
      "Epoch 141/250\n",
      "124/124 [==============================] - 0s 430us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9259\n",
      "Epoch 142/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9259\n",
      "Epoch 143/250\n",
      "124/124 [==============================] - 0s 328us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9259\n",
      "Epoch 144/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9259\n",
      "Epoch 145/250\n",
      "124/124 [==============================] - 0s 364us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9259\n",
      "Epoch 146/250\n",
      "124/124 [==============================] - 0s 304us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4681 - val_accuracy: 0.9259\n",
      "Epoch 147/250\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.1921e-07 - accuracy: 1.00 - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9259\n",
      "Epoch 148/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9259\n",
      "Epoch 149/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9259\n",
      "Epoch 150/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 151/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 152/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 153/250\n",
      "124/124 [==============================] - 0s 582us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 154/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 155/250\n",
      "124/124 [==============================] - 0s 402us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 156/250\n",
      "124/124 [==============================] - 0s 469us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 157/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 158/250\n",
      "124/124 [==============================] - 0s 651us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 159/250\n",
      "124/124 [==============================] - 0s 943us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9259\n",
      "Epoch 160/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9259\n",
      "Epoch 161/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9259\n",
      "Epoch 162/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9259\n",
      "Epoch 163/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n",
      "Epoch 165/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n",
      "Epoch 166/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n",
      "Epoch 167/250\n",
      "124/124 [==============================] - 0s 390us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n",
      "Epoch 168/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n",
      "Epoch 169/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n",
      "Epoch 170/250\n",
      "124/124 [==============================] - 0s 717us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9259\n",
      "Epoch 171/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 172/250\n",
      "124/124 [==============================] - 0s 207us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 173/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 174/250\n",
      "124/124 [==============================] - 0s 474us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 175/250\n",
      "124/124 [==============================] - 0s 336us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 176/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 177/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 178/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 179/250\n",
      "124/124 [==============================] - 0s 425us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 180/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9259\n",
      "Epoch 181/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9259\n",
      "Epoch 182/250\n",
      "124/124 [==============================] - 0s 967us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9259\n",
      "Epoch 183/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9259\n",
      "Epoch 184/250\n",
      "124/124 [==============================] - 0s 592us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9259\n",
      "Epoch 185/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9259\n",
      "Epoch 186/250\n",
      "124/124 [==============================] - 0s 225us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9259\n",
      "Epoch 187/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9259\n",
      "Epoch 188/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9259\n",
      "Epoch 189/250\n",
      "124/124 [==============================] - 0s 489us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9259\n",
      "Epoch 190/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9259\n",
      "Epoch 191/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9259\n",
      "Epoch 192/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9259\n",
      "Epoch 193/250\n",
      "124/124 [==============================] - 0s 350us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9259\n",
      "Epoch 194/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9259\n",
      "Epoch 195/250\n",
      "124/124 [==============================] - 0s 491us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 196/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 197/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 198/250\n",
      "124/124 [==============================] - 0s 400us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 199/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 200/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 201/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 202/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9259\n",
      "Epoch 203/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9259\n",
      "Epoch 204/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.1969e-07 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9259\n",
      "Epoch 205/250\n",
      "124/124 [==============================] - 0s 412us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 206/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 207/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 208/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 209/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 210/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 211/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 212/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 213/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 214/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 215/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 216/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 217/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 218/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 219/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 220/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 221/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 222/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 223/250\n",
      "124/124 [==============================] - 0s 398us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 224/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 225/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 226/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 227/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 228/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 229/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 230/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 231/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 232/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 233/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9259\n",
      "Epoch 234/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9259\n",
      "Epoch 235/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 236/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 237/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 238/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 239/250\n",
      "124/124 [==============================] - 0s 388us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 240/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 241/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 242/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 243/250\n",
      "124/124 [==============================] - 0s 244us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 244/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 245/250\n",
      "124/124 [==============================] - 0s 418us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 246/250\n",
      "124/124 [==============================] - 0s 252us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 247/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 248/250\n",
      "124/124 [==============================] - 0s 420us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 249/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Epoch 250/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.1921e-07 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9259\n",
      "Test loss: 0.4684389520574499\n",
      "Test accuracy: 0.9259259104728699\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='RMSprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=250,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
