{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/25\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 1.0822 - accuracy: 0.5806 - val_loss: 1.0372 - val_accuracy: 0.4074\n",
      "Epoch 2/25\n",
      "124/124 [==============================] - 0s 469us/step - loss: 0.9580 - accuracy: 0.6129 - val_loss: 0.7706 - val_accuracy: 0.9074\n",
      "Epoch 3/25\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.5555 - accuracy: 0.9113 - val_loss: 0.4950 - val_accuracy: 0.7407\n",
      "Epoch 4/25\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.2323 - accuracy: 0.8952 - val_loss: 0.1926 - val_accuracy: 0.9074\n",
      "Epoch 5/25\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.1159 - accuracy: 0.9597 - val_loss: 0.1701 - val_accuracy: 0.9630\n",
      "Epoch 6/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0672 - accuracy: 0.9677 - val_loss: 0.7218 - val_accuracy: 0.7778\n",
      "Epoch 7/25\n",
      "124/124 [==============================] - 0s 471us/step - loss: 0.0724 - accuracy: 0.9758 - val_loss: 0.1695 - val_accuracy: 0.9074\n",
      "Epoch 8/25\n",
      "124/124 [==============================] - 0s 323us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9259\n",
      "Epoch 9/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.1774 - val_accuracy: 0.9259\n",
      "Epoch 10/25\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1691 - val_accuracy: 0.9444\n",
      "Epoch 11/25\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1834 - val_accuracy: 0.9259\n",
      "Epoch 12/25\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9259\n",
      "Epoch 13/25\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9444\n",
      "Epoch 14/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9259\n",
      "Epoch 15/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.9259\n",
      "Epoch 16/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2024 - val_accuracy: 0.9444\n",
      "Epoch 17/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2043 - val_accuracy: 0.9444\n",
      "Epoch 18/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9444\n",
      "Epoch 19/25\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9444\n",
      "Epoch 20/25\n",
      "124/124 [==============================] - 0s 310us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9444\n",
      "Epoch 21/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9444\n",
      "Epoch 22/25\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2330 - val_accuracy: 0.9259\n",
      "Epoch 23/25\n",
      "124/124 [==============================] - 0s 528us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9444\n",
      "Epoch 24/25\n",
      "124/124 [==============================] - 0s 420us/step - loss: 9.4972e-04 - accuracy: 1.0000 - val_loss: 0.2241 - val_accuracy: 0.9444\n",
      "Epoch 25/25\n",
      "124/124 [==============================] - 0s 436us/step - loss: 8.6994e-04 - accuracy: 1.0000 - val_loss: 0.2259 - val_accuracy: 0.9444\n",
      "Test loss: 0.22589792656125846\n",
      "Test accuracy: 0.9444444179534912\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['accuracy'])\n",
    "plt.plot(training_model.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['loss'])\n",
    "plt.plot(training_model.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 3s 22ms/step - loss: 1.0779 - accuracy: 0.5403 - val_loss: 1.0175 - val_accuracy: 0.5926\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 578us/step - loss: 0.9272 - accuracy: 0.6694 - val_loss: 0.7539 - val_accuracy: 0.7407\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.5362 - accuracy: 0.8952 - val_loss: 0.4252 - val_accuracy: 0.8333\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.2281 - accuracy: 0.9355 - val_loss: 0.4005 - val_accuracy: 0.8519\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1321 - accuracy: 0.9677 - val_loss: 0.1850 - val_accuracy: 0.9074\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 227us/step - loss: 0.0759 - accuracy: 0.9839 - val_loss: 0.1791 - val_accuracy: 0.9259\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.0486 - accuracy: 0.9839 - val_loss: 0.2034 - val_accuracy: 0.9074\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 0.9074\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.2139 - val_accuracy: 0.9074\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.2483 - val_accuracy: 0.9074\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 368us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9074\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 556us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9074\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 532us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.8889\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 540us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2552 - val_accuracy: 0.8889\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 472us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9074\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 0.8889\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 471us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2669 - val_accuracy: 0.8889\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 471us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.8889\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 580us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2702 - val_accuracy: 0.8889\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 556us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 0.8889\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 580us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.8889\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 348us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.8889\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2980 - val_accuracy: 0.8889\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.8889\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 613us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2921 - val_accuracy: 0.8889\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 588us/step - loss: 9.1907e-04 - accuracy: 1.0000 - val_loss: 0.3004 - val_accuracy: 0.8889\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 564us/step - loss: 8.3292e-04 - accuracy: 1.0000 - val_loss: 0.2987 - val_accuracy: 0.8889\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 540us/step - loss: 7.7027e-04 - accuracy: 1.0000 - val_loss: 0.3014 - val_accuracy: 0.8889\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 304us/step - loss: 7.1073e-04 - accuracy: 1.0000 - val_loss: 0.3130 - val_accuracy: 0.8889\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 6.3630e-04 - accuracy: 1.0000 - val_loss: 0.3242 - val_accuracy: 0.8889\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 453us/step - loss: 6.0306e-04 - accuracy: 1.0000 - val_loss: 0.3241 - val_accuracy: 0.8889\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 439us/step - loss: 5.5429e-04 - accuracy: 1.0000 - val_loss: 0.3223 - val_accuracy: 0.8889\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 693us/step - loss: 5.2721e-04 - accuracy: 1.0000 - val_loss: 0.3274 - val_accuracy: 0.8889\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 742us/step - loss: 4.8501e-04 - accuracy: 1.0000 - val_loss: 0.3279 - val_accuracy: 0.8889\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 653us/step - loss: 4.5713e-04 - accuracy: 1.0000 - val_loss: 0.3291 - val_accuracy: 0.8889\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 4.3238e-04 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.8889\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 645us/step - loss: 4.0419e-04 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.8889\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 3.8364e-04 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.8889\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 750us/step - loss: 3.6117e-04 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.8889\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 532us/step - loss: 3.4550e-04 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.8889\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 540us/step - loss: 3.2304e-04 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.8889\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 371us/step - loss: 3.1170e-04 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.8889\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.9315e-04 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.8889\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 582us/step - loss: 2.7983e-04 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.6713e-04 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.8889\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 548us/step - loss: 2.5607e-04 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.8889\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 492us/step - loss: 2.4429e-04 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.8889\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 322us/step - loss: 2.3293e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 504us/step - loss: 2.2284e-04 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.8889\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.1391e-04 - accuracy: 1.0000 - val_loss: 0.3630 - val_accuracy: 0.8889\n",
      "Test loss: 0.36299693308494707\n",
      "Test accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/150\n",
      "124/124 [==============================] - 1s 4ms/step - loss: 1.0810 - accuracy: 0.6048 - val_loss: 1.0298 - val_accuracy: 0.6296\n",
      "Epoch 2/150\n",
      "124/124 [==============================] - 0s 260us/step - loss: 0.9163 - accuracy: 0.6613 - val_loss: 0.7468 - val_accuracy: 0.7037\n",
      "Epoch 3/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.4828 - accuracy: 0.8790 - val_loss: 0.3968 - val_accuracy: 0.8333\n",
      "Epoch 4/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.1983 - accuracy: 0.9194 - val_loss: 0.3662 - val_accuracy: 0.8704\n",
      "Epoch 5/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.1101 - accuracy: 0.9516 - val_loss: 0.1927 - val_accuracy: 0.9259\n",
      "Epoch 6/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0489 - accuracy: 0.9919 - val_loss: 0.2355 - val_accuracy: 0.8889\n",
      "Epoch 7/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.8889\n",
      "Epoch 8/150\n",
      "124/124 [==============================] - 0s 499us/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.2505 - val_accuracy: 0.9074\n",
      "Epoch 9/150\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.2856 - val_accuracy: 0.8889\n",
      "Epoch 10/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.8889\n",
      "Epoch 11/150\n",
      "124/124 [==============================] - 0s 752us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.8889\n",
      "Epoch 12/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2928 - val_accuracy: 0.9074\n",
      "Epoch 13/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2935 - val_accuracy: 0.9074\n",
      "Epoch 14/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3122 - val_accuracy: 0.8889\n",
      "Epoch 15/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3192 - val_accuracy: 0.8889\n",
      "Epoch 16/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.8889\n",
      "Epoch 17/150\n",
      "124/124 [==============================] - 0s 596us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.8889\n",
      "Epoch 18/150\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.8889\n",
      "Epoch 19/150\n",
      "124/124 [==============================] - 0s 513us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.8889\n",
      "Epoch 20/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.8889\n",
      "Epoch 21/150\n",
      "124/124 [==============================] - 0s 596us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.8889\n",
      "Epoch 22/150\n",
      "124/124 [==============================] - 0s 750us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.8889\n",
      "Epoch 23/150\n",
      "124/124 [==============================] - 0s 604us/step - loss: 9.2349e-04 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.8889\n",
      "Epoch 24/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 8.4399e-04 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9074\n",
      "Epoch 25/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 8.0197e-04 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.8889\n",
      "Epoch 26/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.1770e-04 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.8889\n",
      "Epoch 27/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.4958e-04 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.8889\n",
      "Epoch 28/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.0252e-04 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.8889\n",
      "Epoch 29/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.6071e-04 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8889\n",
      "Epoch 30/150\n",
      "124/124 [==============================] - 0s 430us/step - loss: 5.2637e-04 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.8889\n",
      "Epoch 31/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 4.9154e-04 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.8889\n",
      "Epoch 32/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 4.6176e-04 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.8889\n",
      "Epoch 33/150\n",
      "124/124 [==============================] - 0s 774us/step - loss: 4.3574e-04 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.8889\n",
      "Epoch 34/150\n",
      "124/124 [==============================] - 0s 428us/step - loss: 4.1137e-04 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.8889\n",
      "Epoch 35/150\n",
      "124/124 [==============================] - 0s 457us/step - loss: 3.8950e-04 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.8889\n",
      "Epoch 36/150\n",
      "124/124 [==============================] - 0s 604us/step - loss: 3.6682e-04 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.8889\n",
      "Epoch 37/150\n",
      "124/124 [==============================] - 0s 733us/step - loss: 3.4687e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.8889\n",
      "Epoch 38/150\n",
      "124/124 [==============================] - 0s 798us/step - loss: 3.2707e-04 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.8889\n",
      "Epoch 39/150\n",
      "124/124 [==============================] - 0s 711us/step - loss: 3.1181e-04 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8889\n",
      "Epoch 40/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.9560e-04 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8889\n",
      "Epoch 41/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.8452e-04 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.8889\n",
      "Epoch 42/150\n",
      "124/124 [==============================] - 0s 476us/step - loss: 2.6930e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8889\n",
      "Epoch 43/150\n",
      "124/124 [==============================] - 0s 350us/step - loss: 2.5711e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.8889\n",
      "Epoch 44/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 2.4771e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8889\n",
      "Epoch 45/150\n",
      "124/124 [==============================] - 0s 791us/step - loss: 2.3765e-04 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8889\n",
      "Epoch 46/150\n",
      "124/124 [==============================] - 0s 742us/step - loss: 2.2726e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8889\n",
      "Epoch 47/150\n",
      "124/124 [==============================] - 0s 653us/step - loss: 2.1896e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8889\n",
      "Epoch 48/150\n",
      "124/124 [==============================] - 0s 373us/step - loss: 2.0882e-04 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.8889\n",
      "Epoch 49/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 2.0244e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.8889\n",
      "Epoch 50/150\n",
      "124/124 [==============================] - 0s 452us/step - loss: 1.9539e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.8889\n",
      "Epoch 51/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.8669e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8889\n",
      "Epoch 52/150\n",
      "124/124 [==============================] - 0s 593us/step - loss: 1.8070e-04 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.8889\n",
      "Epoch 53/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 1.7368e-04 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.8889\n",
      "Epoch 54/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 1.6824e-04 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.8889\n",
      "Epoch 55/150\n",
      "124/124 [==============================] - 0s 725us/step - loss: 1.6120e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.8889\n",
      "Epoch 56/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 564us/step - loss: 1.5501e-04 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.8889\n",
      "Epoch 57/150\n",
      "124/124 [==============================] - 0s 476us/step - loss: 1.5043e-04 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.8889\n",
      "Epoch 58/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.4513e-04 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.8889\n",
      "Epoch 59/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.4116e-04 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.8889\n",
      "Epoch 60/150\n",
      "124/124 [==============================] - 0s 579us/step - loss: 1.3575e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.8889\n",
      "Epoch 61/150\n",
      "124/124 [==============================] - 0s 591us/step - loss: 1.3132e-04 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.8889\n",
      "Epoch 62/150\n",
      "124/124 [==============================] - 0s 412us/step - loss: 1.2831e-04 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8889\n",
      "Epoch 63/150\n",
      "124/124 [==============================] - 0s 326us/step - loss: 1.2326e-04 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8889\n",
      "Epoch 64/150\n",
      "124/124 [==============================] - 0s 485us/step - loss: 1.1969e-04 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.8889\n",
      "Epoch 65/150\n",
      "124/124 [==============================] - 0s 304us/step - loss: 1.1603e-04 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.8889\n",
      "Epoch 66/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.1284e-04 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8889\n",
      "Epoch 67/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0879e-04 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8889\n",
      "Epoch 68/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0606e-04 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.8889\n",
      "Epoch 69/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0297e-04 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.8889\n",
      "Epoch 70/150\n",
      "124/124 [==============================] - 0s 373us/step - loss: 1.0043e-04 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.8889\n",
      "Epoch 71/150\n",
      "124/124 [==============================] - 0s 280us/step - loss: 9.6979e-05 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.8889\n",
      "Epoch 72/150\n",
      "124/124 [==============================] - 0s 461us/step - loss: 9.4815e-05 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.8889\n",
      "Epoch 73/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 9.2937e-05 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.8889\n",
      "Epoch 74/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 8.9690e-05 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.8889\n",
      "Epoch 75/150\n",
      "124/124 [==============================] - 0s 243us/step - loss: 8.7224e-05 - accuracy: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.8889\n",
      "Epoch 76/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 8.4886e-05 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.8889\n",
      "Epoch 77/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 8.3110e-05 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.8889\n",
      "Epoch 78/150\n",
      "124/124 [==============================] - 0s 477us/step - loss: 8.0996e-05 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.8889\n",
      "Epoch 79/150\n",
      "124/124 [==============================] - 0s 532us/step - loss: 7.8837e-05 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.8889\n",
      "Epoch 80/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 7.6954e-05 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.8889\n",
      "Epoch 81/150\n",
      "124/124 [==============================] - 0s 355us/step - loss: 7.5289e-05 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.8889\n",
      "Epoch 82/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 7.3673e-05 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.8889\n",
      "Epoch 83/150\n",
      "124/124 [==============================] - 0s 346us/step - loss: 7.1474e-05 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.8889\n",
      "Epoch 84/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 7.0073e-05 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.8889\n",
      "Epoch 85/150\n",
      "124/124 [==============================] - 0s 519us/step - loss: 6.8355e-05 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.8889\n",
      "Epoch 86/150\n",
      "124/124 [==============================] - 0s 508us/step - loss: 6.6737e-05 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.8889\n",
      "Epoch 87/150\n",
      "124/124 [==============================] - 0s 432us/step - loss: 6.5115e-05 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.8889\n",
      "Epoch 88/150\n",
      "124/124 [==============================] - 0s 481us/step - loss: 6.3343e-05 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.8889\n",
      "Epoch 89/150\n",
      "124/124 [==============================] - 0s 365us/step - loss: 6.2099e-05 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8889\n",
      "Epoch 90/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.1141e-05 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.8889\n",
      "Epoch 91/150\n",
      "124/124 [==============================] - 0s 607us/step - loss: 5.9425e-05 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.8889\n",
      "Epoch 92/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 5.8313e-05 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.8889\n",
      "Epoch 93/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 5.6847e-05 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.8889\n",
      "Epoch 94/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 5.5747e-05 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8889\n",
      "Epoch 95/150\n",
      "124/124 [==============================] - 0s 355us/step - loss: 5.4245e-05 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.8889\n",
      "Epoch 96/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.3405e-05 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.8889\n",
      "Epoch 97/150\n",
      "124/124 [==============================] - 0s 548us/step - loss: 5.2291e-05 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.8889\n",
      "Epoch 98/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.1150e-05 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8889\n",
      "Epoch 99/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.0290e-05 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.8889\n",
      "Epoch 100/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.9100e-05 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.8889\n",
      "Epoch 101/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.8211e-05 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.8889\n",
      "Epoch 102/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.7110e-05 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8889\n",
      "Epoch 103/150\n",
      "124/124 [==============================] - 0s 396us/step - loss: 4.6100e-05 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.8889\n",
      "Epoch 104/150\n",
      "124/124 [==============================] - 0s 499us/step - loss: 4.5285e-05 - accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.8889\n",
      "Epoch 105/150\n",
      "124/124 [==============================] - 0s 621us/step - loss: 4.4466e-05 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.8889\n",
      "Epoch 106/150\n",
      "124/124 [==============================] - 0s 883us/step - loss: 4.3369e-05 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.8889\n",
      "Epoch 107/150\n",
      "124/124 [==============================] - ETA: 0s - loss: 6.6525e-05 - accuracy: 1.00 - 0s 399us/step - loss: 4.2658e-05 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8889\n",
      "Epoch 108/150\n",
      "124/124 [==============================] - 0s 564us/step - loss: 4.1972e-05 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.8889\n",
      "Epoch 109/150\n",
      "124/124 [==============================] - 0s 613us/step - loss: 4.1376e-05 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.8889\n",
      "Epoch 110/150\n",
      "124/124 [==============================] - 0s 914us/step - loss: 4.0381e-05 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8889\n",
      "Epoch 111/150\n",
      "124/124 [==============================] - 0s 524us/step - loss: 3.9751e-05 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8889\n",
      "Epoch 112/150\n",
      "124/124 [==============================] - 0s 564us/step - loss: 3.9390e-05 - accuracy: 1.0000 - val_loss: 0.5242 - val_accuracy: 0.8889\n",
      "Epoch 113/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 3.8339e-05 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.8889\n",
      "Epoch 114/150\n",
      "124/124 [==============================] - 0s 677us/step - loss: 3.7882e-05 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.8889\n",
      "Epoch 115/150\n",
      "124/124 [==============================] - 0s 783us/step - loss: 3.7175e-05 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8889\n",
      "Epoch 116/150\n",
      "124/124 [==============================] - 0s 964us/step - loss: 3.6253e-05 - accuracy: 1.0000 - val_loss: 0.5270 - val_accuracy: 0.8889\n",
      "Epoch 117/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 3.5513e-05 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.8889\n",
      "Epoch 118/150\n",
      "124/124 [==============================] - 0s 782us/step - loss: 3.4948e-05 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8889\n",
      "Epoch 119/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 3.4252e-05 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.8889\n",
      "Epoch 120/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 3.3711e-05 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.8889\n",
      "Epoch 121/150\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 3.3125e-05 - accuracy: 1.0000 - val_loss: 0.5300 - val_accuracy: 0.8889\n",
      "Epoch 122/150\n",
      "124/124 [==============================] - 0s 951us/step - loss: 3.2641e-05 - accuracy: 1.0000 - val_loss: 0.5307 - val_accuracy: 0.8889\n",
      "Epoch 123/150\n",
      "124/124 [==============================] - 0s 725us/step - loss: 3.1950e-05 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8889\n",
      "Epoch 124/150\n",
      "124/124 [==============================] - 0s 590us/step - loss: 3.1425e-05 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.8889\n",
      "Epoch 125/150\n",
      "124/124 [==============================] - 0s 516us/step - loss: 3.0949e-05 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.8889\n",
      "Epoch 126/150\n",
      "124/124 [==============================] - ETA: 0s - loss: 2.9584e-05 - accuracy: 1.00 - 0s 838us/step - loss: 3.0477e-05 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.8889\n",
      "Epoch 127/150\n",
      "124/124 [==============================] - 0s 846us/step - loss: 2.9922e-05 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.8889\n",
      "Epoch 128/150\n",
      "124/124 [==============================] - 0s 717us/step - loss: 2.9381e-05 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.8889\n",
      "Epoch 129/150\n",
      "124/124 [==============================] - 0s 717us/step - loss: 2.9067e-05 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8889\n",
      "Epoch 130/150\n",
      "124/124 [==============================] - 0s 733us/step - loss: 2.8324e-05 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.8889\n",
      "Epoch 131/150\n",
      "124/124 [==============================] - 0s 879us/step - loss: 2.7683e-05 - accuracy: 1.0000 - val_loss: 0.5372 - val_accuracy: 0.8889\n",
      "Epoch 132/150\n",
      "124/124 [==============================] - 0s 725us/step - loss: 2.7275e-05 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.8889\n",
      "Epoch 133/150\n",
      "124/124 [==============================] - 0s 532us/step - loss: 2.6950e-05 - accuracy: 1.0000 - val_loss: 0.5399 - val_accuracy: 0.8889\n",
      "Epoch 134/150\n",
      "124/124 [==============================] - 0s 540us/step - loss: 2.6676e-05 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8889\n",
      "Epoch 135/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.6194e-05 - accuracy: 1.0000 - val_loss: 0.5417 - val_accuracy: 0.8889\n",
      "Epoch 136/150\n",
      "124/124 [==============================] - 0s 540us/step - loss: 2.5825e-05 - accuracy: 1.0000 - val_loss: 0.5450 - val_accuracy: 0.8889\n",
      "Epoch 137/150\n",
      "124/124 [==============================] - 0s 653us/step - loss: 2.5187e-05 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.8889\n",
      "Epoch 138/150\n",
      "124/124 [==============================] - 0s 480us/step - loss: 2.4849e-05 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.8889\n",
      "Epoch 139/150\n",
      "124/124 [==============================] - 0s 630us/step - loss: 2.4474e-05 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.8889\n",
      "Epoch 140/150\n",
      "124/124 [==============================] - 0s 580us/step - loss: 2.4327e-05 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.8889\n",
      "Epoch 141/150\n",
      "124/124 [==============================] - 0s 677us/step - loss: 2.3846e-05 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.8889\n",
      "Epoch 142/150\n",
      "124/124 [==============================] - 0s 604us/step - loss: 2.3703e-05 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.8889\n",
      "Epoch 143/150\n",
      "124/124 [==============================] - 0s 613us/step - loss: 2.3119e-05 - accuracy: 1.0000 - val_loss: 0.5516 - val_accuracy: 0.8889\n",
      "Epoch 144/150\n",
      "124/124 [==============================] - 0s 572us/step - loss: 2.2898e-05 - accuracy: 1.0000 - val_loss: 0.5554 - val_accuracy: 0.8889\n",
      "Epoch 145/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 2.2561e-05 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.8889\n",
      "Epoch 146/150\n",
      "124/124 [==============================] - 0s 580us/step - loss: 2.2161e-05 - accuracy: 1.0000 - val_loss: 0.5579 - val_accuracy: 0.8889\n",
      "Epoch 147/150\n",
      "124/124 [==============================] - 0s 733us/step - loss: 2.1916e-05 - accuracy: 1.0000 - val_loss: 0.5594 - val_accuracy: 0.8889\n",
      "Epoch 148/150\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.1621e-05 - accuracy: 1.0000 - val_loss: 0.5556 - val_accuracy: 0.8889\n",
      "Epoch 149/150\n",
      "124/124 [==============================] - 0s 649us/step - loss: 2.1190e-05 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.8889\n",
      "Epoch 150/150\n",
      "124/124 [==============================] - 0s 703us/step - loss: 2.0798e-05 - accuracy: 1.0000 - val_loss: 0.5608 - val_accuracy: 0.8889\n",
      "Test loss: 0.5607989568401266\n",
      "Test accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=150,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/250\n",
      "124/124 [==============================] - 2s 15ms/step - loss: 1.0655 - accuracy: 0.4516 - val_loss: 0.9817 - val_accuracy: 0.5556\n",
      "Epoch 2/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 0.8776 - accuracy: 0.7097 - val_loss: 0.6959 - val_accuracy: 0.6667\n",
      "Epoch 3/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 0.5096 - accuracy: 0.8629 - val_loss: 0.3752 - val_accuracy: 0.9074\n",
      "Epoch 4/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 0.2314 - accuracy: 0.9435 - val_loss: 0.2666 - val_accuracy: 0.9074\n",
      "Epoch 5/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 0.1344 - accuracy: 0.9597 - val_loss: 0.2438 - val_accuracy: 0.9074\n",
      "Epoch 6/250\n",
      "124/124 [==============================] - 0s 903us/step - loss: 0.0901 - accuracy: 0.9677 - val_loss: 0.2019 - val_accuracy: 0.9074\n",
      "Epoch 7/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 0.0582 - accuracy: 0.9677 - val_loss: 0.4030 - val_accuracy: 0.8889\n",
      "Epoch 8/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 0.0409 - accuracy: 0.9919 - val_loss: 0.1861 - val_accuracy: 0.9444\n",
      "Epoch 9/250\n",
      "124/124 [==============================] - 0s 661us/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.2463 - val_accuracy: 0.9074\n",
      "Epoch 10/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 0.0201 - accuracy: 0.9919 - val_loss: 0.2242 - val_accuracy: 0.9259\n",
      "Epoch 11/250\n",
      "124/124 [==============================] - 0s 721us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.2202 - val_accuracy: 0.9259\n",
      "Epoch 12/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.2360 - val_accuracy: 0.9259\n",
      "Epoch 13/250\n",
      "124/124 [==============================] - 0s 624us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2399 - val_accuracy: 0.9259\n",
      "Epoch 14/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.2490 - val_accuracy: 0.9259\n",
      "Epoch 15/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9259\n",
      "Epoch 16/250\n",
      "124/124 [==============================] - 0s 862us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2547 - val_accuracy: 0.9259\n",
      "Epoch 17/250\n",
      "124/124 [==============================] - 0s 677us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9259\n",
      "Epoch 18/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2597 - val_accuracy: 0.9259\n",
      "Epoch 19/250\n",
      "124/124 [==============================] - 0s 742us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2663 - val_accuracy: 0.9259\n",
      "Epoch 20/250\n",
      "124/124 [==============================] - 0s 782us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9259\n",
      "Epoch 21/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9259\n",
      "Epoch 22/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9074\n",
      "Epoch 23/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9074\n",
      "Epoch 24/250\n",
      "124/124 [==============================] - 0s 551us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9259\n",
      "Epoch 25/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2918 - val_accuracy: 0.9259\n",
      "Epoch 26/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 9.4097e-04 - accuracy: 1.0000 - val_loss: 0.3000 - val_accuracy: 0.9259\n",
      "Epoch 27/250\n",
      "124/124 [==============================] - 0s 935us/step - loss: 8.8659e-04 - accuracy: 1.0000 - val_loss: 0.2995 - val_accuracy: 0.9259\n",
      "Epoch 28/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 8.2656e-04 - accuracy: 1.0000 - val_loss: 0.2993 - val_accuracy: 0.9259\n",
      "Epoch 29/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 7.4812e-04 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9259\n",
      "Epoch 30/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 7.0165e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9259\n",
      "Epoch 31/250\n",
      "124/124 [==============================] - 0s 814us/step - loss: 6.4171e-04 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9074\n",
      "Epoch 32/250\n",
      "124/124 [==============================] - 0s 782us/step - loss: 6.0387e-04 - accuracy: 1.0000 - val_loss: 0.3073 - val_accuracy: 0.9074\n",
      "Epoch 33/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 5.5339e-04 - accuracy: 1.0000 - val_loss: 0.3138 - val_accuracy: 0.9259\n",
      "Epoch 34/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 5.2409e-04 - accuracy: 1.0000 - val_loss: 0.3203 - val_accuracy: 0.9259\n",
      "Epoch 35/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 4.9040e-04 - accuracy: 1.0000 - val_loss: 0.3194 - val_accuracy: 0.9074\n",
      "Epoch 36/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 4.5784e-04 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9074\n",
      "Epoch 37/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 4.3268e-04 - accuracy: 1.0000 - val_loss: 0.3221 - val_accuracy: 0.9074\n",
      "Epoch 38/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 4.0985e-04 - accuracy: 1.0000 - val_loss: 0.3235 - val_accuracy: 0.9074\n",
      "Epoch 39/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 3.9014e-04 - accuracy: 1.0000 - val_loss: 0.3288 - val_accuracy: 0.9259\n",
      "Epoch 40/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 3.6599e-04 - accuracy: 1.0000 - val_loss: 0.3266 - val_accuracy: 0.9074\n",
      "Epoch 41/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 3.4369e-04 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 0.9074\n",
      "Epoch 42/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 3.2868e-04 - accuracy: 1.0000 - val_loss: 0.3283 - val_accuracy: 0.9074\n",
      "Epoch 43/250\n",
      "124/124 [==============================] - 0s 677us/step - loss: 3.1014e-04 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 0.9074\n",
      "Epoch 44/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 2.9669e-04 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9074\n",
      "Epoch 45/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 2.7998e-04 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9074\n",
      "Epoch 46/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 2.6510e-04 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9074\n",
      "Epoch 47/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 2.5642e-04 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9074\n",
      "Epoch 48/250\n",
      "124/124 [==============================] - 0s 862us/step - loss: 2.4416e-04 - accuracy: 1.0000 - val_loss: 0.3468 - val_accuracy: 0.9074\n",
      "Epoch 49/250\n",
      "124/124 [==============================] - 0s 717us/step - loss: 2.3397e-04 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9074\n",
      "Epoch 50/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 2.2385e-04 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9074\n",
      "Epoch 51/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 2.1543e-04 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.9074\n",
      "Epoch 52/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 2.0556e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9074\n",
      "Epoch 53/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 1.9942e-04 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9074\n",
      "Epoch 54/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 1.9070e-04 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9074\n",
      "Epoch 55/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 1.8400e-04 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9074\n",
      "Epoch 56/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 1.7736e-04 - accuracy: 1.0000 - val_loss: 0.3623 - val_accuracy: 0.9074\n",
      "Epoch 57/250\n",
      "124/124 [==============================] - 0s 782us/step - loss: 1.6977e-04 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9074\n",
      "Epoch 58/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.6366e-04 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9074\n",
      "Epoch 59/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 1.5799e-04 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9074\n",
      "Epoch 60/250\n",
      "124/124 [==============================] - 0s 895us/step - loss: 1.5191e-04 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9074\n",
      "Epoch 61/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 1.4610e-04 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9074\n",
      "Epoch 62/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 1.4138e-04 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9074\n",
      "Epoch 63/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.3648e-04 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9074\n",
      "Epoch 64/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 1.3278e-04 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9074\n",
      "Epoch 65/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 1.2785e-04 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9074\n",
      "Epoch 66/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 1.2454e-04 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9074\n",
      "Epoch 67/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 1.2011e-04 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9074\n",
      "Epoch 68/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.1610e-04 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9074\n",
      "Epoch 69/250\n",
      "124/124 [==============================] - 0s 895us/step - loss: 1.1331e-04 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9074\n",
      "Epoch 70/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 1.1014e-04 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9074\n",
      "Epoch 71/250\n",
      "124/124 [==============================] - 0s 742us/step - loss: 1.0477e-04 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9074\n",
      "Epoch 72/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 1.0222e-04 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9074\n",
      "Epoch 73/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 9.9034e-05 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9074\n",
      "Epoch 74/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 9.5866e-05 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9074\n",
      "Epoch 75/250\n",
      "124/124 [==============================] - 0s 696us/step - loss: 9.2918e-05 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9074\n",
      "Epoch 76/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 9.0545e-05 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9074\n",
      "Epoch 77/250\n",
      "124/124 [==============================] - 0s 635us/step - loss: 8.7635e-05 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9074\n",
      "Epoch 78/250\n",
      "124/124 [==============================] - 0s 788us/step - loss: 8.5515e-05 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9074\n",
      "Epoch 79/250\n",
      "124/124 [==============================] - 0s 530us/step - loss: 8.3315e-05 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.9074\n",
      "Epoch 80/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 8.1042e-05 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9074\n",
      "Epoch 81/250\n",
      "124/124 [==============================] - 0s 742us/step - loss: 7.8563e-05 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9074\n",
      "Epoch 82/250\n",
      "124/124 [==============================] - 0s 800us/step - loss: 7.6965e-05 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9074\n",
      "Epoch 83/250\n",
      "124/124 [==============================] - 0s 656us/step - loss: 7.4753e-05 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9074\n",
      "Epoch 84/250\n",
      "124/124 [==============================] - 0s 965us/step - loss: 7.2524e-05 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9074\n",
      "Epoch 85/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 7.0750e-05 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9074\n",
      "Epoch 86/250\n",
      "124/124 [==============================] - 0s 758us/step - loss: 6.8717e-05 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.9074\n",
      "Epoch 87/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 6.6960e-05 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9074\n",
      "Epoch 88/250\n",
      "124/124 [==============================] - 0s 830us/step - loss: 6.5923e-05 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9074\n",
      "Epoch 89/250\n",
      "124/124 [==============================] - 0s 975us/step - loss: 6.3871e-05 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9074\n",
      "Epoch 90/250\n",
      "124/124 [==============================] - 0s 806us/step - loss: 6.2415e-05 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9074\n",
      "Epoch 91/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 6.0824e-05 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9074\n",
      "Epoch 92/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 5.9478e-05 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9074\n",
      "Epoch 93/250\n",
      "124/124 [==============================] - 0s 870us/step - loss: 5.7995e-05 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9074\n",
      "Epoch 94/250\n",
      "124/124 [==============================] - 0s 806us/step - loss: 5.7068e-05 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9074\n",
      "Epoch 95/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 5.5471e-05 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9074\n",
      "Epoch 96/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 5.4034e-05 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9074\n",
      "Epoch 97/250\n",
      "124/124 [==============================] - 0s 766us/step - loss: 5.3047e-05 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9074\n",
      "Epoch 98/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 5.1797e-05 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9074\n",
      "Epoch 99/250\n",
      "124/124 [==============================] - 0s 822us/step - loss: 5.1322e-05 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9074\n",
      "Epoch 100/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 4.9342e-05 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9074\n",
      "Epoch 101/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 4.8678e-05 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9074\n",
      "Epoch 102/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 4.7653e-05 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9074\n",
      "Epoch 103/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 4.6399e-05 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9074\n",
      "Epoch 104/250\n",
      "124/124 [==============================] - 0s 978us/step - loss: 4.5477e-05 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.9074\n",
      "Epoch 105/250\n",
      "124/124 [==============================] - 0s 766us/step - loss: 4.4159e-05 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.9074\n",
      "Epoch 106/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 4.3488e-05 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9074\n",
      "Epoch 107/250\n",
      "124/124 [==============================] - 0s 798us/step - loss: 4.2614e-05 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9074\n",
      "Epoch 108/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 4.1745e-05 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9074\n",
      "Epoch 109/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 4.0941e-05 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9074\n",
      "Epoch 110/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 4.0190e-05 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/250\n",
      "124/124 [==============================] - 0s 606us/step - loss: 3.9566e-05 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9074\n",
      "Epoch 112/250\n",
      "124/124 [==============================] - 0s 904us/step - loss: 3.8667e-05 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9074\n",
      "Epoch 113/250\n",
      "124/124 [==============================] - 0s 862us/step - loss: 3.7834e-05 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9074\n",
      "Epoch 114/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 3.7142e-05 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9074\n",
      "Epoch 115/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 3.6554e-05 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9074\n",
      "Epoch 116/250\n",
      "124/124 [==============================] - 0s 701us/step - loss: 3.5677e-05 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.9074\n",
      "Epoch 117/250\n",
      "124/124 [==============================] - 0s 822us/step - loss: 3.4953e-05 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9074\n",
      "Epoch 118/250\n",
      "124/124 [==============================] - 0s 830us/step - loss: 3.4338e-05 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9074\n",
      "Epoch 119/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 3.3762e-05 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9074\n",
      "Epoch 120/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 3.3138e-05 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.9074\n",
      "Epoch 121/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 3.2536e-05 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.9074\n",
      "Epoch 122/250\n",
      "124/124 [==============================] - 0s 806us/step - loss: 3.2110e-05 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9074\n",
      "Epoch 123/250\n",
      "124/124 [==============================] - 0s 822us/step - loss: 3.1366e-05 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9074\n",
      "Epoch 124/250\n",
      "124/124 [==============================] - 0s 701us/step - loss: 3.0913e-05 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9074\n",
      "Epoch 125/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 3.0330e-05 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9074\n",
      "Epoch 126/250\n",
      "124/124 [==============================] - 0s 830us/step - loss: 2.9815e-05 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9074\n",
      "Epoch 127/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 2.9256e-05 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9074\n",
      "Epoch 128/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 2.8859e-05 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9074\n",
      "Epoch 129/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 2.8310e-05 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9074\n",
      "Epoch 130/250\n",
      "124/124 [==============================] - 0s 870us/step - loss: 2.7670e-05 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9074\n",
      "Epoch 131/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 2.7269e-05 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9074\n",
      "Epoch 132/250\n",
      "124/124 [==============================] - 0s 742us/step - loss: 2.6709e-05 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9074\n",
      "Epoch 133/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 2.6344e-05 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9074\n",
      "Epoch 134/250\n",
      "124/124 [==============================] - 0s 701us/step - loss: 2.5759e-05 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9074\n",
      "Epoch 135/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 2.5496e-05 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9074\n",
      "Epoch 136/250\n",
      "124/124 [==============================] - 0s 766us/step - loss: 2.5168e-05 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9074\n",
      "Epoch 137/250\n",
      "124/124 [==============================] - 0s 733us/step - loss: 2.4610e-05 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9074\n",
      "Epoch 138/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 2.4386e-05 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9074\n",
      "Epoch 139/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 2.3957e-05 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9074\n",
      "Epoch 140/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.3566e-05 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.9074\n",
      "Epoch 141/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 2.3205e-05 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.9074\n",
      "Epoch 142/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 2.2814e-05 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9074\n",
      "Epoch 143/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 2.2421e-05 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9074\n",
      "Epoch 144/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 2.2158e-05 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9074\n",
      "Epoch 145/250\n",
      "124/124 [==============================] - 0s 975us/step - loss: 2.1860e-05 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9074\n",
      "Epoch 146/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 2.1569e-05 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9074\n",
      "Epoch 147/250\n",
      "124/124 [==============================] - 0s 927us/step - loss: 2.1202e-05 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9074\n",
      "Epoch 148/250\n",
      "124/124 [==============================] - 0s 959us/step - loss: 2.0876e-05 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9074\n",
      "Epoch 149/250\n",
      "124/124 [==============================] - 0s 935us/step - loss: 2.0568e-05 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9074\n",
      "Epoch 150/250\n",
      "124/124 [==============================] - 0s 533us/step - loss: 2.0356e-05 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9074\n",
      "Epoch 151/250\n",
      "124/124 [==============================] - 0s 990us/step - loss: 1.9954e-05 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9074\n",
      "Epoch 152/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.9690e-05 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.9074\n",
      "Epoch 153/250\n",
      "124/124 [==============================] - 0s 634us/step - loss: 1.9319e-05 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9074\n",
      "Epoch 154/250\n",
      "124/124 [==============================] - 0s 726us/step - loss: 1.9118e-05 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9074\n",
      "Epoch 155/250\n",
      "124/124 [==============================] - 0s 872us/step - loss: 1.8929e-05 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9074\n",
      "Epoch 156/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.8581e-05 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9074\n",
      "Epoch 157/250\n",
      "124/124 [==============================] - 0s 798us/step - loss: 1.8451e-05 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.9074\n",
      "Epoch 158/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.8034e-05 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9074\n",
      "Epoch 159/250\n",
      "124/124 [==============================] - 0s 807us/step - loss: 1.7796e-05 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9074\n",
      "Epoch 160/250\n",
      "124/124 [==============================] - 0s 935us/step - loss: 1.7562e-05 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9074\n",
      "Epoch 161/250\n",
      "124/124 [==============================] - 0s 879us/step - loss: 1.7404e-05 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9074\n",
      "Epoch 162/250\n",
      "124/124 [==============================] - 0s 782us/step - loss: 1.7200e-05 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9074\n",
      "Epoch 163/250\n",
      "124/124 [==============================] - 0s 717us/step - loss: 1.7026e-05 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9074\n",
      "Epoch 164/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.6725e-05 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9074\n",
      "Epoch 165/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 1.6441e-05 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.9074\n",
      "Epoch 166/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.6222e-05 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9074\n",
      "Epoch 167/250\n",
      "124/124 [==============================] - 0s 537us/step - loss: 1.5980e-05 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9074\n",
      "Epoch 168/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.5755e-05 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.9074\n",
      "Epoch 169/250\n",
      "124/124 [==============================] - 0s 587us/step - loss: 1.5568e-05 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.9074\n",
      "Epoch 170/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 1.5406e-05 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9074\n",
      "Epoch 171/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 1.5235e-05 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9074\n",
      "Epoch 172/250\n",
      "124/124 [==============================] - 0s 735us/step - loss: 1.5186e-05 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9074\n",
      "Epoch 173/250\n",
      "124/124 [==============================] - 0s 627us/step - loss: 1.4876e-05 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9074\n",
      "Epoch 174/250\n",
      "124/124 [==============================] - 0s 612us/step - loss: 1.4682e-05 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9074\n",
      "Epoch 175/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 1.4496e-05 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.9074\n",
      "Epoch 176/250\n",
      "124/124 [==============================] - 0s 798us/step - loss: 1.4304e-05 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9074\n",
      "Epoch 177/250\n",
      "124/124 [==============================] - 0s 650us/step - loss: 1.4103e-05 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9074\n",
      "Epoch 178/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.3868e-05 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9074\n",
      "Epoch 179/250\n",
      "124/124 [==============================] - 0s 728us/step - loss: 1.3674e-05 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9074\n",
      "Epoch 180/250\n",
      "124/124 [==============================] - 0s 756us/step - loss: 1.3565e-05 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9074\n",
      "Epoch 181/250\n",
      "124/124 [==============================] - 0s 919us/step - loss: 1.3372e-05 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9074\n",
      "Epoch 182/250\n",
      "124/124 [==============================] - 0s 701us/step - loss: 1.3209e-05 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9074\n",
      "Epoch 183/250\n",
      "124/124 [==============================] - 0s 454us/step - loss: 1.3053e-05 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9074\n",
      "Epoch 184/250\n",
      "124/124 [==============================] - 0s 543us/step - loss: 1.2906e-05 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.9074\n",
      "Epoch 185/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 1.2762e-05 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9074\n",
      "Epoch 186/250\n",
      "124/124 [==============================] - 0s 943us/step - loss: 1.2636e-05 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9074\n",
      "Epoch 187/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 1.2459e-05 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9074\n",
      "Epoch 188/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.2211e-05 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9074\n",
      "Epoch 189/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.2109e-05 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9074\n",
      "Epoch 190/250\n",
      "124/124 [==============================] - 0s 561us/step - loss: 1.1979e-05 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9074\n",
      "Epoch 191/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 1.1756e-05 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9074\n",
      "Epoch 192/250\n",
      "124/124 [==============================] - 0s 778us/step - loss: 1.1666e-05 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9074\n",
      "Epoch 193/250\n",
      "124/124 [==============================] - 0s 766us/step - loss: 1.1638e-05 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9074\n",
      "Epoch 194/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 1.1346e-05 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9074\n",
      "Epoch 195/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.1274e-05 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.9074\n",
      "Epoch 196/250\n",
      "124/124 [==============================] - 0s 565us/step - loss: 1.1184e-05 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.9074\n",
      "Epoch 197/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.0997e-05 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9074\n",
      "Epoch 198/250\n",
      "124/124 [==============================] - 0s 600us/step - loss: 1.0920e-05 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9074\n",
      "Epoch 199/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 1.0761e-05 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9074\n",
      "Epoch 200/250\n",
      "124/124 [==============================] - 0s 725us/step - loss: 1.0668e-05 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9074\n",
      "Epoch 201/250\n",
      "124/124 [==============================] - 0s 943us/step - loss: 1.0560e-05 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9074\n",
      "Epoch 202/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 1.0407e-05 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.9074\n",
      "Epoch 203/250\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 1.0241e-05 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9074\n",
      "Epoch 204/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.0139e-05 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9074\n",
      "Epoch 205/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 1.0224e-05 - accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 0.9074\n",
      "Epoch 206/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 1.0047e-05 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9074\n",
      "Epoch 207/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 9.8753e-06 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9074\n",
      "Epoch 208/250\n",
      "124/124 [==============================] - 0s 661us/step - loss: 9.8037e-06 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9074\n",
      "Epoch 209/250\n",
      "124/124 [==============================] - 0s 541us/step - loss: 9.6975e-06 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9074\n",
      "Epoch 210/250\n",
      "124/124 [==============================] - 0s 912us/step - loss: 9.4941e-06 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.9074\n",
      "Epoch 211/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 9.4956e-06 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.9074\n",
      "Epoch 212/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 9.3379e-06 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9074\n",
      "Epoch 213/250\n",
      "124/124 [==============================] - 0s 825us/step - loss: 9.2398e-06 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9074\n",
      "Epoch 214/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 9.0721e-06 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9074\n",
      "Epoch 215/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 8.9769e-06 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9074\n",
      "Epoch 216/250\n",
      "124/124 [==============================] - 0s 905us/step - loss: 8.9259e-06 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9074\n",
      "Epoch 217/250\n",
      "124/124 [==============================] - 0s 766us/step - loss: 8.8880e-06 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9074\n",
      "Epoch 218/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 8.7404e-06 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9074\n",
      "Epoch 219/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 443us/step - loss: 8.6154e-06 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9074\n",
      "Epoch 220/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 8.6072e-06 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.9074\n",
      "Epoch 221/250\n",
      "124/124 [==============================] - 0s 727us/step - loss: 8.5049e-06 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9074\n",
      "Epoch 222/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 8.3179e-06 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.9074\n",
      "Epoch 223/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 8.2957e-06 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9074\n",
      "Epoch 224/250\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 8.2659e-06 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9074\n",
      "Epoch 225/250\n",
      "124/124 [==============================] - 0s 733us/step - loss: 8.1198e-06 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9074\n",
      "Epoch 226/250\n",
      "124/124 [==============================] - 0s 701us/step - loss: 8.0626e-06 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9074\n",
      "Epoch 227/250\n",
      "124/124 [==============================] - 0s 537us/step - loss: 7.9141e-06 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9074\n",
      "Epoch 228/250\n",
      "124/124 [==============================] - 0s 565us/step - loss: 7.7905e-06 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9074\n",
      "Epoch 229/250\n",
      "124/124 [==============================] - 0s 716us/step - loss: 7.7804e-06 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.9074\n",
      "Epoch 230/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 7.6324e-06 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9074\n",
      "Epoch 231/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 7.6756e-06 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.9074\n",
      "Epoch 232/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 7.4560e-06 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9074\n",
      "Epoch 233/250\n",
      "124/124 [==============================] - 0s 583us/step - loss: 7.4291e-06 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9074\n",
      "Epoch 234/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 7.4132e-06 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9074\n",
      "Epoch 235/250\n",
      "124/124 [==============================] - 0s 608us/step - loss: 7.2209e-06 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.9074\n",
      "Epoch 236/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 7.2171e-06 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.9074\n",
      "Epoch 237/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 7.1950e-06 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9074\n",
      "Epoch 238/250\n",
      "124/124 [==============================] - 0s 620us/step - loss: 7.0767e-06 - accuracy: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.9074\n",
      "Epoch 239/250\n",
      "124/124 [==============================] - 0s 488us/step - loss: 7.0012e-06 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8889\n",
      "Epoch 240/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.9666e-06 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9074\n",
      "Epoch 241/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.8686e-06 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9074\n",
      "Epoch 242/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.7941e-06 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9074\n",
      "Epoch 243/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.7700e-06 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9074\n",
      "Epoch 244/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 6.6148e-06 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9074\n",
      "Epoch 245/250\n",
      "124/124 [==============================] - 0s 586us/step - loss: 6.6484e-06 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9074\n",
      "Epoch 246/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 6.6359e-06 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9074\n",
      "Epoch 247/250\n",
      "124/124 [==============================] - 0s 814us/step - loss: 6.5008e-06 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.8889\n",
      "Epoch 248/250\n",
      "124/124 [==============================] - 0s 895us/step - loss: 6.4701e-06 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.8889\n",
      "Epoch 249/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 6.3936e-06 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.8889\n",
      "Epoch 250/250\n",
      "124/124 [==============================] - 0s 545us/step - loss: 6.2682e-06 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.8889\n",
      "Test loss: 0.5014933082792494\n",
      "Test accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Nadam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=250,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
