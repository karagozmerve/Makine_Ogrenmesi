{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Merve\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/25\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 1.0982 - accuracy: 0.3306 - val_loss: 1.0969 - val_accuracy: 0.3704\n",
      "Epoch 2/25\n",
      "124/124 [==============================] - 0s 393us/step - loss: 1.0974 - accuracy: 0.3548 - val_loss: 1.0960 - val_accuracy: 0.3889\n",
      "Epoch 3/25\n",
      "124/124 [==============================] - 0s 484us/step - loss: 1.0965 - accuracy: 0.4194 - val_loss: 1.0951 - val_accuracy: 0.4259\n",
      "Epoch 4/25\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.0958 - accuracy: 0.4435 - val_loss: 1.0941 - val_accuracy: 0.5185\n",
      "Epoch 5/25\n",
      "124/124 [==============================] - 0s 388us/step - loss: 1.0948 - accuracy: 0.5000 - val_loss: 1.0933 - val_accuracy: 0.5370\n",
      "Epoch 6/25\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0940 - accuracy: 0.5403 - val_loss: 1.0926 - val_accuracy: 0.5370\n",
      "Epoch 7/25\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0933 - accuracy: 0.5242 - val_loss: 1.0918 - val_accuracy: 0.5741\n",
      "Epoch 8/25\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0926 - accuracy: 0.5323 - val_loss: 1.0912 - val_accuracy: 0.5741\n",
      "Epoch 9/25\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0919 - accuracy: 0.5484 - val_loss: 1.0904 - val_accuracy: 0.5741\n",
      "Epoch 10/25\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0912 - accuracy: 0.4516 - val_loss: 1.0897 - val_accuracy: 0.5741\n",
      "Epoch 11/25\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0905 - accuracy: 0.4597 - val_loss: 1.0888 - val_accuracy: 0.4815\n",
      "Epoch 12/25\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0896 - accuracy: 0.4274 - val_loss: 1.0879 - val_accuracy: 0.4259\n",
      "Epoch 13/25\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0889 - accuracy: 0.4032 - val_loss: 1.0870 - val_accuracy: 0.4259\n",
      "Epoch 14/25\n",
      "124/124 [==============================] - 0s 339us/step - loss: 1.0881 - accuracy: 0.4113 - val_loss: 1.0863 - val_accuracy: 0.4074\n",
      "Epoch 15/25\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0873 - accuracy: 0.3952 - val_loss: 1.0855 - val_accuracy: 0.4074\n",
      "Epoch 16/25\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0865 - accuracy: 0.3952 - val_loss: 1.0845 - val_accuracy: 0.4074\n",
      "Epoch 17/25\n",
      "124/124 [==============================] - 0s 484us/step - loss: 1.0856 - accuracy: 0.3952 - val_loss: 1.0838 - val_accuracy: 0.4074\n",
      "Epoch 18/25\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0849 - accuracy: 0.3952 - val_loss: 1.0832 - val_accuracy: 0.4074\n",
      "Epoch 19/25\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0843 - accuracy: 0.3952 - val_loss: 1.0826 - val_accuracy: 0.4074\n",
      "Epoch 20/25\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0837 - accuracy: 0.3952 - val_loss: 1.0817 - val_accuracy: 0.4074\n",
      "Epoch 21/25\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0829 - accuracy: 0.3952 - val_loss: 1.0810 - val_accuracy: 0.4074\n",
      "Epoch 22/25\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0822 - accuracy: 0.3952 - val_loss: 1.0802 - val_accuracy: 0.4074\n",
      "Epoch 23/25\n",
      "124/124 [==============================] - 0s 459us/step - loss: 1.0815 - accuracy: 0.3952 - val_loss: 1.0796 - val_accuracy: 0.4074\n",
      "Epoch 24/25\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0809 - accuracy: 0.3952 - val_loss: 1.0792 - val_accuracy: 0.4074\n",
      "Epoch 25/25\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.0803 - accuracy: 0.3952 - val_loss: 1.0785 - val_accuracy: 0.4074\n",
      "Test loss: 1.0784774356418185\n",
      "Test accuracy: 0.40740740299224854\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['accuracy'])\n",
    "plt.plot(training_model.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['loss'])\n",
    "plt.plot(training_model.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 1.0972 - accuracy: 0.4032 - val_loss: 1.0955 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0961 - accuracy: 0.4677 - val_loss: 1.0942 - val_accuracy: 0.4630\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0949 - accuracy: 0.4435 - val_loss: 1.0929 - val_accuracy: 0.4074\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0938 - accuracy: 0.4274 - val_loss: 1.0918 - val_accuracy: 0.4074\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0927 - accuracy: 0.4032 - val_loss: 1.0906 - val_accuracy: 0.4074\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0914 - accuracy: 0.3952 - val_loss: 1.0895 - val_accuracy: 0.4074\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 392us/step - loss: 1.0905 - accuracy: 0.3952 - val_loss: 1.0886 - val_accuracy: 0.4074\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0896 - accuracy: 0.3952 - val_loss: 1.0876 - val_accuracy: 0.4074\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0887 - accuracy: 0.3952 - val_loss: 1.0866 - val_accuracy: 0.4074\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 352us/step - loss: 1.0877 - accuracy: 0.3952 - val_loss: 1.0855 - val_accuracy: 0.4074\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0867 - accuracy: 0.3952 - val_loss: 1.0846 - val_accuracy: 0.4074\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0858 - accuracy: 0.3952 - val_loss: 1.0836 - val_accuracy: 0.4074\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 367us/step - loss: 1.0849 - accuracy: 0.3952 - val_loss: 1.0826 - val_accuracy: 0.4074\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0840 - accuracy: 0.3952 - val_loss: 1.0818 - val_accuracy: 0.4074\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0830 - accuracy: 0.3952 - val_loss: 1.0806 - val_accuracy: 0.4074\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 362us/step - loss: 1.0818 - accuracy: 0.3952 - val_loss: 1.0795 - val_accuracy: 0.4074\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0809 - accuracy: 0.3952 - val_loss: 1.0784 - val_accuracy: 0.4074\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0798 - accuracy: 0.3952 - val_loss: 1.0773 - val_accuracy: 0.4074\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0788 - accuracy: 0.3952 - val_loss: 1.0763 - val_accuracy: 0.4074\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 339us/step - loss: 1.0777 - accuracy: 0.3952 - val_loss: 1.0753 - val_accuracy: 0.4074\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0767 - accuracy: 0.3952 - val_loss: 1.0744 - val_accuracy: 0.4074\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 427us/step - loss: 1.0758 - accuracy: 0.3952 - val_loss: 1.0732 - val_accuracy: 0.4074\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0746 - accuracy: 0.3952 - val_loss: 1.0719 - val_accuracy: 0.4074\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0734 - accuracy: 0.3952 - val_loss: 1.0709 - val_accuracy: 0.4074\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0724 - accuracy: 0.3952 - val_loss: 1.0699 - val_accuracy: 0.4074\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.0715 - accuracy: 0.3952 - val_loss: 1.0687 - val_accuracy: 0.4074\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0704 - accuracy: 0.3952 - val_loss: 1.0675 - val_accuracy: 0.4074\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 467us/step - loss: 1.0691 - accuracy: 0.3952 - val_loss: 1.0663 - val_accuracy: 0.4074\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 492us/step - loss: 1.0680 - accuracy: 0.3952 - val_loss: 1.0652 - val_accuracy: 0.4074\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0668 - accuracy: 0.3952 - val_loss: 1.0641 - val_accuracy: 0.4074\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0656 - accuracy: 0.3952 - val_loss: 1.0629 - val_accuracy: 0.4074\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0645 - accuracy: 0.3952 - val_loss: 1.0615 - val_accuracy: 0.4074\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0631 - accuracy: 0.3952 - val_loss: 1.0603 - val_accuracy: 0.4074\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0619 - accuracy: 0.3952 - val_loss: 1.0591 - val_accuracy: 0.4074\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 427us/step - loss: 1.0606 - accuracy: 0.3952 - val_loss: 1.0579 - val_accuracy: 0.4074\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0594 - accuracy: 0.3952 - val_loss: 1.0568 - val_accuracy: 0.4074\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 467us/step - loss: 1.0581 - accuracy: 0.3952 - val_loss: 1.0558 - val_accuracy: 0.4074\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0566 - accuracy: 0.3952 - val_loss: 1.0541 - val_accuracy: 0.4074\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0552 - accuracy: 0.3952 - val_loss: 1.0530 - val_accuracy: 0.4074\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0540 - accuracy: 0.3952 - val_loss: 1.0513 - val_accuracy: 0.4074\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0523 - accuracy: 0.3952 - val_loss: 1.0497 - val_accuracy: 0.4074\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 476us/step - loss: 1.0509 - accuracy: 0.3952 - val_loss: 1.0484 - val_accuracy: 0.4074\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.0493 - accuracy: 0.3952 - val_loss: 1.0468 - val_accuracy: 0.4074\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0478 - accuracy: 0.3952 - val_loss: 1.0452 - val_accuracy: 0.4074\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0460 - accuracy: 0.3952 - val_loss: 1.0434 - val_accuracy: 0.4074\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0443 - accuracy: 0.3952 - val_loss: 1.0416 - val_accuracy: 0.4074\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 359us/step - loss: 1.0426 - accuracy: 0.3952 - val_loss: 1.0399 - val_accuracy: 0.4074\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0408 - accuracy: 0.3952 - val_loss: 1.0381 - val_accuracy: 0.4074\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0389 - accuracy: 0.3952 - val_loss: 1.0365 - val_accuracy: 0.4074\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0372 - accuracy: 0.3952 - val_loss: 1.0346 - val_accuracy: 0.4074\n",
      "Test loss: 1.0346124348817047\n",
      "Test accuracy: 0.40740740299224854\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='SGD', \n",
    "              metrics=['accuracy'])\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/150\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 1.0997 - accuracy: 0.3871 - val_loss: 1.0987 - val_accuracy: 0.3889\n",
      "Epoch 2/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0985 - accuracy: 0.4597 - val_loss: 1.0975 - val_accuracy: 0.4444\n",
      "Epoch 3/150\n",
      "124/124 [==============================] - 0s 311us/step - loss: 1.0974 - accuracy: 0.4355 - val_loss: 1.0961 - val_accuracy: 0.5370\n",
      "Epoch 4/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 1.0963 - accuracy: 0.4597 - val_loss: 1.0950 - val_accuracy: 0.5185\n",
      "Epoch 5/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0954 - accuracy: 0.4758 - val_loss: 1.0938 - val_accuracy: 0.5000\n",
      "Epoch 6/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 1.0942 - accuracy: 0.3952 - val_loss: 1.0927 - val_accuracy: 0.4074\n",
      "Epoch 7/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0933 - accuracy: 0.3871 - val_loss: 1.0919 - val_accuracy: 0.4074\n",
      "Epoch 8/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 1.0924 - accuracy: 0.3790 - val_loss: 1.0906 - val_accuracy: 0.4074\n",
      "Epoch 9/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0915 - accuracy: 0.3790 - val_loss: 1.0902 - val_accuracy: 0.4074\n",
      "Epoch 10/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 1.0908 - accuracy: 0.3871 - val_loss: 1.0893 - val_accuracy: 0.4074\n",
      "Epoch 11/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0900 - accuracy: 0.3952 - val_loss: 1.0887 - val_accuracy: 0.4074\n",
      "Epoch 12/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0894 - accuracy: 0.3952 - val_loss: 1.0878 - val_accuracy: 0.4074\n",
      "Epoch 13/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0887 - accuracy: 0.3952 - val_loss: 1.0871 - val_accuracy: 0.4074\n",
      "Epoch 14/150\n",
      "124/124 [==============================] - 0s 345us/step - loss: 1.0880 - accuracy: 0.3952 - val_loss: 1.0863 - val_accuracy: 0.4074\n",
      "Epoch 15/150\n",
      "124/124 [==============================] - 0s 409us/step - loss: 1.0871 - accuracy: 0.3952 - val_loss: 1.0854 - val_accuracy: 0.4074\n",
      "Epoch 16/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0863 - accuracy: 0.3952 - val_loss: 1.0843 - val_accuracy: 0.4074\n",
      "Epoch 17/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0856 - accuracy: 0.3952 - val_loss: 1.0834 - val_accuracy: 0.4074\n",
      "Epoch 18/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 1.0848 - accuracy: 0.3952 - val_loss: 1.0825 - val_accuracy: 0.4074\n",
      "Epoch 19/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0839 - accuracy: 0.3952 - val_loss: 1.0815 - val_accuracy: 0.4074\n",
      "Epoch 20/150\n",
      "124/124 [==============================] - 0s 475us/step - loss: 1.0832 - accuracy: 0.3952 - val_loss: 1.0808 - val_accuracy: 0.4074\n",
      "Epoch 21/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 1.0823 - accuracy: 0.3952 - val_loss: 1.0798 - val_accuracy: 0.4074\n",
      "Epoch 22/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.0815 - accuracy: 0.3952 - val_loss: 1.0789 - val_accuracy: 0.4074\n",
      "Epoch 23/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0807 - accuracy: 0.3952 - val_loss: 1.0778 - val_accuracy: 0.4074\n",
      "Epoch 24/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.0798 - accuracy: 0.3952 - val_loss: 1.0769 - val_accuracy: 0.4074\n",
      "Epoch 25/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0789 - accuracy: 0.3952 - val_loss: 1.0760 - val_accuracy: 0.4074\n",
      "Epoch 26/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0780 - accuracy: 0.3952 - val_loss: 1.0749 - val_accuracy: 0.4074\n",
      "Epoch 27/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0770 - accuracy: 0.3952 - val_loss: 1.0738 - val_accuracy: 0.4074\n",
      "Epoch 28/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0761 - accuracy: 0.3952 - val_loss: 1.0728 - val_accuracy: 0.4074\n",
      "Epoch 29/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 1.0751 - accuracy: 0.3952 - val_loss: 1.0718 - val_accuracy: 0.4074\n",
      "Epoch 30/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 1.0741 - accuracy: 0.3952 - val_loss: 1.0708 - val_accuracy: 0.4074\n",
      "Epoch 31/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0731 - accuracy: 0.3952 - val_loss: 1.0700 - val_accuracy: 0.4074\n",
      "Epoch 32/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.0721 - accuracy: 0.3952 - val_loss: 1.0691 - val_accuracy: 0.4074\n",
      "Epoch 33/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0712 - accuracy: 0.3952 - val_loss: 1.0682 - val_accuracy: 0.4074\n",
      "Epoch 34/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0701 - accuracy: 0.3952 - val_loss: 1.0673 - val_accuracy: 0.4074\n",
      "Epoch 35/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 1.0691 - accuracy: 0.3952 - val_loss: 1.0662 - val_accuracy: 0.4074\n",
      "Epoch 36/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0681 - accuracy: 0.3952 - val_loss: 1.0654 - val_accuracy: 0.4074\n",
      "Epoch 37/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0671 - accuracy: 0.3952 - val_loss: 1.0641 - val_accuracy: 0.4074\n",
      "Epoch 38/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 1.0659 - accuracy: 0.3952 - val_loss: 1.0629 - val_accuracy: 0.4074\n",
      "Epoch 39/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0649 - accuracy: 0.3952 - val_loss: 1.0615 - val_accuracy: 0.4074\n",
      "Epoch 40/150\n",
      "124/124 [==============================] - 0s 339us/step - loss: 1.0635 - accuracy: 0.3952 - val_loss: 1.0602 - val_accuracy: 0.4074\n",
      "Epoch 41/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0623 - accuracy: 0.3952 - val_loss: 1.0591 - val_accuracy: 0.4074\n",
      "Epoch 42/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0612 - accuracy: 0.3952 - val_loss: 1.0579 - val_accuracy: 0.4074\n",
      "Epoch 43/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0598 - accuracy: 0.3952 - val_loss: 1.0566 - val_accuracy: 0.4074\n",
      "Epoch 44/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0585 - accuracy: 0.3952 - val_loss: 1.0550 - val_accuracy: 0.4074\n",
      "Epoch 45/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0571 - accuracy: 0.3952 - val_loss: 1.0535 - val_accuracy: 0.4074\n",
      "Epoch 46/150\n",
      "124/124 [==============================] - 0s 354us/step - loss: 1.0556 - accuracy: 0.3952 - val_loss: 1.0519 - val_accuracy: 0.4074\n",
      "Epoch 47/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0540 - accuracy: 0.3952 - val_loss: 1.0510 - val_accuracy: 0.4074\n",
      "Epoch 48/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0527 - accuracy: 0.3952 - val_loss: 1.0495 - val_accuracy: 0.4074\n",
      "Epoch 49/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0511 - accuracy: 0.3952 - val_loss: 1.0480 - val_accuracy: 0.4074\n",
      "Epoch 50/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0498 - accuracy: 0.3952 - val_loss: 1.0463 - val_accuracy: 0.4074\n",
      "Epoch 51/150\n",
      "124/124 [==============================] - 0s 330us/step - loss: 1.0480 - accuracy: 0.3952 - val_loss: 1.0452 - val_accuracy: 0.4074\n",
      "Epoch 52/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0463 - accuracy: 0.3952 - val_loss: 1.0437 - val_accuracy: 0.4074\n",
      "Epoch 53/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0448 - accuracy: 0.3952 - val_loss: 1.0418 - val_accuracy: 0.4074\n",
      "Epoch 54/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0428 - accuracy: 0.3952 - val_loss: 1.0397 - val_accuracy: 0.4074\n",
      "Epoch 55/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0411 - accuracy: 0.3952 - val_loss: 1.0378 - val_accuracy: 0.4074\n",
      "Epoch 56/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0389 - accuracy: 0.3952 - val_loss: 1.0355 - val_accuracy: 0.4074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "124/124 [==============================] - 0s 355us/step - loss: 1.0369 - accuracy: 0.3952 - val_loss: 1.0333 - val_accuracy: 0.4074\n",
      "Epoch 58/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0349 - accuracy: 0.3952 - val_loss: 1.0313 - val_accuracy: 0.4074\n",
      "Epoch 59/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0326 - accuracy: 0.3952 - val_loss: 1.0291 - val_accuracy: 0.4074\n",
      "Epoch 60/150\n",
      "124/124 [==============================] - 0s 322us/step - loss: 1.0303 - accuracy: 0.3952 - val_loss: 1.0266 - val_accuracy: 0.4074\n",
      "Epoch 61/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0281 - accuracy: 0.3952 - val_loss: 1.0241 - val_accuracy: 0.4074\n",
      "Epoch 62/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0258 - accuracy: 0.3952 - val_loss: 1.0222 - val_accuracy: 0.4074\n",
      "Epoch 63/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0231 - accuracy: 0.3952 - val_loss: 1.0198 - val_accuracy: 0.4074\n",
      "Epoch 64/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0206 - accuracy: 0.3952 - val_loss: 1.0171 - val_accuracy: 0.4074\n",
      "Epoch 65/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0178 - accuracy: 0.3952 - val_loss: 1.0151 - val_accuracy: 0.4074\n",
      "Epoch 66/150\n",
      "124/124 [==============================] - 0s 475us/step - loss: 1.0149 - accuracy: 0.4032 - val_loss: 1.0124 - val_accuracy: 0.4074\n",
      "Epoch 67/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 1.0119 - accuracy: 0.4032 - val_loss: 1.0090 - val_accuracy: 0.4074\n",
      "Epoch 68/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0089 - accuracy: 0.3952 - val_loss: 1.0055 - val_accuracy: 0.4074\n",
      "Epoch 69/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0054 - accuracy: 0.3952 - val_loss: 1.0026 - val_accuracy: 0.4074\n",
      "Epoch 70/150\n",
      "124/124 [==============================] - 0s 447us/step - loss: 1.0022 - accuracy: 0.4113 - val_loss: 0.9989 - val_accuracy: 0.4074\n",
      "Epoch 71/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.9987 - accuracy: 0.4032 - val_loss: 0.9955 - val_accuracy: 0.4259\n",
      "Epoch 72/150\n",
      "124/124 [==============================] - 0s 397us/step - loss: 0.9950 - accuracy: 0.4113 - val_loss: 0.9915 - val_accuracy: 0.4630\n",
      "Epoch 73/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.9910 - accuracy: 0.4194 - val_loss: 0.9875 - val_accuracy: 0.4630\n",
      "Epoch 74/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.9869 - accuracy: 0.4274 - val_loss: 0.9835 - val_accuracy: 0.4630\n",
      "Epoch 75/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.9826 - accuracy: 0.4274 - val_loss: 0.9799 - val_accuracy: 0.5000\n",
      "Epoch 76/150\n",
      "124/124 [==============================] - 0s 392us/step - loss: 0.9783 - accuracy: 0.4435 - val_loss: 0.9755 - val_accuracy: 0.5000\n",
      "Epoch 77/150\n",
      "124/124 [==============================] - 0s 548us/step - loss: 0.9737 - accuracy: 0.4597 - val_loss: 0.9710 - val_accuracy: 0.5000\n",
      "Epoch 78/150\n",
      "124/124 [==============================] - 0s 556us/step - loss: 0.9691 - accuracy: 0.4597 - val_loss: 0.9660 - val_accuracy: 0.5000\n",
      "Epoch 79/150\n",
      "124/124 [==============================] - 0s 441us/step - loss: 0.9641 - accuracy: 0.4516 - val_loss: 0.9611 - val_accuracy: 0.5000\n",
      "Epoch 80/150\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.9587 - accuracy: 0.4597 - val_loss: 0.9567 - val_accuracy: 0.5185\n",
      "Epoch 81/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.9526 - accuracy: 0.4758 - val_loss: 0.9511 - val_accuracy: 0.5185\n",
      "Epoch 82/150\n",
      "124/124 [==============================] - 0s 421us/step - loss: 0.9472 - accuracy: 0.5242 - val_loss: 0.9454 - val_accuracy: 0.5370\n",
      "Epoch 83/150\n",
      "124/124 [==============================] - 0s 516us/step - loss: 0.9410 - accuracy: 0.5484 - val_loss: 0.9393 - val_accuracy: 0.5741\n",
      "Epoch 84/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.9346 - accuracy: 0.6048 - val_loss: 0.9335 - val_accuracy: 0.5741\n",
      "Epoch 85/150\n",
      "124/124 [==============================] - 0s 524us/step - loss: 0.9276 - accuracy: 0.6048 - val_loss: 0.9268 - val_accuracy: 0.5741\n",
      "Epoch 86/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.9209 - accuracy: 0.6290 - val_loss: 0.9202 - val_accuracy: 0.5741\n",
      "Epoch 87/150\n",
      "124/124 [==============================] - 0s 524us/step - loss: 0.9137 - accuracy: 0.6210 - val_loss: 0.9140 - val_accuracy: 0.5741\n",
      "Epoch 88/150\n",
      "124/124 [==============================] - 0s 524us/step - loss: 0.9058 - accuracy: 0.6371 - val_loss: 0.9060 - val_accuracy: 0.5926\n",
      "Epoch 89/150\n",
      "124/124 [==============================] - 0s 472us/step - loss: 0.8977 - accuracy: 0.6935 - val_loss: 0.8982 - val_accuracy: 0.6852\n",
      "Epoch 90/150\n",
      "124/124 [==============================] - 0s 468us/step - loss: 0.8896 - accuracy: 0.7661 - val_loss: 0.8911 - val_accuracy: 0.7037\n",
      "Epoch 91/150\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.8801 - accuracy: 0.7500 - val_loss: 0.8819 - val_accuracy: 0.7593\n",
      "Epoch 92/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.8713 - accuracy: 0.7903 - val_loss: 0.8727 - val_accuracy: 0.7963\n",
      "Epoch 93/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.8621 - accuracy: 0.7984 - val_loss: 0.8635 - val_accuracy: 0.8148\n",
      "Epoch 94/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.8521 - accuracy: 0.8145 - val_loss: 0.8553 - val_accuracy: 0.8148\n",
      "Epoch 95/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.8416 - accuracy: 0.8145 - val_loss: 0.8454 - val_accuracy: 0.7963\n",
      "Epoch 96/150\n",
      "124/124 [==============================] - 0s 492us/step - loss: 0.8308 - accuracy: 0.8468 - val_loss: 0.8351 - val_accuracy: 0.7963\n",
      "Epoch 97/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.8195 - accuracy: 0.8226 - val_loss: 0.8246 - val_accuracy: 0.7963\n",
      "Epoch 98/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.8083 - accuracy: 0.8548 - val_loss: 0.8140 - val_accuracy: 0.8148\n",
      "Epoch 99/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.7964 - accuracy: 0.8871 - val_loss: 0.8026 - val_accuracy: 0.8333\n",
      "Epoch 100/150\n",
      "124/124 [==============================] - 0s 516us/step - loss: 0.7845 - accuracy: 0.8871 - val_loss: 0.7910 - val_accuracy: 0.8519\n",
      "Epoch 101/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.7723 - accuracy: 0.8952 - val_loss: 0.7791 - val_accuracy: 0.8704\n",
      "Epoch 102/150\n",
      "124/124 [==============================] - 0s 483us/step - loss: 0.7593 - accuracy: 0.8952 - val_loss: 0.7680 - val_accuracy: 0.8704\n",
      "Epoch 103/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.7466 - accuracy: 0.8952 - val_loss: 0.7560 - val_accuracy: 0.8519\n",
      "Epoch 104/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.7323 - accuracy: 0.8952 - val_loss: 0.7431 - val_accuracy: 0.8704\n",
      "Epoch 105/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.7188 - accuracy: 0.9113 - val_loss: 0.7302 - val_accuracy: 0.8889\n",
      "Epoch 106/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.7051 - accuracy: 0.9113 - val_loss: 0.7171 - val_accuracy: 0.8889\n",
      "Epoch 107/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.6909 - accuracy: 0.9435 - val_loss: 0.7042 - val_accuracy: 0.8889\n",
      "Epoch 108/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.6767 - accuracy: 0.9435 - val_loss: 0.6909 - val_accuracy: 0.8889\n",
      "Epoch 109/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.6619 - accuracy: 0.9355 - val_loss: 0.6780 - val_accuracy: 0.8889\n",
      "Epoch 110/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.6465 - accuracy: 0.9274 - val_loss: 0.6637 - val_accuracy: 0.8889\n",
      "Epoch 111/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.6314 - accuracy: 0.9274 - val_loss: 0.6504 - val_accuracy: 0.8889\n",
      "Epoch 112/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.6159 - accuracy: 0.9274 - val_loss: 0.6366 - val_accuracy: 0.9074\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 484us/step - loss: 0.6027 - accuracy: 0.9274 - val_loss: 0.6233 - val_accuracy: 0.8889\n",
      "Epoch 114/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.5880 - accuracy: 0.9032 - val_loss: 0.6100 - val_accuracy: 0.8889\n",
      "Epoch 115/150\n",
      "124/124 [==============================] - 0s 460us/step - loss: 0.5720 - accuracy: 0.9355 - val_loss: 0.5972 - val_accuracy: 0.8889\n",
      "Epoch 116/150\n",
      "124/124 [==============================] - 0s 455us/step - loss: 0.5575 - accuracy: 0.9274 - val_loss: 0.5841 - val_accuracy: 0.8889\n",
      "Epoch 117/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.5418 - accuracy: 0.9274 - val_loss: 0.5718 - val_accuracy: 0.8704\n",
      "Epoch 118/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.5281 - accuracy: 0.9194 - val_loss: 0.5589 - val_accuracy: 0.8704\n",
      "Epoch 119/150\n",
      "124/124 [==============================] - 0s 430us/step - loss: 0.5131 - accuracy: 0.9194 - val_loss: 0.5462 - val_accuracy: 0.8704\n",
      "Epoch 120/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.4990 - accuracy: 0.9194 - val_loss: 0.5357 - val_accuracy: 0.8704\n",
      "Epoch 121/150\n",
      "124/124 [==============================] - 0s 441us/step - loss: 0.4845 - accuracy: 0.9194 - val_loss: 0.5246 - val_accuracy: 0.8704\n",
      "Epoch 122/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.4721 - accuracy: 0.9113 - val_loss: 0.5125 - val_accuracy: 0.8704\n",
      "Epoch 123/150\n",
      "124/124 [==============================] - 0s 409us/step - loss: 0.4580 - accuracy: 0.9274 - val_loss: 0.5025 - val_accuracy: 0.8704\n",
      "Epoch 124/150\n",
      "124/124 [==============================] - 0s 404us/step - loss: 0.4461 - accuracy: 0.9355 - val_loss: 0.4925 - val_accuracy: 0.8704\n",
      "Epoch 125/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.4332 - accuracy: 0.9113 - val_loss: 0.4820 - val_accuracy: 0.8704\n",
      "Epoch 126/150\n",
      "124/124 [==============================] - 0s 391us/step - loss: 0.4205 - accuracy: 0.9194 - val_loss: 0.4743 - val_accuracy: 0.8704\n",
      "Epoch 127/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.4075 - accuracy: 0.9113 - val_loss: 0.4643 - val_accuracy: 0.8704\n",
      "Epoch 128/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.3966 - accuracy: 0.9113 - val_loss: 0.4591 - val_accuracy: 0.8704\n",
      "Epoch 129/150\n",
      "124/124 [==============================] - 0s 396us/step - loss: 0.3871 - accuracy: 0.9194 - val_loss: 0.4474 - val_accuracy: 0.8704\n",
      "Epoch 130/150\n",
      "124/124 [==============================] - 0s 376us/step - loss: 0.3747 - accuracy: 0.9274 - val_loss: 0.4395 - val_accuracy: 0.8704\n",
      "Epoch 131/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.3622 - accuracy: 0.9194 - val_loss: 0.4364 - val_accuracy: 0.8704\n",
      "Epoch 132/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.3529 - accuracy: 0.9194 - val_loss: 0.4378 - val_accuracy: 0.8519\n",
      "Epoch 133/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.3458 - accuracy: 0.9194 - val_loss: 0.4246 - val_accuracy: 0.8704\n",
      "Epoch 134/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.3333 - accuracy: 0.9355 - val_loss: 0.4147 - val_accuracy: 0.8704\n",
      "Epoch 135/150\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.3237 - accuracy: 0.9355 - val_loss: 0.4087 - val_accuracy: 0.8704\n",
      "Epoch 136/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.3171 - accuracy: 0.9194 - val_loss: 0.4052 - val_accuracy: 0.8704\n",
      "Epoch 137/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.3062 - accuracy: 0.9355 - val_loss: 0.3992 - val_accuracy: 0.8704\n",
      "Epoch 138/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.2994 - accuracy: 0.9435 - val_loss: 0.3905 - val_accuracy: 0.8704\n",
      "Epoch 139/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2905 - accuracy: 0.9516 - val_loss: 0.3922 - val_accuracy: 0.8704\n",
      "Epoch 140/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.2842 - accuracy: 0.9194 - val_loss: 0.3904 - val_accuracy: 0.8704\n",
      "Epoch 141/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2773 - accuracy: 0.9194 - val_loss: 0.3823 - val_accuracy: 0.8704\n",
      "Epoch 142/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2699 - accuracy: 0.9355 - val_loss: 0.3777 - val_accuracy: 0.8704\n",
      "Epoch 143/150\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.2619 - accuracy: 0.9435 - val_loss: 0.3871 - val_accuracy: 0.8704\n",
      "Epoch 144/150\n",
      "124/124 [==============================] - 0s 328us/step - loss: 0.2547 - accuracy: 0.9435 - val_loss: 0.3784 - val_accuracy: 0.8704\n",
      "Epoch 145/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.2507 - accuracy: 0.9355 - val_loss: 0.3786 - val_accuracy: 0.8704\n",
      "Epoch 146/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2436 - accuracy: 0.9355 - val_loss: 0.3737 - val_accuracy: 0.8704\n",
      "Epoch 147/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.2377 - accuracy: 0.9435 - val_loss: 0.3765 - val_accuracy: 0.8704\n",
      "Epoch 148/150\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2335 - accuracy: 0.9355 - val_loss: 0.3632 - val_accuracy: 0.8704\n",
      "Epoch 149/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.2256 - accuracy: 0.9435 - val_loss: 0.3604 - val_accuracy: 0.8704\n",
      "Epoch 150/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2201 - accuracy: 0.9435 - val_loss: 0.3584 - val_accuracy: 0.8704\n",
      "Test loss: 0.35841288500361973\n",
      "Test accuracy: 0.8703703880310059\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=150,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/250\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 1.0978 - accuracy: 0.4516 - val_loss: 1.0969 - val_accuracy: 0.4444\n",
      "Epoch 2/250\n",
      "124/124 [==============================] - 0s 475us/step - loss: 1.0971 - accuracy: 0.4274 - val_loss: 1.0958 - val_accuracy: 0.4630\n",
      "Epoch 3/250\n",
      "124/124 [==============================] - 0s 392us/step - loss: 1.0961 - accuracy: 0.4355 - val_loss: 1.0950 - val_accuracy: 0.4259\n",
      "Epoch 4/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0953 - accuracy: 0.3952 - val_loss: 1.0940 - val_accuracy: 0.4074\n",
      "Epoch 5/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.0944 - accuracy: 0.3952 - val_loss: 1.0931 - val_accuracy: 0.4074\n",
      "Epoch 6/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0937 - accuracy: 0.3952 - val_loss: 1.0926 - val_accuracy: 0.4074\n",
      "Epoch 7/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0931 - accuracy: 0.3952 - val_loss: 1.0917 - val_accuracy: 0.4074\n",
      "Epoch 8/250\n",
      "124/124 [==============================] - 0s 342us/step - loss: 1.0923 - accuracy: 0.3952 - val_loss: 1.0910 - val_accuracy: 0.4074\n",
      "Epoch 9/250\n",
      "124/124 [==============================] - 0s 452us/step - loss: 1.0917 - accuracy: 0.3952 - val_loss: 1.0901 - val_accuracy: 0.4074\n",
      "Epoch 10/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0909 - accuracy: 0.3952 - val_loss: 1.0893 - val_accuracy: 0.4074\n",
      "Epoch 11/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0904 - accuracy: 0.3952 - val_loss: 1.0887 - val_accuracy: 0.4074\n",
      "Epoch 12/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0897 - accuracy: 0.3952 - val_loss: 1.0878 - val_accuracy: 0.4074\n",
      "Epoch 13/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0888 - accuracy: 0.3952 - val_loss: 1.0872 - val_accuracy: 0.4074\n",
      "Epoch 14/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 1.0883 - accuracy: 0.3952 - val_loss: 1.0864 - val_accuracy: 0.4074\n",
      "Epoch 15/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0875 - accuracy: 0.3952 - val_loss: 1.0858 - val_accuracy: 0.4074\n",
      "Epoch 16/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0870 - accuracy: 0.3952 - val_loss: 1.0851 - val_accuracy: 0.4074\n",
      "Epoch 17/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0863 - accuracy: 0.3952 - val_loss: 1.0844 - val_accuracy: 0.4074\n",
      "Epoch 18/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.0856 - accuracy: 0.3952 - val_loss: 1.0838 - val_accuracy: 0.4074\n",
      "Epoch 19/250\n",
      "124/124 [==============================] - 0s 390us/step - loss: 1.0849 - accuracy: 0.3952 - val_loss: 1.0832 - val_accuracy: 0.4074\n",
      "Epoch 20/250\n",
      "124/124 [==============================] - 0s 339us/step - loss: 1.0844 - accuracy: 0.3952 - val_loss: 1.0825 - val_accuracy: 0.4074\n",
      "Epoch 21/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0837 - accuracy: 0.3952 - val_loss: 1.0819 - val_accuracy: 0.4074\n",
      "Epoch 22/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0830 - accuracy: 0.3952 - val_loss: 1.0812 - val_accuracy: 0.4074\n",
      "Epoch 23/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0824 - accuracy: 0.3952 - val_loss: 1.0804 - val_accuracy: 0.4074\n",
      "Epoch 24/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0818 - accuracy: 0.3952 - val_loss: 1.0799 - val_accuracy: 0.4074\n",
      "Epoch 25/250\n",
      "124/124 [==============================] - 0s 398us/step - loss: 1.0811 - accuracy: 0.3952 - val_loss: 1.0793 - val_accuracy: 0.4074\n",
      "Epoch 26/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0804 - accuracy: 0.3952 - val_loss: 1.0786 - val_accuracy: 0.4074\n",
      "Epoch 27/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.0797 - accuracy: 0.3952 - val_loss: 1.0779 - val_accuracy: 0.4074\n",
      "Epoch 28/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0790 - accuracy: 0.3952 - val_loss: 1.0772 - val_accuracy: 0.4074\n",
      "Epoch 29/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0783 - accuracy: 0.3952 - val_loss: 1.0764 - val_accuracy: 0.4074\n",
      "Epoch 30/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0776 - accuracy: 0.3952 - val_loss: 1.0758 - val_accuracy: 0.4074\n",
      "Epoch 31/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0768 - accuracy: 0.3952 - val_loss: 1.0750 - val_accuracy: 0.4074\n",
      "Epoch 32/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0761 - accuracy: 0.3952 - val_loss: 1.0741 - val_accuracy: 0.4074\n",
      "Epoch 33/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0754 - accuracy: 0.3952 - val_loss: 1.0732 - val_accuracy: 0.4074\n",
      "Epoch 34/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0745 - accuracy: 0.3952 - val_loss: 1.0723 - val_accuracy: 0.4074\n",
      "Epoch 35/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 1.0736 - accuracy: 0.3952 - val_loss: 1.0715 - val_accuracy: 0.4074\n",
      "Epoch 36/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 1.0728 - accuracy: 0.3952 - val_loss: 1.0709 - val_accuracy: 0.4074\n",
      "Epoch 37/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 1.0721 - accuracy: 0.3952 - val_loss: 1.0699 - val_accuracy: 0.4074\n",
      "Epoch 38/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 1.0712 - accuracy: 0.3952 - val_loss: 1.0690 - val_accuracy: 0.4074\n",
      "Epoch 39/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 1.0704 - accuracy: 0.3952 - val_loss: 1.0681 - val_accuracy: 0.4074\n",
      "Epoch 40/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 1.0696 - accuracy: 0.3952 - val_loss: 1.0672 - val_accuracy: 0.4074\n",
      "Epoch 41/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 1.0687 - accuracy: 0.3952 - val_loss: 1.0661 - val_accuracy: 0.4074\n",
      "Epoch 42/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 1.0677 - accuracy: 0.3952 - val_loss: 1.0652 - val_accuracy: 0.4074\n",
      "Epoch 43/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 1.0668 - accuracy: 0.3952 - val_loss: 1.0641 - val_accuracy: 0.4074\n",
      "Epoch 44/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0659 - accuracy: 0.3952 - val_loss: 1.0630 - val_accuracy: 0.4074\n",
      "Epoch 45/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0649 - accuracy: 0.3952 - val_loss: 1.0619 - val_accuracy: 0.4074\n",
      "Epoch 46/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0637 - accuracy: 0.3952 - val_loss: 1.0609 - val_accuracy: 0.4074\n",
      "Epoch 47/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0628 - accuracy: 0.3952 - val_loss: 1.0598 - val_accuracy: 0.4074\n",
      "Epoch 48/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 1.0618 - accuracy: 0.3952 - val_loss: 1.0587 - val_accuracy: 0.4074\n",
      "Epoch 49/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0607 - accuracy: 0.3952 - val_loss: 1.0574 - val_accuracy: 0.4074\n",
      "Epoch 50/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0595 - accuracy: 0.3952 - val_loss: 1.0563 - val_accuracy: 0.4074\n",
      "Epoch 51/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0585 - accuracy: 0.3952 - val_loss: 1.0551 - val_accuracy: 0.4074\n",
      "Epoch 52/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0574 - accuracy: 0.3952 - val_loss: 1.0537 - val_accuracy: 0.4074\n",
      "Epoch 53/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0561 - accuracy: 0.3952 - val_loss: 1.0524 - val_accuracy: 0.4074\n",
      "Epoch 54/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 1.0548 - accuracy: 0.3952 - val_loss: 1.0512 - val_accuracy: 0.4074\n",
      "Epoch 55/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0535 - accuracy: 0.3952 - val_loss: 1.0498 - val_accuracy: 0.4074\n",
      "Epoch 56/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0524 - accuracy: 0.3952 - val_loss: 1.0484 - val_accuracy: 0.4074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 1.0509 - accuracy: 0.3952 - val_loss: 1.0471 - val_accuracy: 0.4074\n",
      "Epoch 58/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0495 - accuracy: 0.3952 - val_loss: 1.0455 - val_accuracy: 0.4074\n",
      "Epoch 59/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 1.0481 - accuracy: 0.3952 - val_loss: 1.0443 - val_accuracy: 0.4074\n",
      "Epoch 60/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0467 - accuracy: 0.3952 - val_loss: 1.0429 - val_accuracy: 0.4074\n",
      "Epoch 61/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0452 - accuracy: 0.3952 - val_loss: 1.0413 - val_accuracy: 0.4074\n",
      "Epoch 62/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0436 - accuracy: 0.3952 - val_loss: 1.0395 - val_accuracy: 0.4074\n",
      "Epoch 63/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0421 - accuracy: 0.3952 - val_loss: 1.0376 - val_accuracy: 0.4074\n",
      "Epoch 64/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0403 - accuracy: 0.3952 - val_loss: 1.0360 - val_accuracy: 0.4074\n",
      "Epoch 65/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0385 - accuracy: 0.3952 - val_loss: 1.0340 - val_accuracy: 0.4074\n",
      "Epoch 66/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 1.0366 - accuracy: 0.3952 - val_loss: 1.0321 - val_accuracy: 0.4074\n",
      "Epoch 67/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 1.0347 - accuracy: 0.3952 - val_loss: 1.0302 - val_accuracy: 0.4074\n",
      "Epoch 68/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 1.0328 - accuracy: 0.3952 - val_loss: 1.0284 - val_accuracy: 0.4074\n",
      "Epoch 69/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 1.0308 - accuracy: 0.3952 - val_loss: 1.0264 - val_accuracy: 0.4074\n",
      "Epoch 70/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0288 - accuracy: 0.3952 - val_loss: 1.0242 - val_accuracy: 0.4074\n",
      "Epoch 71/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0266 - accuracy: 0.3952 - val_loss: 1.0221 - val_accuracy: 0.4074\n",
      "Epoch 72/250\n",
      "124/124 [==============================] - 0s 330us/step - loss: 1.0245 - accuracy: 0.3952 - val_loss: 1.0196 - val_accuracy: 0.4074\n",
      "Epoch 73/250\n",
      "124/124 [==============================] - 0s 323us/step - loss: 1.0222 - accuracy: 0.3952 - val_loss: 1.0173 - val_accuracy: 0.4074\n",
      "Epoch 74/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0198 - accuracy: 0.3952 - val_loss: 1.0148 - val_accuracy: 0.4074\n",
      "Epoch 75/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0173 - accuracy: 0.3952 - val_loss: 1.0123 - val_accuracy: 0.4074\n",
      "Epoch 76/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 1.0147 - accuracy: 0.3952 - val_loss: 1.0096 - val_accuracy: 0.4074\n",
      "Epoch 77/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0120 - accuracy: 0.3952 - val_loss: 1.0069 - val_accuracy: 0.4074\n",
      "Epoch 78/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0092 - accuracy: 0.3952 - val_loss: 1.0045 - val_accuracy: 0.4074\n",
      "Epoch 79/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 1.0065 - accuracy: 0.3952 - val_loss: 1.0016 - val_accuracy: 0.4074\n",
      "Epoch 80/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 1.0035 - accuracy: 0.3952 - val_loss: 0.9986 - val_accuracy: 0.4074\n",
      "Epoch 81/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0004 - accuracy: 0.3952 - val_loss: 0.9955 - val_accuracy: 0.4074\n",
      "Epoch 82/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.9969 - accuracy: 0.3952 - val_loss: 0.9919 - val_accuracy: 0.4074\n",
      "Epoch 83/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.9933 - accuracy: 0.3952 - val_loss: 0.9886 - val_accuracy: 0.4074\n",
      "Epoch 84/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.9900 - accuracy: 0.3952 - val_loss: 0.9851 - val_accuracy: 0.4074\n",
      "Epoch 85/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.9863 - accuracy: 0.3952 - val_loss: 0.9810 - val_accuracy: 0.4074\n",
      "Epoch 86/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.9823 - accuracy: 0.3952 - val_loss: 0.9770 - val_accuracy: 0.4074\n",
      "Epoch 87/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.9783 - accuracy: 0.3952 - val_loss: 0.9729 - val_accuracy: 0.4074\n",
      "Epoch 88/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.9740 - accuracy: 0.3952 - val_loss: 0.9688 - val_accuracy: 0.4074\n",
      "Epoch 89/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.9697 - accuracy: 0.3952 - val_loss: 0.9647 - val_accuracy: 0.4074\n",
      "Epoch 90/250\n",
      "124/124 [==============================] - 0s 323us/step - loss: 0.9654 - accuracy: 0.3952 - val_loss: 0.9596 - val_accuracy: 0.4074\n",
      "Epoch 91/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.9604 - accuracy: 0.3952 - val_loss: 0.9547 - val_accuracy: 0.4074\n",
      "Epoch 92/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.9553 - accuracy: 0.3952 - val_loss: 0.9499 - val_accuracy: 0.4074\n",
      "Epoch 93/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.9501 - accuracy: 0.3952 - val_loss: 0.9447 - val_accuracy: 0.4074\n",
      "Epoch 94/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.9445 - accuracy: 0.4032 - val_loss: 0.9387 - val_accuracy: 0.4074\n",
      "Epoch 95/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.9386 - accuracy: 0.4194 - val_loss: 0.9330 - val_accuracy: 0.4074\n",
      "Epoch 96/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.9326 - accuracy: 0.4355 - val_loss: 0.9275 - val_accuracy: 0.4630\n",
      "Epoch 97/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.9267 - accuracy: 0.4516 - val_loss: 0.9209 - val_accuracy: 0.5000\n",
      "Epoch 98/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.9198 - accuracy: 0.5161 - val_loss: 0.9141 - val_accuracy: 0.5185\n",
      "Epoch 99/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.9133 - accuracy: 0.5806 - val_loss: 0.9069 - val_accuracy: 0.6296\n",
      "Epoch 100/250\n",
      "124/124 [==============================] - 0s 339us/step - loss: 0.9060 - accuracy: 0.6290 - val_loss: 0.8996 - val_accuracy: 0.6481\n",
      "Epoch 101/250\n",
      "124/124 [==============================] - 0s 315us/step - loss: 0.8985 - accuracy: 0.6532 - val_loss: 0.8926 - val_accuracy: 0.7037\n",
      "Epoch 102/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.8908 - accuracy: 0.7097 - val_loss: 0.8851 - val_accuracy: 0.7037\n",
      "Epoch 103/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.8832 - accuracy: 0.7419 - val_loss: 0.8770 - val_accuracy: 0.7037\n",
      "Epoch 104/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.8746 - accuracy: 0.7581 - val_loss: 0.8685 - val_accuracy: 0.7963\n",
      "Epoch 105/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.8659 - accuracy: 0.7903 - val_loss: 0.8591 - val_accuracy: 0.8148\n",
      "Epoch 106/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.8565 - accuracy: 0.7903 - val_loss: 0.8501 - val_accuracy: 0.8148\n",
      "Epoch 107/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.8474 - accuracy: 0.8468 - val_loss: 0.8414 - val_accuracy: 0.8148\n",
      "Epoch 108/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.8380 - accuracy: 0.8226 - val_loss: 0.8314 - val_accuracy: 0.8889\n",
      "Epoch 109/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.8281 - accuracy: 0.8629 - val_loss: 0.8215 - val_accuracy: 0.8889\n",
      "Epoch 110/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.8180 - accuracy: 0.8710 - val_loss: 0.8108 - val_accuracy: 0.8889\n",
      "Epoch 111/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.8065 - accuracy: 0.8790 - val_loss: 0.8000 - val_accuracy: 0.9074\n",
      "Epoch 112/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.7951 - accuracy: 0.8790 - val_loss: 0.7887 - val_accuracy: 0.8889\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 363us/step - loss: 0.7834 - accuracy: 0.8790 - val_loss: 0.7772 - val_accuracy: 0.8889\n",
      "Epoch 114/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.7712 - accuracy: 0.8790 - val_loss: 0.7654 - val_accuracy: 0.9074\n",
      "Epoch 115/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.7599 - accuracy: 0.8790 - val_loss: 0.7532 - val_accuracy: 0.9074\n",
      "Epoch 116/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.7471 - accuracy: 0.8871 - val_loss: 0.7407 - val_accuracy: 0.8889\n",
      "Epoch 117/250\n",
      "124/124 [==============================] - 0s 384us/step - loss: 0.7345 - accuracy: 0.8871 - val_loss: 0.7283 - val_accuracy: 0.8704\n",
      "Epoch 118/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.7210 - accuracy: 0.8871 - val_loss: 0.7148 - val_accuracy: 0.9074\n",
      "Epoch 119/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.7065 - accuracy: 0.8790 - val_loss: 0.7013 - val_accuracy: 0.8889\n",
      "Epoch 120/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.6924 - accuracy: 0.8710 - val_loss: 0.6877 - val_accuracy: 0.8889\n",
      "Epoch 121/250\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.6769 - accuracy: 0.8790 - val_loss: 0.6743 - val_accuracy: 0.8889\n",
      "Epoch 122/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.6623 - accuracy: 0.9032 - val_loss: 0.6594 - val_accuracy: 0.8889\n",
      "Epoch 123/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.6465 - accuracy: 0.8710 - val_loss: 0.6443 - val_accuracy: 0.8889\n",
      "Epoch 124/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.6310 - accuracy: 0.8952 - val_loss: 0.6291 - val_accuracy: 0.8889\n",
      "Epoch 125/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.6153 - accuracy: 0.8871 - val_loss: 0.6142 - val_accuracy: 0.8889\n",
      "Epoch 126/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.5993 - accuracy: 0.9113 - val_loss: 0.5988 - val_accuracy: 0.8889\n",
      "Epoch 127/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.5830 - accuracy: 0.9032 - val_loss: 0.5838 - val_accuracy: 0.8889\n",
      "Epoch 128/250\n",
      "124/124 [==============================] - 0s 350us/step - loss: 0.5682 - accuracy: 0.8790 - val_loss: 0.5688 - val_accuracy: 0.8889\n",
      "Epoch 129/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.5526 - accuracy: 0.9032 - val_loss: 0.5561 - val_accuracy: 0.8889\n",
      "Epoch 130/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.5376 - accuracy: 0.8871 - val_loss: 0.5391 - val_accuracy: 0.8889\n",
      "Epoch 131/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.5196 - accuracy: 0.8871 - val_loss: 0.5251 - val_accuracy: 0.9074\n",
      "Epoch 132/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.5042 - accuracy: 0.8871 - val_loss: 0.5096 - val_accuracy: 0.8889\n",
      "Epoch 133/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.4878 - accuracy: 0.8952 - val_loss: 0.4964 - val_accuracy: 0.8889\n",
      "Epoch 134/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.4722 - accuracy: 0.9194 - val_loss: 0.4826 - val_accuracy: 0.8889\n",
      "Epoch 135/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.4593 - accuracy: 0.8952 - val_loss: 0.4692 - val_accuracy: 0.8889\n",
      "Epoch 136/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.4442 - accuracy: 0.8952 - val_loss: 0.4575 - val_accuracy: 0.8889\n",
      "Epoch 137/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.4300 - accuracy: 0.8952 - val_loss: 0.4450 - val_accuracy: 0.8889\n",
      "Epoch 138/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.4172 - accuracy: 0.8952 - val_loss: 0.4350 - val_accuracy: 0.8704\n",
      "Epoch 139/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.4038 - accuracy: 0.8952 - val_loss: 0.4246 - val_accuracy: 0.8704\n",
      "Epoch 140/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.3901 - accuracy: 0.8952 - val_loss: 0.4129 - val_accuracy: 0.8704\n",
      "Epoch 141/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.3783 - accuracy: 0.8952 - val_loss: 0.4040 - val_accuracy: 0.8704\n",
      "Epoch 142/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.3682 - accuracy: 0.8952 - val_loss: 0.3970 - val_accuracy: 0.8704\n",
      "Epoch 143/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.3586 - accuracy: 0.9032 - val_loss: 0.3906 - val_accuracy: 0.8704\n",
      "Epoch 144/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.3465 - accuracy: 0.8952 - val_loss: 0.3826 - val_accuracy: 0.8704\n",
      "Epoch 145/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.3360 - accuracy: 0.8952 - val_loss: 0.3783 - val_accuracy: 0.8704\n",
      "Epoch 146/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.3311 - accuracy: 0.8952 - val_loss: 0.3706 - val_accuracy: 0.8704\n",
      "Epoch 147/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.3198 - accuracy: 0.9032 - val_loss: 0.3662 - val_accuracy: 0.8704\n",
      "Epoch 148/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.3123 - accuracy: 0.9032 - val_loss: 0.3586 - val_accuracy: 0.8704\n",
      "Epoch 149/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.3037 - accuracy: 0.8952 - val_loss: 0.3545 - val_accuracy: 0.8704\n",
      "Epoch 150/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.2955 - accuracy: 0.9032 - val_loss: 0.3463 - val_accuracy: 0.8704\n",
      "Epoch 151/250\n",
      "124/124 [==============================] - 0s 331us/step - loss: 0.2930 - accuracy: 0.8871 - val_loss: 0.3510 - val_accuracy: 0.8704\n",
      "Epoch 152/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2841 - accuracy: 0.9032 - val_loss: 0.3382 - val_accuracy: 0.8704\n",
      "Epoch 153/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2787 - accuracy: 0.8952 - val_loss: 0.3364 - val_accuracy: 0.8704\n",
      "Epoch 154/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2714 - accuracy: 0.8952 - val_loss: 0.3441 - val_accuracy: 0.8704\n",
      "Epoch 155/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.2680 - accuracy: 0.9032 - val_loss: 0.3371 - val_accuracy: 0.8704\n",
      "Epoch 156/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2584 - accuracy: 0.9032 - val_loss: 0.3305 - val_accuracy: 0.8704\n",
      "Epoch 157/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.2543 - accuracy: 0.8952 - val_loss: 0.3301 - val_accuracy: 0.8704\n",
      "Epoch 158/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.2488 - accuracy: 0.9032 - val_loss: 0.3253 - val_accuracy: 0.8704\n",
      "Epoch 159/250\n",
      "124/124 [==============================] - 0s 346us/step - loss: 0.2459 - accuracy: 0.9032 - val_loss: 0.3273 - val_accuracy: 0.8704\n",
      "Epoch 160/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2406 - accuracy: 0.9032 - val_loss: 0.3302 - val_accuracy: 0.8704\n",
      "Epoch 161/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.2352 - accuracy: 0.9032 - val_loss: 0.3306 - val_accuracy: 0.8704\n",
      "Epoch 162/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2331 - accuracy: 0.9032 - val_loss: 0.3148 - val_accuracy: 0.8704\n",
      "Epoch 163/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2307 - accuracy: 0.8952 - val_loss: 0.3234 - val_accuracy: 0.8704\n",
      "Epoch 164/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2226 - accuracy: 0.9194 - val_loss: 0.3113 - val_accuracy: 0.8704\n",
      "Epoch 165/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2223 - accuracy: 0.9032 - val_loss: 0.3140 - val_accuracy: 0.8704\n",
      "Epoch 166/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.2158 - accuracy: 0.9032 - val_loss: 0.3135 - val_accuracy: 0.8704\n",
      "Epoch 167/250\n",
      "124/124 [==============================] - 0s 386us/step - loss: 0.2148 - accuracy: 0.9113 - val_loss: 0.3421 - val_accuracy: 0.8704\n",
      "Epoch 168/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.2114 - accuracy: 0.9274 - val_loss: 0.3094 - val_accuracy: 0.8704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2071 - accuracy: 0.9113 - val_loss: 0.3210 - val_accuracy: 0.8704\n",
      "Epoch 170/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.2012 - accuracy: 0.9194 - val_loss: 0.3136 - val_accuracy: 0.8704\n",
      "Epoch 171/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.2009 - accuracy: 0.9113 - val_loss: 0.3256 - val_accuracy: 0.8704\n",
      "Epoch 172/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.1955 - accuracy: 0.9113 - val_loss: 0.3516 - val_accuracy: 0.8704\n",
      "Epoch 173/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.2005 - accuracy: 0.9113 - val_loss: 0.3405 - val_accuracy: 0.8704\n",
      "Epoch 174/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.1940 - accuracy: 0.9194 - val_loss: 0.3049 - val_accuracy: 0.8889\n",
      "Epoch 175/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1917 - accuracy: 0.9113 - val_loss: 0.3153 - val_accuracy: 0.8704\n",
      "Epoch 176/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.1850 - accuracy: 0.9274 - val_loss: 0.3209 - val_accuracy: 0.8704\n",
      "Epoch 177/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.1831 - accuracy: 0.9194 - val_loss: 0.3191 - val_accuracy: 0.8704\n",
      "Epoch 178/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1795 - accuracy: 0.9274 - val_loss: 0.3203 - val_accuracy: 0.8704\n",
      "Epoch 179/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.1770 - accuracy: 0.9194 - val_loss: 0.3169 - val_accuracy: 0.8704\n",
      "Epoch 180/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1802 - accuracy: 0.9355 - val_loss: 0.3488 - val_accuracy: 0.8704\n",
      "Epoch 181/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1772 - accuracy: 0.9274 - val_loss: 0.3151 - val_accuracy: 0.8704\n",
      "Epoch 182/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.1694 - accuracy: 0.9355 - val_loss: 0.3077 - val_accuracy: 0.8889\n",
      "Epoch 183/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1714 - accuracy: 0.9274 - val_loss: 0.3411 - val_accuracy: 0.8704\n",
      "Epoch 184/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.1688 - accuracy: 0.9355 - val_loss: 0.3560 - val_accuracy: 0.8704\n",
      "Epoch 185/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.1682 - accuracy: 0.9355 - val_loss: 0.3201 - val_accuracy: 0.8704\n",
      "Epoch 186/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1629 - accuracy: 0.9516 - val_loss: 0.3107 - val_accuracy: 0.8889\n",
      "Epoch 187/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.1623 - accuracy: 0.9355 - val_loss: 0.2985 - val_accuracy: 0.8889\n",
      "Epoch 188/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.1621 - accuracy: 0.9435 - val_loss: 0.3146 - val_accuracy: 0.8889\n",
      "Epoch 189/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.1560 - accuracy: 0.9274 - val_loss: 0.3307 - val_accuracy: 0.8889\n",
      "Epoch 190/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.1523 - accuracy: 0.9435 - val_loss: 0.3255 - val_accuracy: 0.8704\n",
      "Epoch 191/250\n",
      "124/124 [==============================] - 0s 333us/step - loss: 0.1534 - accuracy: 0.9355 - val_loss: 0.3013 - val_accuracy: 0.8889\n",
      "Epoch 192/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1607 - accuracy: 0.9435 - val_loss: 0.3089 - val_accuracy: 0.8889\n",
      "Epoch 193/250\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.1518 - accuracy: 0.9355 - val_loss: 0.3228 - val_accuracy: 0.8889\n",
      "Epoch 194/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 0.1454 - accuracy: 0.9355 - val_loss: 0.3296 - val_accuracy: 0.8889\n",
      "Epoch 195/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.1435 - accuracy: 0.9597 - val_loss: 0.3487 - val_accuracy: 0.8704\n",
      "Epoch 196/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1462 - accuracy: 0.9435 - val_loss: 0.3130 - val_accuracy: 0.8889\n",
      "Epoch 197/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.1430 - accuracy: 0.9355 - val_loss: 0.3306 - val_accuracy: 0.8889\n",
      "Epoch 198/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1418 - accuracy: 0.9435 - val_loss: 0.3245 - val_accuracy: 0.9074\n",
      "Epoch 199/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1372 - accuracy: 0.9597 - val_loss: 0.3259 - val_accuracy: 0.8889\n",
      "Epoch 200/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.1335 - accuracy: 0.9597 - val_loss: 0.3565 - val_accuracy: 0.8889\n",
      "Epoch 201/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1373 - accuracy: 0.9597 - val_loss: 0.3428 - val_accuracy: 0.8704\n",
      "Epoch 202/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.1312 - accuracy: 0.9597 - val_loss: 0.3133 - val_accuracy: 0.8889\n",
      "Epoch 203/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.1287 - accuracy: 0.9677 - val_loss: 0.3198 - val_accuracy: 0.8889\n",
      "Epoch 204/250\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.1283 - accuracy: 0.9597 - val_loss: 0.3234 - val_accuracy: 0.8889\n",
      "Epoch 205/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.1298 - accuracy: 0.9597 - val_loss: 0.3357 - val_accuracy: 0.9259\n",
      "Epoch 206/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.1248 - accuracy: 0.9677 - val_loss: 0.3337 - val_accuracy: 0.9259\n",
      "Epoch 207/250\n",
      "124/124 [==============================] - 0s 335us/step - loss: 0.1286 - accuracy: 0.9516 - val_loss: 0.3262 - val_accuracy: 0.8889\n",
      "Epoch 208/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.1209 - accuracy: 0.9677 - val_loss: 0.3201 - val_accuracy: 0.8889\n",
      "Epoch 209/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1254 - accuracy: 0.9516 - val_loss: 0.3063 - val_accuracy: 0.8889\n",
      "Epoch 210/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.1206 - accuracy: 0.9597 - val_loss: 0.3430 - val_accuracy: 0.9259\n",
      "Epoch 211/250\n",
      "124/124 [==============================] - 0s 355us/step - loss: 0.1179 - accuracy: 0.9597 - val_loss: 0.3435 - val_accuracy: 0.9259\n",
      "Epoch 212/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.1203 - accuracy: 0.9516 - val_loss: 0.3413 - val_accuracy: 0.9259\n",
      "Epoch 213/250\n",
      "124/124 [==============================] - 0s 347us/step - loss: 0.1176 - accuracy: 0.9516 - val_loss: 0.3182 - val_accuracy: 0.8889\n",
      "Epoch 214/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1146 - accuracy: 0.9516 - val_loss: 0.3327 - val_accuracy: 0.9074\n",
      "Epoch 215/250\n",
      "124/124 [==============================] - 0s 314us/step - loss: 0.1142 - accuracy: 0.9677 - val_loss: 0.3149 - val_accuracy: 0.8889\n",
      "Epoch 216/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.1126 - accuracy: 0.9597 - val_loss: 0.3048 - val_accuracy: 0.8889\n",
      "Epoch 217/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.1168 - accuracy: 0.9597 - val_loss: 0.4099 - val_accuracy: 0.8519\n",
      "Epoch 218/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.1327 - accuracy: 0.9516 - val_loss: 0.3479 - val_accuracy: 0.9074\n",
      "Epoch 219/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.1083 - accuracy: 0.9758 - val_loss: 0.3354 - val_accuracy: 0.9074\n",
      "Epoch 220/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.1045 - accuracy: 0.9677 - val_loss: 0.3334 - val_accuracy: 0.9074\n",
      "Epoch 221/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1049 - accuracy: 0.9597 - val_loss: 0.3557 - val_accuracy: 0.9074\n",
      "Epoch 222/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1067 - accuracy: 0.9677 - val_loss: 0.3431 - val_accuracy: 0.9259\n",
      "Epoch 223/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.1020 - accuracy: 0.9677 - val_loss: 0.3465 - val_accuracy: 0.9259\n",
      "Epoch 224/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.1017 - accuracy: 0.9758 - val_loss: 0.3328 - val_accuracy: 0.9074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/250\n",
      "124/124 [==============================] - 0s 330us/step - loss: 0.1003 - accuracy: 0.9677 - val_loss: 0.3558 - val_accuracy: 0.9074\n",
      "Epoch 226/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.1050 - accuracy: 0.9597 - val_loss: 0.3255 - val_accuracy: 0.8889\n",
      "Epoch 227/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.1010 - accuracy: 0.9677 - val_loss: 0.3268 - val_accuracy: 0.8889\n",
      "Epoch 228/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.0975 - accuracy: 0.9677 - val_loss: 0.3130 - val_accuracy: 0.8889\n",
      "Epoch 229/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0992 - accuracy: 0.9677 - val_loss: 0.3275 - val_accuracy: 0.8889\n",
      "Epoch 230/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0983 - accuracy: 0.9677 - val_loss: 0.3766 - val_accuracy: 0.9074\n",
      "Epoch 231/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 0.0980 - accuracy: 0.9677 - val_loss: 0.3754 - val_accuracy: 0.9074\n",
      "Epoch 232/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0950 - accuracy: 0.9758 - val_loss: 0.3496 - val_accuracy: 0.9074\n",
      "Epoch 233/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 0.0931 - accuracy: 0.9758 - val_loss: 0.3474 - val_accuracy: 0.9259\n",
      "Epoch 234/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 0.0919 - accuracy: 0.9758 - val_loss: 0.3419 - val_accuracy: 0.9259\n",
      "Epoch 235/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0972 - accuracy: 0.9677 - val_loss: 0.3364 - val_accuracy: 0.9074\n",
      "Epoch 236/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0890 - accuracy: 0.9839 - val_loss: 0.3645 - val_accuracy: 0.9074\n",
      "Epoch 237/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0875 - accuracy: 0.9758 - val_loss: 0.3137 - val_accuracy: 0.8889\n",
      "Epoch 238/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.0937 - accuracy: 0.9758 - val_loss: 0.3560 - val_accuracy: 0.9259\n",
      "Epoch 239/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 0.0926 - accuracy: 0.9677 - val_loss: 0.3594 - val_accuracy: 0.9259\n",
      "Epoch 240/250\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0874 - accuracy: 0.9758 - val_loss: 0.3474 - val_accuracy: 0.9259\n",
      "Epoch 241/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0849 - accuracy: 0.9839 - val_loss: 0.3440 - val_accuracy: 0.9259\n",
      "Epoch 242/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.0885 - accuracy: 0.9677 - val_loss: 0.3409 - val_accuracy: 0.9259\n",
      "Epoch 243/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 0.0844 - accuracy: 0.9839 - val_loss: 0.3464 - val_accuracy: 0.9259\n",
      "Epoch 244/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 0.0882 - accuracy: 0.9758 - val_loss: 0.3496 - val_accuracy: 0.9259\n",
      "Epoch 245/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0806 - accuracy: 0.9839 - val_loss: 0.3452 - val_accuracy: 0.9259\n",
      "Epoch 246/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.0831 - accuracy: 0.9758 - val_loss: 0.3477 - val_accuracy: 0.9259\n",
      "Epoch 247/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.0892 - accuracy: 0.9758 - val_loss: 0.3541 - val_accuracy: 0.9259\n",
      "Epoch 248/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 0.0846 - accuracy: 0.9677 - val_loss: 0.3618 - val_accuracy: 0.9259\n",
      "Epoch 249/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.0782 - accuracy: 0.9758 - val_loss: 0.3520 - val_accuracy: 0.9259\n",
      "Epoch 250/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 0.0777 - accuracy: 0.9758 - val_loss: 0.3403 - val_accuracy: 0.9074\n",
      "Test loss: 0.34025640316583494\n",
      "Test accuracy: 0.9074074029922485\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=250,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
