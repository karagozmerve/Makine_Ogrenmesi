{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 0s 3ms/step - loss: 1.0913 - accuracy: 0.3952 - val_loss: 1.0776 - val_accuracy: 0.4074\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.0651 - accuracy: 0.4032 - val_loss: 1.0365 - val_accuracy: 0.4074\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 438us/step - loss: 1.0015 - accuracy: 0.4274 - val_loss: 0.9251 - val_accuracy: 0.7037\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.8351 - accuracy: 0.7823 - val_loss: 0.6758 - val_accuracy: 0.7963\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.5608 - accuracy: 0.8306 - val_loss: 0.3876 - val_accuracy: 0.9074\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 345us/step - loss: 0.2419 - accuracy: 0.9435 - val_loss: 0.6794 - val_accuracy: 0.6852\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 496us/step - loss: 0.2198 - accuracy: 0.8952 - val_loss: 0.2464 - val_accuracy: 0.8704\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 408us/step - loss: 0.2162 - accuracy: 0.9194 - val_loss: 0.2512 - val_accuracy: 0.9259\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.1119 - accuracy: 0.9758 - val_loss: 0.2108 - val_accuracy: 0.9074\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 392us/step - loss: 0.1351 - accuracy: 0.9677 - val_loss: 0.2831 - val_accuracy: 0.9074\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 399us/step - loss: 0.1076 - accuracy: 0.9758 - val_loss: 0.2002 - val_accuracy: 0.9074\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.1056 - accuracy: 0.9597 - val_loss: 0.1971 - val_accuracy: 0.9259\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0654 - accuracy: 0.9839 - val_loss: 0.1971 - val_accuracy: 0.9074\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0536 - accuracy: 0.9839 - val_loss: 0.2177 - val_accuracy: 0.9074\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 439us/step - loss: 0.0508 - accuracy: 0.9758 - val_loss: 0.4157 - val_accuracy: 0.8889\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0900 - accuracy: 0.9677 - val_loss: 0.2338 - val_accuracy: 0.9259\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0460 - accuracy: 0.9839 - val_loss: 0.2149 - val_accuracy: 0.9259\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0360 - accuracy: 0.9758 - val_loss: 0.2177 - val_accuracy: 0.9259\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0290 - accuracy: 0.9839 - val_loss: 0.2680 - val_accuracy: 0.9259\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 424us/step - loss: 0.0400 - accuracy: 0.9839 - val_loss: 0.3109 - val_accuracy: 0.9074\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.0401 - accuracy: 0.9839 - val_loss: 0.3053 - val_accuracy: 0.9259\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 516us/step - loss: 0.0202 - accuracy: 0.9919 - val_loss: 0.2357 - val_accuracy: 0.9259\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 516us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.3196 - val_accuracy: 0.9259\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 526us/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9259\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0216 - accuracy: 0.9919 - val_loss: 0.2373 - val_accuracy: 0.9074\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0171 - accuracy: 0.9919 - val_loss: 0.2802 - val_accuracy: 0.9259\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9259\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.2697 - val_accuracy: 0.9259\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 613us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9074\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 548us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.3162 - val_accuracy: 0.9259\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3022 - val_accuracy: 0.9259\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.9259\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.2974 - val_accuracy: 0.9259\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 473us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3213 - val_accuracy: 0.9259\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 588us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9259\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 492us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9074\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.9259\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 476us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.8889\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9259\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9259\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 404us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9259\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9259\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 0.9259\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9074\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9259\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 359us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3270 - val_accuracy: 0.9259\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9074\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 380us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9259\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 434us/step - loss: 9.9233e-04 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9259\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 508us/step - loss: 8.9394e-04 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9074\n",
      "Test loss: 0.3730047815651805\n",
      "Test accuracy: 0.9074074029922485\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['accuracy'])\n",
    "plt.plot(training_model.history['val_accuracy'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(training_model.history['loss'])\n",
    "plt.plot(training_model.history['val_loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/50\n",
      "124/124 [==============================] - 2s 13ms/step - loss: 1.0931 - accuracy: 0.4516 - val_loss: 1.0762 - val_accuracy: 0.5926\n",
      "Epoch 2/50\n",
      "124/124 [==============================] - 0s 571us/step - loss: 1.0636 - accuracy: 0.5645 - val_loss: 1.0296 - val_accuracy: 0.6852\n",
      "Epoch 3/50\n",
      "124/124 [==============================] - 0s 356us/step - loss: 0.9886 - accuracy: 0.6371 - val_loss: 0.9083 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.7954 - accuracy: 0.7419 - val_loss: 0.6210 - val_accuracy: 0.9444\n",
      "Epoch 5/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.4742 - accuracy: 0.8871 - val_loss: 0.4091 - val_accuracy: 0.8148\n",
      "Epoch 6/50\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.2301 - accuracy: 0.9355 - val_loss: 1.1453 - val_accuracy: 0.6296\n",
      "Epoch 7/50\n",
      "124/124 [==============================] - 0s 308us/step - loss: 0.2320 - accuracy: 0.9355 - val_loss: 0.1485 - val_accuracy: 0.9444\n",
      "Epoch 8/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.1801 - accuracy: 0.9274 - val_loss: 0.6900 - val_accuracy: 0.7222\n",
      "Epoch 9/50\n",
      "124/124 [==============================] - 0s 450us/step - loss: 0.1670 - accuracy: 0.9113 - val_loss: 0.3455 - val_accuracy: 0.8704\n",
      "Epoch 10/50\n",
      "124/124 [==============================] - 0s 264us/step - loss: 0.1103 - accuracy: 0.9758 - val_loss: 0.1190 - val_accuracy: 0.9630\n",
      "Epoch 11/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0983 - accuracy: 0.9758 - val_loss: 0.1532 - val_accuracy: 0.9259\n",
      "Epoch 12/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0757 - accuracy: 0.9677 - val_loss: 0.1598 - val_accuracy: 0.9259\n",
      "Epoch 13/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.1273 - val_accuracy: 0.9815\n",
      "Epoch 14/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0793 - accuracy: 0.9758 - val_loss: 0.1647 - val_accuracy: 0.9259\n",
      "Epoch 15/50\n",
      "124/124 [==============================] - 0s 504us/step - loss: 0.0564 - accuracy: 0.9839 - val_loss: 0.2106 - val_accuracy: 0.9259\n",
      "Epoch 16/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0393 - accuracy: 0.9839 - val_loss: 0.2041 - val_accuracy: 0.9259\n",
      "Epoch 17/50\n",
      "124/124 [==============================] - 0s 400us/step - loss: 0.0615 - accuracy: 0.9758 - val_loss: 0.1677 - val_accuracy: 0.9259\n",
      "Epoch 18/50\n",
      "124/124 [==============================] - 0s 434us/step - loss: 0.0439 - accuracy: 0.9758 - val_loss: 0.1632 - val_accuracy: 0.9259\n",
      "Epoch 19/50\n",
      "124/124 [==============================] - 0s 371us/step - loss: 0.0404 - accuracy: 0.9758 - val_loss: 0.2041 - val_accuracy: 0.9259\n",
      "Epoch 20/50\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0273 - accuracy: 0.9839 - val_loss: 0.1565 - val_accuracy: 0.9815\n",
      "Epoch 21/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0287 - accuracy: 0.9839 - val_loss: 0.1784 - val_accuracy: 0.9259\n",
      "Epoch 22/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.2612 - val_accuracy: 0.9259\n",
      "Epoch 23/50\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0185 - accuracy: 0.9919 - val_loss: 0.1739 - val_accuracy: 0.9444\n",
      "Epoch 24/50\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 0.9259\n",
      "Epoch 25/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.1704 - val_accuracy: 0.9630\n",
      "Epoch 26/50\n",
      "124/124 [==============================] - 0s 240us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9259\n",
      "Epoch 27/50\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9444\n",
      "Epoch 28/50\n",
      "124/124 [==============================] - 0s 389us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2520 - val_accuracy: 0.9259\n",
      "Epoch 29/50\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.2181 - val_accuracy: 0.9259\n",
      "Epoch 30/50\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.2488 - val_accuracy: 0.9259\n",
      "Epoch 31/50\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9259\n",
      "Epoch 32/50\n",
      "124/124 [==============================] - 0s 345us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9259\n",
      "Epoch 33/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2374 - val_accuracy: 0.9259\n",
      "Epoch 34/50\n",
      "124/124 [==============================] - 0s 504us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2185 - val_accuracy: 0.9259\n",
      "Epoch 35/50\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2226 - val_accuracy: 0.9259\n",
      "Epoch 36/50\n",
      "124/124 [==============================] - 0s 495us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2507 - val_accuracy: 0.9259\n",
      "Epoch 37/50\n",
      "124/124 [==============================] - 0s 410us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2459 - val_accuracy: 0.9259\n",
      "Epoch 38/50\n",
      "124/124 [==============================] - 0s 798us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2549 - val_accuracy: 0.9259\n",
      "Epoch 39/50\n",
      "124/124 [==============================] - 0s 685us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2342 - val_accuracy: 0.9259\n",
      "Epoch 40/50\n",
      "124/124 [==============================] - 0s 328us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2159 - val_accuracy: 0.9630\n",
      "Epoch 41/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2660 - val_accuracy: 0.9259\n",
      "Epoch 42/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2267 - val_accuracy: 0.9444\n",
      "Epoch 43/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2423 - val_accuracy: 0.9259\n",
      "Epoch 44/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9259\n",
      "Epoch 45/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.5784e-04 - accuracy: 1.0000 - val_loss: 0.2236 - val_accuracy: 0.9630\n",
      "Epoch 46/50\n",
      "124/124 [==============================] - 0s 533us/step - loss: 9.7234e-04 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9259\n",
      "Epoch 47/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.6683e-04 - accuracy: 1.0000 - val_loss: 0.2538 - val_accuracy: 0.9259\n",
      "Epoch 48/50\n",
      "124/124 [==============================] - 0s 504us/step - loss: 7.2186e-04 - accuracy: 1.0000 - val_loss: 0.3075 - val_accuracy: 0.9259\n",
      "Epoch 49/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.9542e-04 - accuracy: 1.0000 - val_loss: 0.2536 - val_accuracy: 0.9259\n",
      "Epoch 50/50\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.1528e-04 - accuracy: 1.0000 - val_loss: 0.2599 - val_accuracy: 0.9259\n",
      "Test loss: 0.2599046259635576\n",
      "Test accuracy: 0.9259259104728699\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/150\n",
      "124/124 [==============================] - 1s 7ms/step - loss: 1.0927 - accuracy: 0.4919 - val_loss: 1.0820 - val_accuracy: 0.4259\n",
      "Epoch 2/150\n",
      "124/124 [==============================] - 0s 366us/step - loss: 1.0705 - accuracy: 0.4355 - val_loss: 1.0482 - val_accuracy: 0.5370\n",
      "Epoch 3/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.0168 - accuracy: 0.6694 - val_loss: 0.9466 - val_accuracy: 0.6667\n",
      "Epoch 4/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 0.8506 - accuracy: 0.7903 - val_loss: 0.6582 - val_accuracy: 0.8148\n",
      "Epoch 5/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.5305 - accuracy: 0.8871 - val_loss: 0.5334 - val_accuracy: 0.6852\n",
      "Epoch 6/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.3002 - accuracy: 0.8871 - val_loss: 0.2575 - val_accuracy: 0.9074\n",
      "Epoch 7/150\n",
      "124/124 [==============================] - 0s 560us/step - loss: 0.1698 - accuracy: 0.9435 - val_loss: 1.4484 - val_accuracy: 0.7037\n",
      "Epoch 8/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.2126 - accuracy: 0.9435 - val_loss: 0.2326 - val_accuracy: 0.8889\n",
      "Epoch 9/150\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.1107 - accuracy: 0.9597 - val_loss: 0.1942 - val_accuracy: 0.8889\n",
      "Epoch 10/150\n",
      "124/124 [==============================] - 0s 492us/step - loss: 0.0668 - accuracy: 0.9758 - val_loss: 0.3142 - val_accuracy: 0.8889\n",
      "Epoch 11/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0772 - accuracy: 0.9677 - val_loss: 1.2260 - val_accuracy: 0.7037\n",
      "Epoch 12/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.1649 - accuracy: 0.9597 - val_loss: 0.3648 - val_accuracy: 0.8889\n",
      "Epoch 13/150\n",
      "124/124 [==============================] - 0s 363us/step - loss: 0.0709 - accuracy: 0.9839 - val_loss: 0.3226 - val_accuracy: 0.8889\n",
      "Epoch 14/150\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0550 - accuracy: 0.9839 - val_loss: 0.8579 - val_accuracy: 0.7407\n",
      "Epoch 15/150\n",
      "124/124 [==============================] - 0s 669us/step - loss: 0.0830 - accuracy: 0.9677 - val_loss: 0.1972 - val_accuracy: 0.9259\n",
      "Epoch 16/150\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0393 - accuracy: 0.9919 - val_loss: 0.6688 - val_accuracy: 0.8148\n",
      "Epoch 17/150\n",
      "124/124 [==============================] - 0s 285us/step - loss: 0.0563 - accuracy: 0.9758 - val_loss: 0.2974 - val_accuracy: 0.8889\n",
      "Epoch 18/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0229 - accuracy: 0.9919 - val_loss: 0.2297 - val_accuracy: 0.8889\n",
      "Epoch 19/150\n",
      "124/124 [==============================] - 0s 509us/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2153 - val_accuracy: 0.9074\n",
      "Epoch 20/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.2662 - val_accuracy: 0.8889\n",
      "Epoch 21/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 0.0210 - accuracy: 0.9839 - val_loss: 0.2751 - val_accuracy: 0.8889\n",
      "Epoch 22/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.8889\n",
      "Epoch 23/150\n",
      "124/124 [==============================] - 0s 261us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.3086 - val_accuracy: 0.8889\n",
      "Epoch 24/150\n",
      "124/124 [==============================] - 0s 413us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.3304 - val_accuracy: 0.8889\n",
      "Epoch 25/150\n",
      "124/124 [==============================] - 0s 459us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.2387 - val_accuracy: 0.9259\n",
      "Epoch 26/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.3230 - val_accuracy: 0.8889\n",
      "Epoch 27/150\n",
      "124/124 [==============================] - 0s 524us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.3105 - val_accuracy: 0.8889\n",
      "Epoch 28/150\n",
      "124/124 [==============================] - 0s 419us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.8889\n",
      "Epoch 29/150\n",
      "124/124 [==============================] - 0s 379us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.3151 - val_accuracy: 0.8889\n",
      "Epoch 30/150\n",
      "124/124 [==============================] - 0s 362us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3128 - val_accuracy: 0.8889\n",
      "Epoch 31/150\n",
      "124/124 [==============================] - 0s 387us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.8889\n",
      "Epoch 32/150\n",
      "124/124 [==============================] - 0s 230us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.8889\n",
      "Epoch 33/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3284 - val_accuracy: 0.8889\n",
      "Epoch 34/150\n",
      "124/124 [==============================] - 0s 369us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.8889\n",
      "Epoch 35/150\n",
      "124/124 [==============================] - 0s 411us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.8889\n",
      "Epoch 36/150\n",
      "124/124 [==============================] - 0s 403us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.8889\n",
      "Epoch 37/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.8889\n",
      "Epoch 38/150\n",
      "124/124 [==============================] - 0s 350us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.8889\n",
      "Epoch 39/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.8889\n",
      "Epoch 40/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.8889\n",
      "Epoch 41/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3040 - val_accuracy: 0.8889\n",
      "Epoch 42/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.8889\n",
      "Epoch 43/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.8889\n",
      "Epoch 44/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.8889\n",
      "Epoch 45/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.8889\n",
      "Epoch 46/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.8889\n",
      "Epoch 47/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.0856e-04 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8889\n",
      "Epoch 48/150\n",
      "124/124 [==============================] - 0s 493us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.8889\n",
      "Epoch 49/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.3632e-04 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.8889\n",
      "Epoch 50/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.7123e-04 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.8889\n",
      "Epoch 51/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.5034e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8889\n",
      "Epoch 52/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.1751e-04 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.8889\n",
      "Epoch 53/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.5537e-04 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.8889\n",
      "Epoch 54/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.0006e-04 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8889\n",
      "Epoch 55/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.1674e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8889\n",
      "Epoch 56/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.8492e-04 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.8889\n",
      "Epoch 57/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.1305e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8889\n",
      "Epoch 58/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.0333e-04 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.8889\n",
      "Epoch 59/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.5918e-04 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8889\n",
      "Epoch 60/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.4877e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8889\n",
      "Epoch 61/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 3.5849e-04 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.8889\n",
      "Epoch 62/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 3.1468e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.8889\n",
      "Epoch 63/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.9249e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.8889\n",
      "Epoch 64/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.8648e-04 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.8889\n",
      "Epoch 65/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 2.6651e-04 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.8889\n",
      "Epoch 66/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 2.5134e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8889\n",
      "Epoch 67/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.3752e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8889\n",
      "Epoch 68/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.3590e-04 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8889\n",
      "Epoch 69/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 2.2064e-04 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.8889\n",
      "Epoch 70/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.1613e-04 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.8889\n",
      "Epoch 71/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.0161e-04 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.8889\n",
      "Epoch 72/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.9260e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8889\n",
      "Epoch 73/150\n",
      "124/124 [==============================] - 0s 531us/step - loss: 1.8730e-04 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.8889\n",
      "Epoch 74/150\n",
      "124/124 [==============================] - 0s 376us/step - loss: 1.7990e-04 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8889\n",
      "Epoch 75/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.7204e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8889\n",
      "Epoch 76/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.7166e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8889\n",
      "Epoch 77/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.6505e-04 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.8889\n",
      "Epoch 78/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.5976e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8889\n",
      "Epoch 79/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.5724e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.8889\n",
      "Epoch 80/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.4877e-04 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8889\n",
      "Epoch 81/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.4114e-04 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8889\n",
      "Epoch 82/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.3988e-04 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.8889\n",
      "Epoch 83/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.3529e-04 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.8889\n",
      "Epoch 84/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.2989e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8889\n",
      "Epoch 85/150\n",
      "124/124 [==============================] - 0s 882us/step - loss: 1.2796e-04 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8889\n",
      "Epoch 86/150\n",
      "124/124 [==============================] - 0s 362us/step - loss: 1.2193e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.8889\n",
      "Epoch 87/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2139e-04 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.8889\n",
      "Epoch 88/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1697e-04 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.8889\n",
      "Epoch 89/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1518e-04 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.8889\n",
      "Epoch 90/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.1174e-04 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8889\n",
      "Epoch 91/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.0722e-04 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8889\n",
      "Epoch 92/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.0669e-04 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.8889\n",
      "Epoch 93/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.0372e-04 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.8889\n",
      "Epoch 94/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.0222e-04 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8889\n",
      "Epoch 95/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.0031e-04 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.8889\n",
      "Epoch 96/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.5442e-05 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8889\n",
      "Epoch 97/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.5977e-05 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.8889\n",
      "Epoch 98/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.4053e-05 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8889\n",
      "Epoch 99/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.1440e-05 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.8889\n",
      "Epoch 100/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.0972e-05 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.8889\n",
      "Epoch 101/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 8.8183e-05 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.8889\n",
      "Epoch 102/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 8.5301e-05 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.8889\n",
      "Epoch 103/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 8.4601e-05 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.8889\n",
      "Epoch 104/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 8.2576e-05 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.8889\n",
      "Epoch 105/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 8.1839e-05 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.8889\n",
      "Epoch 106/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 8.0025e-05 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.8889\n",
      "Epoch 107/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.7779e-05 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.8889\n",
      "Epoch 108/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.6775e-05 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8889\n",
      "Epoch 109/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.5265e-05 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.8889\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 630us/step - loss: 7.4122e-05 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.8889\n",
      "Epoch 111/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.3158e-05 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8889\n",
      "Epoch 112/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 7.1331e-05 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8889\n",
      "Epoch 113/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.9868e-05 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.8889\n",
      "Epoch 114/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.8616e-05 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.8889\n",
      "Epoch 115/150\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.7425e-05 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.8889\n",
      "Epoch 116/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.6777e-05 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.8889\n",
      "Epoch 117/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 6.5123e-05 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8889\n",
      "Epoch 118/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 6.4463e-05 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.8889\n",
      "Epoch 119/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 6.4148e-05 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.8889\n",
      "Epoch 120/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.3424e-05 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.8889\n",
      "Epoch 121/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.2070e-05 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.8889\n",
      "Epoch 122/150\n",
      "124/124 [==============================] - 0s 287us/step - loss: 6.1025e-05 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.8889\n",
      "Epoch 123/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.9858e-05 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.8889\n",
      "Epoch 124/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.9130e-05 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.8889\n",
      "Epoch 125/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.9292e-05 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.8889\n",
      "Epoch 126/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.7436e-05 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.8889\n",
      "Epoch 127/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.6366e-05 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.8889\n",
      "Epoch 128/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.6133e-05 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.8889\n",
      "Epoch 129/150\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.5003e-05 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8889\n",
      "Epoch 130/150\n",
      "124/124 [==============================] - 0s 252us/step - loss: 5.4478e-05 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8889\n",
      "Epoch 131/150\n",
      "124/124 [==============================] - 0s 426us/step - loss: 5.3683e-05 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.8889\n",
      "Epoch 132/150\n",
      "124/124 [==============================] - 0s 501us/step - loss: 5.2825e-05 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.8889\n",
      "Epoch 133/150\n",
      "124/124 [==============================] - 0s 412us/step - loss: 5.2222e-05 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8889\n",
      "Epoch 134/150\n",
      "124/124 [==============================] - 0s 790us/step - loss: 5.1962e-05 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8889\n",
      "Epoch 135/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 5.0908e-05 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8889\n",
      "Epoch 136/150\n",
      "124/124 [==============================] - 0s 516us/step - loss: 5.0303e-05 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.8889\n",
      "Epoch 137/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 4.9704e-05 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.8889\n",
      "Epoch 138/150\n",
      "124/124 [==============================] - 0s 443us/step - loss: 4.8954e-05 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.8889\n",
      "Epoch 139/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 4.8506e-05 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.8889\n",
      "Epoch 140/150\n",
      "124/124 [==============================] - 0s 451us/step - loss: 4.7804e-05 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.8889\n",
      "Epoch 141/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 4.7611e-05 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8889\n",
      "Epoch 142/150\n",
      "124/124 [==============================] - 0s 484us/step - loss: 4.6919e-05 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.8889\n",
      "Epoch 143/150\n",
      "124/124 [==============================] - 0s 500us/step - loss: 4.6202e-05 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.8889\n",
      "Epoch 144/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 4.5567e-05 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.8889\n",
      "Epoch 145/150\n",
      "124/124 [==============================] - 0s 467us/step - loss: 4.5600e-05 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8889\n",
      "Epoch 146/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 4.4479e-05 - accuracy: 1.0000 - val_loss: 0.5136 - val_accuracy: 0.8889\n",
      "Epoch 147/150\n",
      "124/124 [==============================] - 0s 427us/step - loss: 4.4269e-05 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.8889\n",
      "Epoch 148/150\n",
      "124/124 [==============================] - 0s 492us/step - loss: 4.3814e-05 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.8889\n",
      "Epoch 149/150\n",
      "124/124 [==============================] - 0s 435us/step - loss: 4.3113e-05 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.8889\n",
      "Epoch 150/150\n",
      "124/124 [==============================] - ETA: 0s - loss: 1.4739e-05 - accuracy: 1.00 - 0s 997us/step - loss: 4.2558e-05 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8889\n",
      "Test loss: 0.5154563734928767\n",
      "Test accuracy: 0.8888888955116272\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=150,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124 samples, validate on 54 samples\n",
      "Epoch 1/250\n",
      "124/124 [==============================] - 1s 5ms/step - loss: 1.0935 - accuracy: 0.3952 - val_loss: 1.0788 - val_accuracy: 0.5741\n",
      "Epoch 2/250\n",
      "124/124 [==============================] - 0s 774us/step - loss: 1.0710 - accuracy: 0.5242 - val_loss: 1.0416 - val_accuracy: 0.6481\n",
      "Epoch 3/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 1.0170 - accuracy: 0.5565 - val_loss: 0.9586 - val_accuracy: 0.8148\n",
      "Epoch 4/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 0.8796 - accuracy: 0.7903 - val_loss: 0.7461 - val_accuracy: 0.6481\n",
      "Epoch 5/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 0.6597 - accuracy: 0.7984 - val_loss: 0.5029 - val_accuracy: 0.8333\n",
      "Epoch 6/250\n",
      "124/124 [==============================] - 0s 677us/step - loss: 0.3817 - accuracy: 0.9113 - val_loss: 0.4971 - val_accuracy: 0.7778\n",
      "Epoch 7/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 0.3034 - accuracy: 0.8790 - val_loss: 0.2614 - val_accuracy: 0.8889\n",
      "Epoch 8/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 0.1501 - accuracy: 0.9597 - val_loss: 1.2106 - val_accuracy: 0.5741\n",
      "Epoch 9/250\n",
      "124/124 [==============================] - 0s 661us/step - loss: 0.2033 - accuracy: 0.9113 - val_loss: 0.4141 - val_accuracy: 0.8519\n",
      "Epoch 10/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 0.1498 - accuracy: 0.9597 - val_loss: 0.1848 - val_accuracy: 0.9444\n",
      "Epoch 11/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 0.0831 - accuracy: 0.9677 - val_loss: 0.2108 - val_accuracy: 0.9074\n",
      "Epoch 12/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 0.0567 - accuracy: 0.9839 - val_loss: 0.2166 - val_accuracy: 0.9074\n",
      "Epoch 13/250\n",
      "124/124 [==============================] - 0s 878us/step - loss: 0.0556 - accuracy: 0.9839 - val_loss: 0.3455 - val_accuracy: 0.9074\n",
      "Epoch 14/250\n",
      "124/124 [==============================] - 0s 903us/step - loss: 0.0705 - accuracy: 0.9839 - val_loss: 0.2952 - val_accuracy: 0.9074\n",
      "Epoch 15/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 0.0363 - accuracy: 0.9919 - val_loss: 0.2383 - val_accuracy: 0.9074\n",
      "Epoch 16/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 0.0516 - accuracy: 0.9758 - val_loss: 0.2482 - val_accuracy: 0.8889\n",
      "Epoch 17/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 0.0318 - accuracy: 0.9919 - val_loss: 0.3019 - val_accuracy: 0.9074\n",
      "Epoch 18/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 0.0354 - accuracy: 0.9839 - val_loss: 0.3158 - val_accuracy: 0.9074\n",
      "Epoch 19/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 0.0346 - accuracy: 0.9839 - val_loss: 0.2962 - val_accuracy: 0.9074\n",
      "Epoch 20/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.2540 - val_accuracy: 0.8704\n",
      "Epoch 21/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9074\n",
      "Epoch 22/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9074\n",
      "Epoch 23/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.2975 - val_accuracy: 0.9074\n",
      "Epoch 24/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.2713 - val_accuracy: 0.8889\n",
      "Epoch 25/250\n",
      "124/124 [==============================] - 0s 677us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9074\n",
      "Epoch 26/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.8889\n",
      "Epoch 27/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9074\n",
      "Epoch 28/250\n",
      "124/124 [==============================] - 0s 645us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9074\n",
      "Epoch 29/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.3259 - val_accuracy: 0.8889\n",
      "Epoch 30/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 0.9074\n",
      "Epoch 31/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.3171 - val_accuracy: 0.8889\n",
      "Epoch 32/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9074\n",
      "Epoch 33/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.3099 - val_accuracy: 0.8519\n",
      "Epoch 34/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9074\n",
      "Epoch 35/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.8889\n",
      "Epoch 36/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9074\n",
      "Epoch 37/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9074\n",
      "Epoch 38/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9074\n",
      "Epoch 39/250\n",
      "124/124 [==============================] - 0s 450us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.8889\n",
      "Epoch 40/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.8704\n",
      "Epoch 41/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9074\n",
      "Epoch 42/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9074\n",
      "Epoch 43/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.8889\n",
      "Epoch 44/250\n",
      "124/124 [==============================] - 0s 515us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9074\n",
      "Epoch 45/250\n",
      "124/124 [==============================] - 0s 457us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.8704\n",
      "Epoch 46/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.9074\n",
      "Epoch 47/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8889\n",
      "Epoch 48/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 9.3233e-04 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8889\n",
      "Epoch 49/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 8.7219e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9074\n",
      "Epoch 50/250\n",
      "124/124 [==============================] - 0s 420us/step - loss: 8.5945e-04 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8889\n",
      "Epoch 51/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 7.6442e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9074\n",
      "Epoch 52/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 7.0212e-04 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8704\n",
      "Epoch 53/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 7.0534e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9074\n",
      "Epoch 54/250\n",
      "124/124 [==============================] - 0s 497us/step - loss: 6.1592e-04 - accuracy: 1.0000 - val_loss: 0.4887 - val_accuracy: 0.9074\n",
      "Epoch 55/250\n",
      "124/124 [==============================] - 0s 701us/step - loss: 6.0020e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.8889\n",
      "Epoch 56/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 5.3721e-04 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.8889\n",
      "Epoch 57/250\n",
      "124/124 [==============================] - 0s 604us/step - loss: 4.8494e-04 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9074\n",
      "Epoch 58/250\n",
      "124/124 [==============================] - 0s 787us/step - loss: 4.5148e-04 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8889\n",
      "Epoch 59/250\n",
      "124/124 [==============================] - 0s 686us/step - loss: 4.3114e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9074\n",
      "Epoch 60/250\n",
      "124/124 [==============================] - 0s 628us/step - loss: 4.0755e-04 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8889\n",
      "Epoch 61/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 3.7913e-04 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9074\n",
      "Epoch 62/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 3.6685e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.8889\n",
      "Epoch 63/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 3.7968e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.8704\n",
      "Epoch 64/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 3.8492e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.8889\n",
      "Epoch 65/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 3.2017e-04 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.8889\n",
      "Epoch 66/250\n",
      "124/124 [==============================] - 0s 464us/step - loss: 2.8427e-04 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9074\n",
      "Epoch 67/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 2.8779e-04 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8889\n",
      "Epoch 68/250\n",
      "124/124 [==============================] - 0s 486us/step - loss: 2.6988e-04 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.9074\n",
      "Epoch 69/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 2.5486e-04 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.9074\n",
      "Epoch 70/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 2.4613e-04 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.8889\n",
      "Epoch 71/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.3059e-04 - accuracy: 1.0000 - val_loss: 0.5215 - val_accuracy: 0.9074\n",
      "Epoch 72/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 2.3618e-04 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.8889\n",
      "Epoch 73/250\n",
      "124/124 [==============================] - 0s 360us/step - loss: 2.2493e-04 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.8889\n",
      "Epoch 74/250\n",
      "124/124 [==============================] - 0s 579us/step - loss: 2.1015e-04 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8889\n",
      "Epoch 75/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 2.0093e-04 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.9074\n",
      "Epoch 76/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 1.9139e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.8889\n",
      "Epoch 77/250\n",
      "124/124 [==============================] - 0s 391us/step - loss: 1.8724e-04 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.8889\n",
      "Epoch 78/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.8642e-04 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.8889\n",
      "Epoch 79/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.7676e-04 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.9074\n",
      "Epoch 80/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.8065e-04 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.9074\n",
      "Epoch 81/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.6729e-04 - accuracy: 1.0000 - val_loss: 0.5277 - val_accuracy: 0.9074\n",
      "Epoch 82/250\n",
      "124/124 [==============================] - 0s 391us/step - loss: 1.6224e-04 - accuracy: 1.0000 - val_loss: 0.5312 - val_accuracy: 0.9074\n",
      "Epoch 83/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.5851e-04 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.9074\n",
      "Epoch 84/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.5302e-04 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.8889\n",
      "Epoch 85/250\n",
      "124/124 [==============================] - 0s 368us/step - loss: 1.4916e-04 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.9074\n",
      "Epoch 86/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.4323e-04 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.9074\n",
      "Epoch 87/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.4107e-04 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9074\n",
      "Epoch 88/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 1.3825e-04 - accuracy: 1.0000 - val_loss: 0.5417 - val_accuracy: 0.9074\n",
      "Epoch 89/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.3103e-04 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.9074\n",
      "Epoch 90/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.2918e-04 - accuracy: 1.0000 - val_loss: 0.5399 - val_accuracy: 0.9074\n",
      "Epoch 91/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 1.2647e-04 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.9074\n",
      "Epoch 92/250\n",
      "124/124 [==============================] - 0s 548us/step - loss: 1.2205e-04 - accuracy: 1.0000 - val_loss: 0.5422 - val_accuracy: 0.9074\n",
      "Epoch 93/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 1.1787e-04 - accuracy: 1.0000 - val_loss: 0.5379 - val_accuracy: 0.8889\n",
      "Epoch 94/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 1.1631e-04 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.9074\n",
      "Epoch 95/250\n",
      "124/124 [==============================] - 0s 457us/step - loss: 1.1258e-04 - accuracy: 1.0000 - val_loss: 0.5399 - val_accuracy: 0.8889\n",
      "Epoch 96/250\n",
      "124/124 [==============================] - 0s 299us/step - loss: 1.1141e-04 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.8889\n",
      "Epoch 97/250\n",
      "124/124 [==============================] - 0s 457us/step - loss: 1.0828e-04 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.9074\n",
      "Epoch 98/250\n",
      "124/124 [==============================] - 0s 371us/step - loss: 1.0567e-04 - accuracy: 1.0000 - val_loss: 0.5560 - val_accuracy: 0.9074\n",
      "Epoch 99/250\n",
      "124/124 [==============================] - 0s 333us/step - loss: 1.0367e-04 - accuracy: 1.0000 - val_loss: 0.5584 - val_accuracy: 0.9074\n",
      "Epoch 100/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 1.0099e-04 - accuracy: 1.0000 - val_loss: 0.5564 - val_accuracy: 0.9074\n",
      "Epoch 101/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 9.9033e-05 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.9074\n",
      "Epoch 102/250\n",
      "124/124 [==============================] - 0s 438us/step - loss: 9.6507e-05 - accuracy: 1.0000 - val_loss: 0.5624 - val_accuracy: 0.9074\n",
      "Epoch 103/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 9.5640e-05 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8889\n",
      "Epoch 104/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 9.4673e-05 - accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.8889\n",
      "Epoch 105/250\n",
      "124/124 [==============================] - 0s 363us/step - loss: 9.2919e-05 - accuracy: 1.0000 - val_loss: 0.5577 - val_accuracy: 0.8889\n",
      "Epoch 106/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 8.9242e-05 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 0.9074\n",
      "Epoch 107/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 8.9122e-05 - accuracy: 1.0000 - val_loss: 0.5657 - val_accuracy: 0.9074\n",
      "Epoch 108/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 8.5680e-05 - accuracy: 1.0000 - val_loss: 0.5716 - val_accuracy: 0.9074\n",
      "Epoch 109/250\n",
      "124/124 [==============================] - 0s 742us/step - loss: 8.4786e-05 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.9074\n",
      "Epoch 110/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 436us/step - loss: 8.4111e-05 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.9074\n",
      "Epoch 111/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 8.2270e-05 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.9074\n",
      "Epoch 112/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 8.0126e-05 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.9074\n",
      "Epoch 113/250\n",
      "124/124 [==============================] - 0s 637us/step - loss: 7.8375e-05 - accuracy: 1.0000 - val_loss: 0.5743 - val_accuracy: 0.9074\n",
      "Epoch 114/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 7.6424e-05 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 0.9074\n",
      "Epoch 115/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 7.5595e-05 - accuracy: 1.0000 - val_loss: 0.5734 - val_accuracy: 0.9074\n",
      "Epoch 116/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 7.4584e-05 - accuracy: 1.0000 - val_loss: 0.5777 - val_accuracy: 0.9074\n",
      "Epoch 117/250\n",
      "124/124 [==============================] - 0s 415us/step - loss: 7.4085e-05 - accuracy: 1.0000 - val_loss: 0.5794 - val_accuracy: 0.9074\n",
      "Epoch 118/250\n",
      "124/124 [==============================] - 0s 535us/step - loss: 7.3153e-05 - accuracy: 1.0000 - val_loss: 0.5823 - val_accuracy: 0.9074\n",
      "Epoch 119/250\n",
      "124/124 [==============================] - 0s 605us/step - loss: 7.0753e-05 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.8889\n",
      "Epoch 120/250\n",
      "124/124 [==============================] - 0s 418us/step - loss: 7.0914e-05 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.9074\n",
      "Epoch 121/250\n",
      "124/124 [==============================] - 0s 490us/step - loss: 6.9733e-05 - accuracy: 1.0000 - val_loss: 0.5790 - val_accuracy: 0.9074\n",
      "Epoch 122/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 6.7664e-05 - accuracy: 1.0000 - val_loss: 0.5783 - val_accuracy: 0.8889\n",
      "Epoch 123/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.7618e-05 - accuracy: 1.0000 - val_loss: 0.5815 - val_accuracy: 0.9074\n",
      "Epoch 124/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.5799e-05 - accuracy: 1.0000 - val_loss: 0.5824 - val_accuracy: 0.9074\n",
      "Epoch 125/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 6.5091e-05 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.9074\n",
      "Epoch 126/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.3979e-05 - accuracy: 1.0000 - val_loss: 0.5858 - val_accuracy: 0.9074\n",
      "Epoch 127/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.3436e-05 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.9074\n",
      "Epoch 128/250\n",
      "124/124 [==============================] - 0s 522us/step - loss: 6.2011e-05 - accuracy: 1.0000 - val_loss: 0.5901 - val_accuracy: 0.9074\n",
      "Epoch 129/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 6.1757e-05 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.9074\n",
      "Epoch 130/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 6.0843e-05 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.9074\n",
      "Epoch 131/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.9477e-05 - accuracy: 1.0000 - val_loss: 0.5916 - val_accuracy: 0.9074\n",
      "Epoch 132/250\n",
      "124/124 [==============================] - 0s 468us/step - loss: 5.9859e-05 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 0.9074\n",
      "Epoch 133/250\n",
      "124/124 [==============================] - 0s 515us/step - loss: 5.8807e-05 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.9074\n",
      "Epoch 134/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 5.7281e-05 - accuracy: 1.0000 - val_loss: 0.5953 - val_accuracy: 0.9074\n",
      "Epoch 135/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.7154e-05 - accuracy: 1.0000 - val_loss: 0.5928 - val_accuracy: 0.9074\n",
      "Epoch 136/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 5.6727e-05 - accuracy: 1.0000 - val_loss: 0.5950 - val_accuracy: 0.9074\n",
      "Epoch 137/250\n",
      "124/124 [==============================] - 0s 432us/step - loss: 5.5751e-05 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 0.9074\n",
      "Epoch 138/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 5.4720e-05 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 0.9074\n",
      "Epoch 139/250\n",
      "124/124 [==============================] - 0s 493us/step - loss: 5.5554e-05 - accuracy: 1.0000 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
      "Epoch 140/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 5.4314e-05 - accuracy: 1.0000 - val_loss: 0.5940 - val_accuracy: 0.8889\n",
      "Epoch 141/250\n",
      "124/124 [==============================] - 0s 806us/step - loss: 5.2978e-05 - accuracy: 1.0000 - val_loss: 0.5934 - val_accuracy: 0.8889\n",
      "Epoch 142/250\n",
      "124/124 [==============================] - 0s 685us/step - loss: 5.3045e-05 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.9074\n",
      "Epoch 143/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 5.1616e-05 - accuracy: 1.0000 - val_loss: 0.6042 - val_accuracy: 0.9074\n",
      "Epoch 144/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 5.1189e-05 - accuracy: 1.0000 - val_loss: 0.6030 - val_accuracy: 0.9074\n",
      "Epoch 145/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 5.0541e-05 - accuracy: 1.0000 - val_loss: 0.6035 - val_accuracy: 0.9074\n",
      "Epoch 146/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 4.9620e-05 - accuracy: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.9074\n",
      "Epoch 147/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 4.8961e-05 - accuracy: 1.0000 - val_loss: 0.6070 - val_accuracy: 0.9074\n",
      "Epoch 148/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 4.8653e-05 - accuracy: 1.0000 - val_loss: 0.6065 - val_accuracy: 0.9074\n",
      "Epoch 149/250\n",
      "124/124 [==============================] - 0s 360us/step - loss: 4.8130e-05 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9074\n",
      "Epoch 150/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 4.7053e-05 - accuracy: 1.0000 - val_loss: 0.6071 - val_accuracy: 0.9074\n",
      "Epoch 151/250\n",
      "124/124 [==============================] - 0s 476us/step - loss: 4.7094e-05 - accuracy: 1.0000 - val_loss: 0.6114 - val_accuracy: 0.9074\n",
      "Epoch 152/250\n",
      "124/124 [==============================] - 0s 413us/step - loss: 4.6052e-05 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.9074\n",
      "Epoch 153/250\n",
      "124/124 [==============================] - 0s 504us/step - loss: 4.5777e-05 - accuracy: 1.0000 - val_loss: 0.6095 - val_accuracy: 0.9074\n",
      "Epoch 154/250\n",
      "124/124 [==============================] - 0s 378us/step - loss: 4.6221e-05 - accuracy: 1.0000 - val_loss: 0.6116 - val_accuracy: 0.9074\n",
      "Epoch 155/250\n",
      "124/124 [==============================] - 0s 449us/step - loss: 4.4748e-05 - accuracy: 1.0000 - val_loss: 0.6139 - val_accuracy: 0.9074\n",
      "Epoch 156/250\n",
      "124/124 [==============================] - 0s 575us/step - loss: 4.4384e-05 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.9074\n",
      "Epoch 157/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 4.3988e-05 - accuracy: 1.0000 - val_loss: 0.6129 - val_accuracy: 0.9074\n",
      "Epoch 158/250\n",
      "124/124 [==============================] - 0s 430us/step - loss: 4.3913e-05 - accuracy: 1.0000 - val_loss: 0.6138 - val_accuracy: 0.9074\n",
      "Epoch 159/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 4.3181e-05 - accuracy: 1.0000 - val_loss: 0.6151 - val_accuracy: 0.9074\n",
      "Epoch 160/250\n",
      "124/124 [==============================] - 0s 660us/step - loss: 4.2571e-05 - accuracy: 1.0000 - val_loss: 0.6158 - val_accuracy: 0.9074\n",
      "Epoch 161/250\n",
      "124/124 [==============================] - 0s 588us/step - loss: 4.2283e-05 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.9074\n",
      "Epoch 162/250\n",
      "124/124 [==============================] - 0s 669us/step - loss: 4.2150e-05 - accuracy: 1.0000 - val_loss: 0.6172 - val_accuracy: 0.9074\n",
      "Epoch 163/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 4.1448e-05 - accuracy: 1.0000 - val_loss: 0.6183 - val_accuracy: 0.9074\n",
      "Epoch 164/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 4.0954e-05 - accuracy: 1.0000 - val_loss: 0.6227 - val_accuracy: 0.9074\n",
      "Epoch 165/250\n",
      "124/124 [==============================] - 0s 691us/step - loss: 4.1087e-05 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.9074\n",
      "Epoch 166/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 4.0265e-05 - accuracy: 1.0000 - val_loss: 0.6274 - val_accuracy: 0.9074\n",
      "Epoch 167/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 4.0236e-05 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.9074\n",
      "Epoch 168/250\n",
      "124/124 [==============================] - 0s 707us/step - loss: 3.9300e-05 - accuracy: 1.0000 - val_loss: 0.6280 - val_accuracy: 0.9074\n",
      "Epoch 169/250\n",
      "124/124 [==============================] - 0s 566us/step - loss: 3.9240e-05 - accuracy: 1.0000 - val_loss: 0.6232 - val_accuracy: 0.9074\n",
      "Epoch 170/250\n",
      "124/124 [==============================] - 0s 750us/step - loss: 3.8777e-05 - accuracy: 1.0000 - val_loss: 0.6249 - val_accuracy: 0.9074\n",
      "Epoch 171/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 3.8090e-05 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.9074\n",
      "Epoch 172/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 3.7728e-05 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 0.9074\n",
      "Epoch 173/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 3.7880e-05 - accuracy: 1.0000 - val_loss: 0.6254 - val_accuracy: 0.9074\n",
      "Epoch 174/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 3.7170e-05 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.9074\n",
      "Epoch 175/250\n",
      "124/124 [==============================] - 0s 653us/step - loss: 3.6794e-05 - accuracy: 1.0000 - val_loss: 0.6223 - val_accuracy: 0.8889\n",
      "Epoch 176/250\n",
      "124/124 [==============================] - 0s 686us/step - loss: 3.6776e-05 - accuracy: 1.0000 - val_loss: 0.6212 - val_accuracy: 0.8889\n",
      "Epoch 177/250\n",
      "124/124 [==============================] - 0s 705us/step - loss: 3.6405e-05 - accuracy: 1.0000 - val_loss: 0.6229 - val_accuracy: 0.8889\n",
      "Epoch 178/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 3.5906e-05 - accuracy: 1.0000 - val_loss: 0.6251 - val_accuracy: 0.8889\n",
      "Epoch 179/250\n",
      "124/124 [==============================] - 0s 443us/step - loss: 3.5724e-05 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.8889\n",
      "Epoch 180/250\n",
      "124/124 [==============================] - 0s 467us/step - loss: 3.5215e-05 - accuracy: 1.0000 - val_loss: 0.6285 - val_accuracy: 0.8889\n",
      "Epoch 181/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 3.5266e-05 - accuracy: 1.0000 - val_loss: 0.6327 - val_accuracy: 0.9074\n",
      "Epoch 182/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 3.4898e-05 - accuracy: 1.0000 - val_loss: 0.6323 - val_accuracy: 0.9074\n",
      "Epoch 183/250\n",
      "124/124 [==============================] - 0s 879us/step - loss: 3.4405e-05 - accuracy: 1.0000 - val_loss: 0.6345 - val_accuracy: 0.9074\n",
      "Epoch 184/250\n",
      "124/124 [==============================] - 0s 929us/step - loss: 3.3834e-05 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.8889\n",
      "Epoch 185/250\n",
      "124/124 [==============================] - 0s 667us/step - loss: 3.3514e-05 - accuracy: 1.0000 - val_loss: 0.6306 - val_accuracy: 0.8889\n",
      "Epoch 186/250\n",
      "124/124 [==============================] - 0s 749us/step - loss: 3.3597e-05 - accuracy: 1.0000 - val_loss: 0.6353 - val_accuracy: 0.9074\n",
      "Epoch 187/250\n",
      "124/124 [==============================] - 0s 726us/step - loss: 3.3375e-05 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.9074\n",
      "Epoch 188/250\n",
      "124/124 [==============================] - 0s 756us/step - loss: 3.3511e-05 - accuracy: 1.0000 - val_loss: 0.6360 - val_accuracy: 0.9074\n",
      "Epoch 189/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 3.2237e-05 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.9074\n",
      "Epoch 190/250\n",
      "124/124 [==============================] - 0s 882us/step - loss: 3.2523e-05 - accuracy: 1.0000 - val_loss: 0.6381 - val_accuracy: 0.9074\n",
      "Epoch 191/250\n",
      "124/124 [==============================] - 0s 756us/step - loss: 3.2487e-05 - accuracy: 1.0000 - val_loss: 0.6380 - val_accuracy: 0.9074\n",
      "Epoch 192/250\n",
      "124/124 [==============================] - 0s 630us/step - loss: 3.2290e-05 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 0.8889\n",
      "Epoch 193/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 3.1977e-05 - accuracy: 1.0000 - val_loss: 0.6366 - val_accuracy: 0.9074\n",
      "Epoch 194/250\n",
      "124/124 [==============================] - 0s 846us/step - loss: 3.1648e-05 - accuracy: 1.0000 - val_loss: 0.6379 - val_accuracy: 0.9074\n",
      "Epoch 195/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 3.1336e-05 - accuracy: 1.0000 - val_loss: 0.6392 - val_accuracy: 0.9074\n",
      "Epoch 196/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 3.0928e-05 - accuracy: 1.0000 - val_loss: 0.6403 - val_accuracy: 0.9074\n",
      "Epoch 197/250\n",
      "124/124 [==============================] - 0s 532us/step - loss: 3.0716e-05 - accuracy: 1.0000 - val_loss: 0.6370 - val_accuracy: 0.9074\n",
      "Epoch 198/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 3.0487e-05 - accuracy: 1.0000 - val_loss: 0.6372 - val_accuracy: 0.9074\n",
      "Epoch 199/250\n",
      "124/124 [==============================] - 0s 629us/step - loss: 3.0144e-05 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.9074\n",
      "Epoch 200/250\n",
      "124/124 [==============================] - 0s 661us/step - loss: 3.0131e-05 - accuracy: 1.0000 - val_loss: 0.6416 - val_accuracy: 0.9074\n",
      "Epoch 201/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 3.0250e-05 - accuracy: 1.0000 - val_loss: 0.6402 - val_accuracy: 0.9074\n",
      "Epoch 202/250\n",
      "124/124 [==============================] - 0s 484us/step - loss: 3.0087e-05 - accuracy: 1.0000 - val_loss: 0.6404 - val_accuracy: 0.9074\n",
      "Epoch 203/250\n",
      "124/124 [==============================] - 0s 597us/step - loss: 3.0225e-05 - accuracy: 1.0000 - val_loss: 0.6421 - val_accuracy: 0.9074\n",
      "Epoch 204/250\n",
      "124/124 [==============================] - 0s 709us/step - loss: 2.9437e-05 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.9074\n",
      "Epoch 205/250\n",
      "124/124 [==============================] - 0s 693us/step - loss: 2.8834e-05 - accuracy: 1.0000 - val_loss: 0.6481 - val_accuracy: 0.9074\n",
      "Epoch 206/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 2.9877e-05 - accuracy: 1.0000 - val_loss: 0.6461 - val_accuracy: 0.9074\n",
      "Epoch 207/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 2.9113e-05 - accuracy: 1.0000 - val_loss: 0.6445 - val_accuracy: 0.9074\n",
      "Epoch 208/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 2.8611e-05 - accuracy: 1.0000 - val_loss: 0.6423 - val_accuracy: 0.8889\n",
      "Epoch 209/250\n",
      "124/124 [==============================] - 0s 486us/step - loss: 2.8351e-05 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.9074\n",
      "Epoch 210/250\n",
      "124/124 [==============================] - 0s 524us/step - loss: 2.8095e-05 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.9074\n",
      "Epoch 211/250\n",
      "124/124 [==============================] - 0s 493us/step - loss: 2.8013e-05 - accuracy: 1.0000 - val_loss: 0.6460 - val_accuracy: 0.9074\n",
      "Epoch 212/250\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 2.8036e-05 - accuracy: 1.0000 - val_loss: 0.6494 - val_accuracy: 0.9074\n",
      "Epoch 213/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 2.7446e-05 - accuracy: 1.0000 - val_loss: 0.6503 - val_accuracy: 0.9074\n",
      "Epoch 214/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 2.7620e-05 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.9074\n",
      "Epoch 215/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 2.7330e-05 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.9074\n",
      "Epoch 216/250\n",
      "124/124 [==============================] - 0s 572us/step - loss: 2.6793e-05 - accuracy: 1.0000 - val_loss: 0.6481 - val_accuracy: 0.9074\n",
      "Epoch 217/250\n",
      "124/124 [==============================] - 0s 516us/step - loss: 2.6905e-05 - accuracy: 1.0000 - val_loss: 0.6450 - val_accuracy: 0.9074\n",
      "Epoch 218/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/124 [==============================] - 0s 467us/step - loss: 2.6654e-05 - accuracy: 1.0000 - val_loss: 0.6483 - val_accuracy: 0.9074\n",
      "Epoch 219/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 2.6648e-05 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.9074\n",
      "Epoch 220/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 2.6059e-05 - accuracy: 1.0000 - val_loss: 0.6462 - val_accuracy: 0.9074\n",
      "Epoch 221/250\n",
      "124/124 [==============================] - 0s 430us/step - loss: 2.6263e-05 - accuracy: 1.0000 - val_loss: 0.6490 - val_accuracy: 0.9074\n",
      "Epoch 222/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 2.6144e-05 - accuracy: 1.0000 - val_loss: 0.6458 - val_accuracy: 0.9074\n",
      "Epoch 223/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 2.5906e-05 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 0.9074\n",
      "Epoch 224/250\n",
      "124/124 [==============================] - 0s 435us/step - loss: 2.6094e-05 - accuracy: 1.0000 - val_loss: 0.6494 - val_accuracy: 0.9074\n",
      "Epoch 225/250\n",
      "124/124 [==============================] - 0s 492us/step - loss: 2.5560e-05 - accuracy: 1.0000 - val_loss: 0.6535 - val_accuracy: 0.9074\n",
      "Epoch 226/250\n",
      "124/124 [==============================] - 0s 508us/step - loss: 2.5412e-05 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 0.9074\n",
      "Epoch 227/250\n",
      "124/124 [==============================] - 0s 482us/step - loss: 2.4947e-05 - accuracy: 1.0000 - val_loss: 0.6545 - val_accuracy: 0.9074\n",
      "Epoch 228/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 2.5125e-05 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.9074\n",
      "Epoch 229/250\n",
      "124/124 [==============================] - 0s 407us/step - loss: 2.4809e-05 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.9074\n",
      "Epoch 230/250\n",
      "124/124 [==============================] - 0s 387us/step - loss: 2.4304e-05 - accuracy: 1.0000 - val_loss: 0.6563 - val_accuracy: 0.9074\n",
      "Epoch 231/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 2.4633e-05 - accuracy: 1.0000 - val_loss: 0.6564 - val_accuracy: 0.9074\n",
      "Epoch 232/250\n",
      "124/124 [==============================] - 0s 376us/step - loss: 2.4106e-05 - accuracy: 1.0000 - val_loss: 0.6559 - val_accuracy: 0.9074\n",
      "Epoch 233/250\n",
      "124/124 [==============================] - 0s 388us/step - loss: 2.3936e-05 - accuracy: 1.0000 - val_loss: 0.6567 - val_accuracy: 0.9074\n",
      "Epoch 234/250\n",
      "124/124 [==============================] - 0s 410us/step - loss: 2.3454e-05 - accuracy: 1.0000 - val_loss: 0.6588 - val_accuracy: 0.9074\n",
      "Epoch 235/250\n",
      "124/124 [==============================] - 0s 451us/step - loss: 2.3807e-05 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.9074\n",
      "Epoch 236/250\n",
      "124/124 [==============================] - 0s 379us/step - loss: 2.3862e-05 - accuracy: 1.0000 - val_loss: 0.6589 - val_accuracy: 0.9074\n",
      "Epoch 237/250\n",
      "124/124 [==============================] - 0s 411us/step - loss: 2.3550e-05 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 0.9074\n",
      "Epoch 238/250\n",
      "124/124 [==============================] - 0s 408us/step - loss: 2.3803e-05 - accuracy: 1.0000 - val_loss: 0.6562 - val_accuracy: 0.9074\n",
      "Epoch 239/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 2.3151e-05 - accuracy: 1.0000 - val_loss: 0.6547 - val_accuracy: 0.9074\n",
      "Epoch 240/250\n",
      "124/124 [==============================] - 0s 395us/step - loss: 2.3644e-05 - accuracy: 1.0000 - val_loss: 0.6560 - val_accuracy: 0.9074\n",
      "Epoch 241/250\n",
      "124/124 [==============================] - 0s 408us/step - loss: 2.3270e-05 - accuracy: 1.0000 - val_loss: 0.6580 - val_accuracy: 0.9074\n",
      "Epoch 242/250\n",
      "124/124 [==============================] - 0s 419us/step - loss: 2.2964e-05 - accuracy: 1.0000 - val_loss: 0.6583 - val_accuracy: 0.9074\n",
      "Epoch 243/250\n",
      "124/124 [==============================] - 0s 427us/step - loss: 2.2599e-05 - accuracy: 1.0000 - val_loss: 0.6605 - val_accuracy: 0.9074\n",
      "Epoch 244/250\n",
      "124/124 [==============================] - 0s 540us/step - loss: 2.2514e-05 - accuracy: 1.0000 - val_loss: 0.6669 - val_accuracy: 0.9074\n",
      "Epoch 245/250\n",
      "124/124 [==============================] - 0s 621us/step - loss: 2.2584e-05 - accuracy: 1.0000 - val_loss: 0.6571 - val_accuracy: 0.9074\n",
      "Epoch 246/250\n",
      "124/124 [==============================] - 0s 500us/step - loss: 2.2817e-05 - accuracy: 1.0000 - val_loss: 0.6584 - val_accuracy: 0.9074\n",
      "Epoch 247/250\n",
      "124/124 [==============================] - 0s 564us/step - loss: 2.1483e-05 - accuracy: 1.0000 - val_loss: 0.6594 - val_accuracy: 0.9074\n",
      "Epoch 248/250\n",
      "124/124 [==============================] - 0s 556us/step - loss: 2.1843e-05 - accuracy: 1.0000 - val_loss: 0.6600 - val_accuracy: 0.9074\n",
      "Epoch 249/250\n",
      "124/124 [==============================] - 0s 613us/step - loss: 2.1958e-05 - accuracy: 1.0000 - val_loss: 0.6616 - val_accuracy: 0.9074\n",
      "Epoch 250/250\n",
      "124/124 [==============================] - 0s 580us/step - loss: 2.2136e-05 - accuracy: 1.0000 - val_loss: 0.6680 - val_accuracy: 0.9074\n",
      "Test loss: 0.6680554183268989\n",
      "Test accuracy: 0.9074074029922485\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('wine.data',header = None)\n",
    "\n",
    "\n",
    "df.columns = [  'class labels'\n",
    "             \t,'alcohol'\n",
    "             \t,'malicAcid'\n",
    "             \t,'ash'\n",
    "            \t,'ashalcalinity'\n",
    "             \t,'magnesium'\n",
    "            \t,'totalPhenols'\n",
    "             \t,'flavanoids'\n",
    "             \t,'nonFlavanoidPhenols'\n",
    "             \t,'proanthocyanins'\n",
    "            \t,'colorIntensity'\n",
    "             \t,'hue'\n",
    "             \t,'od280_od315'\n",
    "             \t,'proline'\n",
    "                 \n",
    "                ]\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "X = df.iloc[:,1:].values\n",
    "\n",
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y-1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "from keras.layers import Conv1D, MaxPooling1D,Embedding\n",
    "model = Sequential()     \n",
    "model.add(Embedding(1700, 32, input_length=13))\n",
    "model.add(Conv1D(32, 3, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "training_model=model.fit(X_train, y_train,\n",
    "          batch_size= 15, \n",
    "          epochs=250,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
